#!/usr/bin/env python3
"""
kaname04å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«ä»£æ›¿åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ®‹ã‚Š13ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‰‹å‹•æ¤œæŸ»ã¨ä»£æ›¿æ‰‹æ³•æ¤œè¨
"""

import os
import cv2
import numpy as np
from PIL import Image
import json
from pathlib import Path

def analyze_failed_files():
    """å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°åˆ†æ"""
    input_dir = Path("/mnt/c/AItools/lora/train/yadokugaeru/org/kaname04")
    output_dir = Path("/mnt/c/AItools/lora/train/yadokugaeru/clipped_boundingbox/kaname04")
    
    # å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
    all_files = [f for f in input_dir.glob("00*.jpg") if f.is_file()]
    processed_files = [f.stem for f in output_dir.glob("*.jpg")]
    failed_files = [f for f in all_files if f.stem not in processed_files]
    
    print(f"ğŸ” å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æé–‹å§‹: {len(failed_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
    
    analysis_results = []
    
    for i, file_path in enumerate(failed_files, 1):
        print(f"\nğŸ“ åˆ†æä¸­ [{i}/{len(failed_files)}]: {file_path.name}")
        
        # ç”»åƒèª­ã¿è¾¼ã¿
        try:
            image = cv2.imread(str(file_path))
            pil_image = Image.open(file_path)
            
            # åŸºæœ¬çµ±è¨ˆ
            height, width = image.shape[:2]
            channels = image.shape[2] if len(image.shape) > 2 else 1
            
            # è‰²ç©ºé–“åˆ†æ
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            mean_brightness = np.mean(gray)
            std_brightness = np.std(gray)
            
            # ã‚¨ãƒƒã‚¸æ¤œå‡º
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / (width * height)
            
            # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆåˆ†æ
            contrast = std_brightness / mean_brightness if mean_brightness > 0 else 0
            
            # è‰²å½©åˆ†æ
            is_grayscale = len(np.unique(image.reshape(-1, image.shape[2]), axis=0)) < 50
            
            # ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸæ¨å®šï¼ˆé«˜é »åº¦ã‚¨ãƒƒã‚¸é ˜åŸŸï¼‰
            kernel = np.ones((3,3), np.uint8)
            dilated_edges = cv2.dilate(edges, kernel, iterations=1)
            text_ratio = np.sum(dilated_edges > 0) / (width * height)
            
            result = {
                'filename': file_path.name,
                'dimensions': f"{width}x{height}",
                'channels': channels,
                'mean_brightness': round(mean_brightness, 1),
                'brightness_std': round(std_brightness, 1),
                'contrast_ratio': round(contrast, 3),
                'edge_density': round(edge_density, 4),
                'text_ratio': round(text_ratio, 4),
                'is_grayscale': is_grayscale,
                'file_size_kb': file_path.stat().st_size // 1024
            }
            
            # ç‰¹å¾´åˆ†é¡
            features = []
            if mean_brightness > 200:
                features.append("é«˜è¼åº¦")
            if mean_brightness < 50:
                features.append("ä½è¼åº¦")
            if contrast < 0.3:
                features.append("ä½ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ")
            if edge_density > 0.15:
                features.append("é«˜ã‚¨ãƒƒã‚¸å¯†åº¦")
            if text_ratio > 0.3:
                features.append("ãƒ†ã‚­ã‚¹ãƒˆå¤šã„")
            if is_grayscale:
                features.append("ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«")
            
            result['features'] = features
            
            # å¤±æ•—ç†ç”±æ¨å®š
            if mean_brightness > 250:
                result['failure_reason'] = "ç™½èƒŒæ™¯éå¤šï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸åœ¨ã®å¯èƒ½æ€§ï¼‰"
            elif text_ratio > 0.4:
                result['failure_reason'] = "ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸãŒç”»åƒã®å¤§éƒ¨åˆ†ã‚’å ã‚ã‚‹"
            elif edge_density < 0.05:
                result['failure_reason'] = "ã‚¨ãƒƒã‚¸æƒ…å ±ä¸è¶³ï¼ˆã‚·ãƒ³ãƒ—ãƒ«èƒŒæ™¯ï¼‰"
            elif contrast < 0.2:
                result['failure_reason'] = "ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆä¸è¶³"
            else:
                result['failure_reason'] = "è¤‡é›‘ãªèƒŒæ™¯ã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¤åˆ¥å›°é›£"
            
            analysis_results.append(result)
            
            print(f"   å¯¸æ³•: {result['dimensions']}")
            print(f"   è¼åº¦: {result['mean_brightness']} (Â±{result['brightness_std']})")
            print(f"   ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ: {result['contrast_ratio']}")
            print(f"   ã‚¨ãƒƒã‚¸å¯†åº¦: {result['edge_density']}")
            print(f"   æ¨å®šå¤±æ•—ç†ç”±: {result['failure_reason']}")
            
        except Exception as e:
            print(f"   âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            analysis_results.append({
                'filename': file_path.name,
                'error': str(e)
            })
    
    return analysis_results

def suggest_alternatives(analysis_results):
    """ä»£æ›¿æ‰‹æ³•ææ¡ˆ"""
    print("\nğŸ”§ ä»£æ›¿æ‰‹æ³•ææ¡ˆ:")
    
    # å¤±æ•—ç†ç”±åˆ¥åˆ†é¡
    failure_categories = {}
    for result in analysis_results:
        if 'failure_reason' in result:
            reason = result['failure_reason']
            if reason not in failure_categories:
                failure_categories[reason] = []
            failure_categories[reason].append(result['filename'])
    
    alternatives = []
    
    for reason, files in failure_categories.items():
        print(f"\nğŸ“‹ å¤±æ•—ç†ç”±: {reason} ({len(files)}ãƒ•ã‚¡ã‚¤ãƒ«)")
        for file in files:
            print(f"   - {file}")
        
        if "ç™½èƒŒæ™¯éå¤š" in reason:
            alternatives.append({
                'reason': reason,
                'files': files,
                'method': 'ã‚¨ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ¤œå‡º',
                'description': 'è¼ªéƒ­ç·šæ¤œå‡ºã«ã‚ˆã‚‹ä»£æ›¿ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é ˜åŸŸç‰¹å®š',
                'feasibility': 'low'
            })
        elif "ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸ" in reason:
            alternatives.append({
                'reason': reason,
                'files': files,
                'method': 'OCRä½µç”¨é™¤å¤–',
                'description': 'ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’é™¤å¤–å¾Œã®æ®‹ã‚Šé ˜åŸŸã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ¤œå‡º',
                'feasibility': 'medium'
            })
        elif "ã‚¨ãƒƒã‚¸æƒ…å ±ä¸è¶³" in reason:
            alternatives.append({
                'reason': reason,
                'files': files,
                'method': 'æ‰‹å‹•ç¢ºèª',
                'description': 'ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸åœ¨ã®å¯èƒ½æ€§ãŒé«˜ã„',
                'feasibility': 'low'
            })
        else:
            alternatives.append({
                'reason': reason,
                'files': files,
                'method': 'ã‚«ã‚¹ã‚¿ãƒ YOLOè¨“ç·´',
                'description': 'æ¼«ç”»ç‰¹åŒ–YOLOãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãŒå¿…è¦',
                'feasibility': 'low'
            })
    
    return alternatives

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ” kaname04å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«ä»£æ›¿åˆ†æé–‹å§‹")
    print("=" * 60)
    
    # å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
    analysis_results = analyze_failed_files()
    
    # ä»£æ›¿æ‰‹æ³•ææ¡ˆ
    alternatives = suggest_alternatives(analysis_results)
    
    # çµæœä¿å­˜
    output_data = {
        'analysis_timestamp': '2025-07-12T13:30:00',
        'total_failed_files': len(analysis_results),
        'analysis_results': analysis_results,
        'alternative_methods': alternatives,
        'final_recommendation': {
            'current_success_rate': '53.6% (15/28)',
            'technical_limitation': 'YOLO+SAMæ‰‹æ³•ã§ã¯æ®‹ã‚Š13ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã¯å›°é›£',
            'recommendation': 'ç¾åœ¨ã®15ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ¸ˆã¿ã§ååˆ†ãªæˆæœã¨ã¿ãªã™',
            'next_steps': [
                'å‡¦ç†æ¸ˆã¿15ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®å­¦ç¿’ç¶™ç¶š',
                'å¿…è¦ã«å¿œã˜ã¦æ‰‹å‹•ã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é ˜åŸŸæŒ‡å®š',
                'å°†æ¥çš„ã«ã¯æ¼«ç”»ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨'
            ]
        }
    }
    
    with open('kaname04_alternative_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“Š åˆ†æå®Œäº†:")
    print(f"   å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(analysis_results)}")
    print(f"   ä»£æ›¿æ‰‹æ³•å€™è£œæ•°: {len(alternatives)}")
    print(f"   åˆ†æçµæœä¿å­˜: kaname04_alternative_analysis.json")
    
    # æœ€çµ‚çµè«–
    print("\nğŸ¯ æœ€çµ‚çµè«–:")
    print("   ç¾åœ¨ã®53.6%æˆåŠŸç‡ã¯æŠ€è¡“çš„é™ç•Œã«è¿‘ã„")
    print("   æ®‹ã‚Š13ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®å•é¡Œ:")
    print("   - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸åœ¨")
    print("   - æ¥µç«¯ãªèƒŒæ™¯ï¼ˆç™½èƒŒæ™¯ãƒ»è¤‡é›‘èƒŒæ™¯ï¼‰")
    print("   - YOLOãƒ¢ãƒ‡ãƒ«ã®æ¼«ç”»å¯¾å¿œé™ç•Œ")
    print("   - ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸéå¤š")
    
    return output_data

if __name__ == "__main__":
    result = main()