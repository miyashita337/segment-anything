#!/usr/bin/env python3
"""
Character Extraction Command
Main command for extracting characters from manga images using SAM + YOLO
"""

import os
import sys
import argparse
import time
from pathlib import Path
from typing import Optional, Dict, Any, List

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

import cv2
import numpy as np

from hooks.start import get_sam_model, get_yolo_model, get_performance_monitor
from utils.preprocessing import preprocess_image_pipeline
from utils.postprocessing import (
    enhance_character_mask, 
    extract_character_from_image, 
    crop_to_content,
    save_character_result,
    calculate_mask_quality_metrics
)
from utils.text_detection import TextDetector


def extract_character_from_path(image_path: str,
                               output_path: Optional[str] = None,
                               enhance_contrast: bool = False,
                               filter_text: bool = True,
                               save_mask: bool = True,
                               save_transparent: bool = True,
                               min_yolo_score: float = 0.1,
                               verbose: bool = True) -> Dict[str, Any]:
    """
    ç”»åƒãƒ‘ã‚¹ã‹ã‚‰ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’æŠ½å‡º
    
    Args:
        image_path: å…¥åŠ›ç”»åƒãƒ‘ã‚¹
        output_path: å‡ºåŠ›ãƒ‘ã‚¹ï¼ˆNone ã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
        enhance_contrast: ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–
        filter_text: ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        save_mask: ãƒã‚¹ã‚¯ã‚’ä¿å­˜
        save_transparent: é€æ˜èƒŒæ™¯ç‰ˆã‚’ä¿å­˜
        min_yolo_score: YOLOæœ€å°ã‚¹ã‚³ã‚¢
        verbose: è©³ç´°å‡ºåŠ›
        
    Returns:
        æŠ½å‡ºçµæœã®è¾æ›¸
    """
    result = {
        'success': False,
        'input_path': image_path,
        'output_path': None,
        'processing_time': 0.0,
        'mask_quality': {},
        'error': None
    }
    
    start_time = time.time()
    
    try:
        # Get models
        sam_model = get_sam_model()
        yolo_model = get_yolo_model()
        performance_monitor = get_performance_monitor()
        
        if not sam_model or not yolo_model:
            raise RuntimeError("Models not initialized. Run start hook first.")
        
        if verbose:
            print(f"ğŸ¯ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡ºé–‹å§‹: {image_path}")
        
        # Step 1: Image preprocessing
        performance_monitor.start_stage("Image Preprocessing")
        bgr_image, rgb_image, scale = preprocess_image_pipeline(
            image_path, 
            enhance_contrast=enhance_contrast
        )
        
        if rgb_image is None:
            raise ValueError(f"Failed to load image: {image_path}")
        
        performance_monitor.end_stage()
        
        # Step 2: SAM mask generation
        performance_monitor.start_stage("SAM Mask Generation")
        all_masks = sam_model.generate_masks(rgb_image)
        
        if not all_masks:
            raise ValueError("No masks generated by SAM")
        
        character_masks = sam_model.filter_character_masks(all_masks)
        
        if verbose:
            print(f"ğŸ“Š ç”Ÿæˆãƒã‚¹ã‚¯: {len(all_masks)} â†’ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å€™è£œ: {len(character_masks)}")
        
        performance_monitor.end_stage()
        
        # Step 3: YOLO scoring
        performance_monitor.start_stage("YOLO Scoring")
        scored_masks = yolo_model.score_masks_with_detections(character_masks, bgr_image)
        
        best_mask = yolo_model.get_best_character_mask(
            scored_masks, 
            bgr_image, 
            min_yolo_score=min_yolo_score
        )
        
        if best_mask is None:
            raise ValueError(f"No good character masks found (min YOLO score: {min_yolo_score})")
        
        if verbose:
            print(f"ğŸ¯ æœ€é©ãƒã‚¹ã‚¯é¸æŠ: YOLO score={best_mask['yolo_score']:.3f}, "
                  f"combined score={best_mask['combined_score']:.3f}")
        
        performance_monitor.end_stage()
        
        # Step 4: Text filtering (optional)
        if filter_text:
            performance_monitor.start_stage("Text Filtering")
            text_detector = TextDetector(use_easyocr=True)
            
            text_density = text_detector.calculate_text_density_score(
                bgr_image, 
                best_mask['bbox']
            )
            
            if text_density > 0.5:
                if verbose:
                    print(f"âš ï¸ é«˜ãƒ†ã‚­ã‚¹ãƒˆå¯†åº¦æ¤œå‡º: {text_density:.3f} - å‡¦ç†ç¶šè¡Œ")
            
            # Add text density to result
            best_mask['text_density'] = text_density
            performance_monitor.end_stage()
        
        # Step 5: Mask refinement
        performance_monitor.start_stage("Mask Refinement")
        raw_mask = sam_model.mask_to_binary(best_mask)
        enhanced_mask = enhance_character_mask(
            raw_mask,
            remove_small_area=100,
            smooth_kernel=3,
            fill_holes=True
        )
        
        # Calculate mask quality metrics
        quality_metrics = calculate_mask_quality_metrics(enhanced_mask)
        result['mask_quality'] = quality_metrics
        
        if verbose:
            print(f"ğŸ“ ãƒã‚¹ã‚¯å“è³ª: coverage={quality_metrics['coverage_ratio']:.3f}, "
                  f"compactness={quality_metrics['compactness']:.3f}")
        
        performance_monitor.end_stage()
        
        # Step 6: Character extraction
        performance_monitor.start_stage("Character Extraction")
        character_image = extract_character_from_image(
            bgr_image, 
            enhanced_mask,
            background_color=(0, 0, 0)  # Black background
        )
        
        # Crop to content
        cropped_character, cropped_mask, crop_bbox = crop_to_content(
            character_image,
            enhanced_mask,
            padding=10
        )
        
        performance_monitor.end_stage()
        
        # Step 7: Save results
        performance_monitor.start_stage("Saving Results")
        
        # Generate output path if not provided
        if output_path is None:
            input_path = Path(image_path)
            output_dir = input_path.parent / "character_output"
            output_dir.mkdir(exist_ok=True)
            output_path = output_dir / input_path.stem
        
        # Save results
        save_success = save_character_result(
            cropped_character,
            cropped_mask,
            str(output_path),
            save_mask=save_mask,
            save_transparent=save_transparent
        )
        
        if not save_success:
            raise RuntimeError("Failed to save results")
        
        result['output_path'] = str(output_path)
        performance_monitor.end_stage()
        
        # Success
        result['success'] = True
        result['processing_time'] = time.time() - start_time
        
        if verbose:
            print(f"âœ… ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡ºå®Œäº†: {result['processing_time']:.2f}ç§’")
            print(f"   å‡ºåŠ›: {result['output_path']}")
        
        return result
        
    except Exception as e:
        result['error'] = str(e)
        result['processing_time'] = time.time() - start_time
        
        if verbose:
            print(f"âŒ æŠ½å‡ºå¤±æ•—: {e}")
        
        return result


def batch_extract_characters(input_dir: str,
                           output_dir: str,
                           **extract_kwargs) -> Dict[str, Any]:
    """
    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ç”»åƒã«å¯¾ã—ã¦ãƒãƒƒãƒå‡¦ç†
    
    Args:
        input_dir: å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        **extract_kwargs: extract_character_from_path ã®å¼•æ•°
        
    Returns:
        ãƒãƒƒãƒå‡¦ç†çµæœ
    """
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    if not input_path.exists():
        return {'success': False, 'error': f'Input directory not found: {input_dir}'}
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
    image_files = []
    
    for ext in image_extensions:
        image_files.extend(input_path.glob(f'*{ext}'))
        image_files.extend(input_path.glob(f'*{ext.upper()}'))
    
    if not image_files:
        return {'success': False, 'error': f'No image files found in {input_dir}'}
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_path.mkdir(parents=True, exist_ok=True)
    
    # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
    results = []
    successful = 0
    
    print(f"ğŸš€ ãƒãƒƒãƒå‡¦ç†é–‹å§‹: {len(image_files)} ç”»åƒ")
    
    for i, image_file in enumerate(image_files, 1):
        print(f"\nğŸ“ å‡¦ç†ä¸­ [{i}/{len(image_files)}]: {image_file.name}")
        
        # å‡ºåŠ›ãƒ‘ã‚¹ç”Ÿæˆ
        output_file = output_path / image_file.stem
        
        # æŠ½å‡ºå®Ÿè¡Œ
        result = extract_character_from_path(
            str(image_file),
            output_path=str(output_file),
            verbose=False,  # ãƒãƒƒãƒå‡¦ç†ã§ã¯è©³ç´°å‡ºåŠ›ã‚’æŠ‘åˆ¶
            **extract_kwargs
        )
        
        result['filename'] = image_file.name
        results.append(result)
        
        if result['success']:
            successful += 1
            print(f"âœ… æˆåŠŸ: {image_file.name}")
        else:
            print(f"âŒ å¤±æ•—: {image_file.name} - {result['error']}")
    
    # çµæœã‚µãƒãƒª
    batch_result = {
        'success': True,
        'total_files': len(image_files),
        'successful': successful,
        'failed': len(image_files) - successful,
        'success_rate': successful / len(image_files),
        'results': results
    }
    
    print(f"\nğŸ“Š ãƒãƒƒãƒå‡¦ç†å®Œäº†:")
    print(f"   æˆåŠŸ: {successful}/{len(image_files)} ({batch_result['success_rate']:.1%})")
    
    return batch_result


def main():
    """Main function for command line interface"""
    parser = argparse.ArgumentParser(description="Character Extraction using SAM + YOLO")
    
    parser.add_argument('input', help='Input image path or directory')
    parser.add_argument('-o', '--output', help='Output path (auto-generated if not specified)')
    parser.add_argument('--batch', action='store_true', help='Batch processing mode')
    parser.add_argument('--enhance-contrast', action='store_true', help='Enhance image contrast')
    parser.add_argument('--filter-text', action='store_true', default=True, help='Filter text regions')
    parser.add_argument('--save-mask', action='store_true', default=True, help='Save mask files')
    parser.add_argument('--save-transparent', action='store_true', default=True, help='Save transparent background')
    parser.add_argument('--min-yolo-score', type=float, default=0.1, help='Minimum YOLO score threshold')
    parser.add_argument('--verbose', action='store_true', default=True, help='Verbose output')
    
    args = parser.parse_args()
    
    # Extract common arguments
    extract_args = {
        'enhance_contrast': args.enhance_contrast,
        'filter_text': args.filter_text,
        'save_mask': args.save_mask,
        'save_transparent': args.save_transparent,
        'min_yolo_score': args.min_yolo_score,
        'verbose': args.verbose
    }
    
    if args.batch:
        # Batch processing
        output_dir = args.output or f"{args.input}_character_output"
        result = batch_extract_characters(args.input, output_dir, **extract_args)
    else:
        # Single file processing
        result = extract_character_from_path(args.input, args.output, **extract_args)
    
    # Exit with appropriate code
    sys.exit(0 if result['success'] else 1)


if __name__ == "__main__":
    main()