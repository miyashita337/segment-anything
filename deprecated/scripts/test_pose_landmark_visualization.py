#!/usr/bin/env python3
"""
ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å¯è¦–åŒ–ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆWeek 2ï¼‰
MediaPipe ãƒãƒ¼ã‚ºãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ãƒœãƒ¼ãƒ³æç”»ã¨å§¿å‹¢åˆ†æ
"""

import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

import numpy as np
import cv2

from features.evaluation.enhanced_detection_systems import EnhancedPoseDetector, PoseDetectionResult

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class PoseLandmarkVisualizer:
    """ãƒãƒ¼ã‚ºãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.PoseLandmarkVisualizer")
        self.pose_detector = EnhancedPoseDetector()
        
        # MediaPipe ãƒãƒ¼ã‚ºãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¥ç¶šå®šç¾©ï¼ˆ33ç‚¹ï¼‰
        self.pose_connections = [
            # é¡”è¼ªéƒ­
            (0, 1), (1, 2), (2, 3), (3, 7),
            (0, 4), (4, 5), (5, 6), (6, 8),
            # ä¸ŠåŠèº«
            (9, 10),  # å£
            (11, 12), # è‚©
            (11, 13), (13, 15),  # å·¦è…•
            (12, 14), (14, 16),  # å³è…•
            (11, 23), (12, 24),  # è‚©ã‹ã‚‰è…°
            (23, 24), # è…°
            # ä¸‹åŠèº«
            (23, 25), (25, 27), (27, 29), (27, 31),  # å·¦è„š
            (24, 26), (26, 28), (28, 30), (28, 32),  # å³è„š
        ]
        
        # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåç§°å®šç¾©
        self.keypoint_names = {
            0: 'nose', 1: 'left_eye_inner', 2: 'left_eye', 3: 'left_eye_outer',
            4: 'right_eye_inner', 5: 'right_eye', 6: 'right_eye_outer',
            7: 'left_ear', 8: 'right_ear', 9: 'mouth_left', 10: 'mouth_right',
            11: 'left_shoulder', 12: 'right_shoulder', 13: 'left_elbow', 14: 'right_elbow',
            15: 'left_wrist', 16: 'right_wrist', 17: 'left_pinky', 18: 'right_pinky',
            19: 'left_index', 20: 'right_index', 21: 'left_thumb', 22: 'right_thumb',
            23: 'left_hip', 24: 'right_hip', 25: 'left_knee', 26: 'right_knee',
            27: 'left_ankle', 28: 'right_ankle', 29: 'left_heel', 30: 'right_heel',
            31: 'left_foot_index', 32: 'right_foot_index'
        }
        
        # Week 2æœ€é©åŒ–: éƒ¨åˆ†é‡è¦åº¦è‰²åˆ†ã‘
        self.keypoint_colors = {
            # ä¸ŠåŠèº«ï¼ˆé‡è¦ï¼‰: èµ¤ç³»
            11: (0, 0, 255), 12: (0, 0, 255),  # è‚©
            13: (0, 50, 255), 14: (0, 50, 255),  # è‚˜
            15: (0, 100, 255), 16: (0, 100, 255),  # æ‰‹é¦–
            # é ­éƒ¨ï¼ˆé‡è¦ï¼‰: é’ç³»
            0: (255, 0, 0), 1: (255, 50, 0), 2: (255, 100, 0), 3: (255, 150, 0),
            4: (255, 150, 0), 5: (255, 100, 0), 6: (255, 50, 0), 7: (255, 0, 50), 8: (255, 0, 50),
            9: (200, 0, 100), 10: (200, 0, 100),
            # ä¸‹åŠèº«ï¼ˆè£œåŠ©ï¼‰: ç·‘ç³»
            23: (0, 255, 0), 24: (0, 255, 0),  # è…°
            25: (0, 200, 50), 26: (0, 200, 50),  # è†
            27: (0, 150, 100), 28: (0, 150, 100),  # è¶³é¦–
        }
    
    def visualize_pose_landmarks(self, image: np.ndarray, pose_result: PoseDetectionResult) -> np.ndarray:
        """ãƒãƒ¼ã‚ºãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®å¯è¦–åŒ–"""
        if not pose_result.detected or not pose_result.landmarks:
            return self._draw_no_detection_message(image)
        
        # ç”»åƒã‚’ã‚³ãƒ”ãƒ¼
        output_image = image.copy()
        height, width = output_image.shape[:2]
        
        # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ã‚’ç”»åƒåº§æ¨™ã«å¤‰æ›
        landmark_points = []
        for i, landmark in enumerate(pose_result.landmarks.landmark):
            x = int(landmark.x * width)
            y = int(landmark.y * height)
            visibility = landmark.visibility
            landmark_points.append((x, y, visibility))
        
        # ãƒœãƒ¼ãƒ³ï¼ˆæ¥ç¶šç·šï¼‰ã‚’æç”»
        self._draw_pose_connections(output_image, landmark_points)
        
        # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æç”»
        self._draw_keypoints(output_image, landmark_points)
        
        # åˆ†ææƒ…å ±ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
        self._draw_analysis_overlay(output_image, pose_result)
        
        return output_image
    
    def _draw_pose_connections(self, image: np.ndarray, landmark_points: List[Tuple[int, int, float]]):
        """ãƒãƒ¼ã‚ºæ¥ç¶šç·šã®æç”»"""
        for connection in self.pose_connections:
            start_idx, end_idx = connection
            
            if start_idx < len(landmark_points) and end_idx < len(landmark_points):
                start_point = landmark_points[start_idx]
                end_point = landmark_points[end_idx]
                
                # ä¸¡ç«¯ç‚¹ã®å¯è¦–æ€§ãƒã‚§ãƒƒã‚¯
                if start_point[2] > 0.2 and end_point[2] > 0.2:  # Week 2æœ€é©åŒ–: ç·©å’Œã•ã‚ŒãŸé–¾å€¤
                    # å¯è¦–æ€§ã«å¿œã˜ãŸç·šã®å¤ªã•ã¨é€æ˜åº¦
                    visibility = min(start_point[2], end_point[2])
                    thickness = max(1, int(visibility * 4))
                    
                    # ç·šã®è‰²ï¼ˆæ¥ç¶šã®ç¨®é¡ã«ã‚ˆã‚‹ï¼‰
                    if start_idx in [11, 12, 13, 14, 15, 16] or end_idx in [11, 12, 13, 14, 15, 16]:
                        color = (0, 0, 255)  # ä¸ŠåŠèº«: èµ¤
                    elif start_idx in range(11) or end_idx in range(11):
                        color = (255, 0, 0)  # é ­éƒ¨: é’
                    else:
                        color = (0, 255, 0)  # ä¸‹åŠèº«: ç·‘
                    
                    cv2.line(image, (start_point[0], start_point[1]), 
                            (end_point[0], end_point[1]), color, thickness)
    
    def _draw_keypoints(self, image: np.ndarray, landmark_points: List[Tuple[int, int, float]]):
        """ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®æç”»"""
        for i, (x, y, visibility) in enumerate(landmark_points):
            if visibility > 0.2:  # Week 2æœ€é©åŒ–: ç·©å’Œã•ã‚ŒãŸé–¾å€¤
                # å¯è¦–æ€§ã«å¿œã˜ãŸå††ã®ã‚µã‚¤ã‚º
                radius = max(2, int(visibility * 8))
                
                # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ¥ã®è‰²
                color = self.keypoint_colors.get(i, (128, 128, 128))
                
                # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»
                cv2.circle(image, (x, y), radius, color, -1)
                
                # Week 2æœ€é©åŒ–: é‡è¦ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã«ãƒ©ãƒ™ãƒ«è¡¨ç¤º
                if i in [11, 12, 13, 14, 15, 16]:  # ä¸ŠåŠèº«ä¸»è¦éƒ¨ä½
                    keypoint_name = self.keypoint_names.get(i, f"point_{i}")
                    cv2.putText(image, keypoint_name[:4], (x + 5, y - 5), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)
    
    def _draw_analysis_overlay(self, image: np.ndarray, pose_result: PoseDetectionResult):
        """åˆ†ææƒ…å ±ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤"""
        height, width = image.shape[:2]
        
        # èƒŒæ™¯çŸ©å½¢
        overlay_height = 180
        cv2.rectangle(image, (10, 10), (width - 10, overlay_height), (0, 0, 0), -1)
        cv2.rectangle(image, (10, 10), (width - 10, overlay_height), (255, 255, 255), 2)
        
        # åˆ†æçµæœãƒ†ã‚­ã‚¹ãƒˆ
        texts = [
            f"Pose Category: {pose_result.pose_category}",
            f"Keypoints Detected: {pose_result.keypoints_detected}/33",
            f"Visibility Score: {pose_result.visibility_score:.3f}",
            f"Completeness Score: {pose_result.completeness_score:.3f}",
            f"Confidence: {pose_result.confidence:.3f}",
            f"Detection Status: {'SUCCESS' if pose_result.detected else 'FAILED'}"
        ]
        
        for i, text in enumerate(texts):
            y_pos = 30 + i * 25
            color = (0, 255, 0) if pose_result.detected else (0, 0, 255)
            cv2.putText(image, text, (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
    
    def _draw_no_detection_message(self, image: np.ndarray) -> np.ndarray:
        """æ¤œå‡ºå¤±æ•—æ™‚ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æç”»"""
        output_image = image.copy()
        height, width = output_image.shape[:2]
        
        # èµ¤ã„èƒŒæ™¯çŸ©å½¢
        cv2.rectangle(output_image, (10, 10), (width - 10, 100), (0, 0, 255), -1)
        cv2.rectangle(output_image, (10, 10), (width - 10, 100), (255, 255, 255), 2)
        
        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        cv2.putText(output_image, "NO POSE DETECTED", (20, 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        cv2.putText(output_image, "Week 2 Optimization Needed", (20, 70), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return output_image


class PoseLandmarkVisualizationTest:
    """ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å¯è¦–åŒ–ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.visualizer = PoseLandmarkVisualizer()
        self.pose_detector = EnhancedPoseDetector()
        self.test_datasets = {
            "kana05": "/mnt/c/AItools/lora/train/yado/org/kana05_cursor_fix",
            "kana07": "/mnt/c/AItools/lora/train/yado/org/kana07_cursor_fix", 
            "kana08": "/mnt/c/AItools/lora/train/yado/org/kana08_cursor_fix"
        }
    
    def run_visualization_test(self, output_dir: str = "pose_analysis") -> Dict:
        """ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å¯è¦–åŒ–ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        logger.info("ğŸ¨ ãƒãƒ¼ã‚ºãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å¯è¦–åŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(output_dir, exist_ok=True)
        
        all_results = {}
        total_images = 0
        total_poses_detected = 0
        detection_details = []
        
        for dataset_name, dataset_path in self.test_datasets.items():
            if not os.path.exists(dataset_path):
                logger.warning(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæœªç™ºè¦‹: {dataset_path}")
                continue
            
            logger.info(f"ğŸ“‚ å¯è¦–åŒ–ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ: {dataset_name}")
            dataset_results = self.test_dataset_visualization(dataset_path, dataset_name, output_dir)
            all_results[dataset_name] = dataset_results
            
            total_images += dataset_results['image_count']
            total_poses_detected += dataset_results['poses_detected']
            detection_details.extend(dataset_results['detection_details'])
        
        # ç·åˆçµ±è¨ˆè¨ˆç®—
        overall_stats = {
            'total_images_processed': total_images,
            'total_poses_detected': total_poses_detected,
            'overall_pose_detection_rate': total_poses_detected / total_images if total_images > 0 else 0.0,
            'week2_target_achievement': total_poses_detected / total_images >= 0.8 if total_images > 0 else False,
            'detection_details': detection_details
        }
        
        # Week 2æœ€é©åŒ–åŠ¹æœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_week2_optimization_report(all_results, overall_stats, output_dir)
        
        return {
            'dataset_results': all_results,
            'overall_statistics': overall_stats,
            'test_completion_time': datetime.now().isoformat(),
            'output_directory': output_dir
        }
    
    def test_dataset_visualization(self, dataset_path: str, dataset_name: str, output_dir: str) -> Dict:
        """å˜ä¸€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¯è¦–åŒ–ãƒ†ã‚¹ãƒˆ"""
        image_files = [f for f in os.listdir(dataset_path) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png')) 
                      and not f.endswith('_gt.png')]
        
        results = {
            'dataset_name': dataset_name,
            'image_count': len(image_files),
            'poses_detected': 0,
            'detection_details': [],
            'visualization_files': []
        }
        
        dataset_output_dir = os.path.join(output_dir, dataset_name)
        os.makedirs(dataset_output_dir, exist_ok=True)
        
        for image_file in image_files:
            image_path = os.path.join(dataset_path, image_file)
            
            try:
                # ç”»åƒèª­ã¿è¾¼ã¿
                image = cv2.imread(image_path)
                if image is None:
                    continue
                
                # Week 2æœ€é©åŒ–ãƒãƒ¼ã‚ºæ¤œå‡ºå®Ÿè¡Œï¼ˆåŠ¹ç‡ãƒ¢ãƒ¼ãƒ‰ï¼‰
                pose_result = self.pose_detector.detect_pose_comprehensive(image, efficient_mode=True)
                
                # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å¯è¦–åŒ–
                visualization_image = self.visualizer.visualize_pose_landmarks(image, pose_result)
                
                # çµæœä¿å­˜
                base_name = os.path.splitext(image_file)[0]
                output_filename = f"{base_name}_pose_analysis.jpg"
                output_path = os.path.join(dataset_output_dir, output_filename)
                cv2.imwrite(output_path, visualization_image)
                
                # çµ±è¨ˆè¨˜éŒ²
                if pose_result.detected:
                    results['poses_detected'] += 1
                
                detection_detail = {
                    'image_file': image_file,
                    'detected': pose_result.detected,
                    'pose_category': pose_result.pose_category,
                    'keypoints_detected': pose_result.keypoints_detected,
                    'visibility_score': pose_result.visibility_score,
                    'completeness_score': pose_result.completeness_score,
                    'confidence': pose_result.confidence,
                    'output_file': output_filename
                }
                
                results['detection_details'].append(detection_detail)
                results['visualization_files'].append(output_path)
                
                logger.debug(f"  {image_file}: {'SUCCESS' if pose_result.detected else 'FAILED'} "
                           f"({pose_result.keypoints_detected} keypoints)")
            
            except Exception as e:
                logger.error(f"å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼ {image_file}: {e}")
        
        return results
    
    def generate_week2_optimization_report(self, all_results: Dict, overall_stats: Dict, output_dir: str):
        """Week 2æœ€é©åŒ–åŠ¹æœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        
        print("\n" + "=" * 80)
        print("ğŸ¨ Week 2 ãƒãƒ¼ã‚ºãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å¯è¦–åŒ–ãƒ†ã‚¹ãƒˆçµæœ")
        print("=" * 80)
        
        print(f"\nğŸ“Š ç·åˆçµ±è¨ˆ:")
        print(f"  å‡¦ç†ç”»åƒæ•°: {overall_stats['total_images_processed']}æš")
        print(f"  ãƒãƒ¼ã‚ºæ¤œå‡ºæ•°: {overall_stats['total_poses_detected']}ä»¶")
        print(f"  æ¤œå‡ºç‡: {overall_stats['overall_pose_detection_rate']:.1%}")
        print(f"  Week 2ç›®æ¨™é”æˆ: {'âœ… YES' if overall_stats['week2_target_achievement'] else 'âŒ NO'} (ç›®æ¨™80%)")
        
        print(f"\nğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥è©³ç´°:")
        for dataset_name, results in all_results.items():
            detection_rate = (results['poses_detected'] / results['image_count']) if results['image_count'] > 0 else 0
            
            print(f"  {dataset_name}:")
            print(f"    ç”»åƒæ•°: {results['image_count']}æš")
            print(f"    ãƒãƒ¼ã‚ºæ¤œå‡ºæ•°: {results['poses_detected']}ä»¶")
            print(f"    æ¤œå‡ºç‡: {detection_rate:.1%}")
            print(f"    å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«: {len(results['visualization_files'])}ä»¶ç”Ÿæˆ")
        
        # Week 2æœ€é©åŒ–åŠ¹æœåˆ†æ
        detection_categories = {}
        keypoint_stats = {'min': 33, 'max': 0, 'total': 0, 'count': 0}
        
        for detail in overall_stats['detection_details']:
            if detail['detected']:
                category = detail['pose_category']
                if category not in detection_categories:
                    detection_categories[category] = 0
                detection_categories[category] += 1
                
                keypoints = detail['keypoints_detected']
                keypoint_stats['min'] = min(keypoint_stats['min'], keypoints)
                keypoint_stats['max'] = max(keypoint_stats['max'], keypoints)
                keypoint_stats['total'] += keypoints
                keypoint_stats['count'] += 1
        
        print(f"\nğŸ¯ Week 2æœ€é©åŒ–åŠ¹æœ:")
        print(f"  æ–°ãƒãƒ¼ã‚ºã‚«ãƒ†ã‚´ãƒªæ¤œå‡º:")
        for category, count in detection_categories.items():
            emoji = "ğŸ†•" if category in ['partial_pose', 'upper_body_only'] else "âœ…"
            print(f"    {emoji} {category}: {count}ä»¶")
        
        if keypoint_stats['count'] > 0:
            avg_keypoints = keypoint_stats['total'] / keypoint_stats['count']
            print(f"  ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆçµ±è¨ˆ:")
            print(f"    å¹³å‡æ¤œå‡ºæ•°: {avg_keypoints:.1f}ç‚¹")
            print(f"    æœ€å°æ¤œå‡ºæ•°: {keypoint_stats['min']}ç‚¹ï¼ˆWeek 2ç›®æ¨™: 3ç‚¹ä»¥ä¸Šï¼‰")
            print(f"    æœ€å¤§æ¤œå‡ºæ•°: {keypoint_stats['max']}ç‚¹")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæƒ…å ±
        print(f"\nğŸ’¾ å¯è¦–åŒ–çµæœ:")
        print(f"  å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}/")
        print(f"  ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {sum(len(r['visualization_files']) for r in all_results.values())}ä»¶")
        
        target_rate = 0.80
        current_rate = overall_stats['overall_pose_detection_rate']
        
        if current_rate >= target_rate:
            print(f"\nğŸ‰ Week 2ç›®æ¨™é”æˆ! ãƒãƒ¼ã‚ºæ¤œå‡ºç‡{current_rate:.1%} >= ç›®æ¨™80%")
        else:
            improvement_needed = target_rate - current_rate
            print(f"\nğŸ“‹ è¿½åŠ æ”¹å–„å¿…è¦: ã‚ã¨{improvement_needed:+.1%}ã®å‘ä¸ŠãŒå¿…è¦")
        
        print("\n" + "=" * 80)
        
        # JSONå½¢å¼ã§ã‚‚ä¿å­˜
        report_data = {
            'overall_statistics': overall_stats,
            'dataset_results': all_results,
            'optimization_analysis': {
                'detection_categories': detection_categories,
                'keypoint_statistics': keypoint_stats,
                'week2_target_achievement': overall_stats['week2_target_achievement']
            }
        }
        
        report_file = os.path.join(output_dir, f"week2_pose_optimization_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ãƒãƒ¼ã‚ºãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å¯è¦–åŒ–ãƒ†ã‚¹ãƒˆ")
    parser.add_argument("--output", "-o", default="pose_analysis", help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    
    args = parser.parse_args()
    
    print("ğŸ¨ Week 2 ãƒãƒ¼ã‚ºãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å¯è¦–åŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    try:
        tester = PoseLandmarkVisualizationTest()
        results = tester.run_visualization_test(args.output)
        
        print(f"\nâœ… Week 2 ãƒãƒ¼ã‚ºãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å¯è¦–åŒ–ãƒ†ã‚¹ãƒˆå®Œäº†")
        print(f"ğŸ’¾ çµæœä¿å­˜: {args.output}/")
        
        return 0
    
    except Exception as e:
        logger.error(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return 1


if __name__ == "__main__":
    exit(main())