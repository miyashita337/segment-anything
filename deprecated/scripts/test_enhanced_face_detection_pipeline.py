#!/usr/bin/env python3
"""
å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¼·åŒ–ãƒ†ã‚¹ãƒˆ
Week 1å®Œäº†ç¢ºèªï¼šã‚¢ãƒ‹ãƒ¡é¡”æ¤œå‡ºã®æ”¹å–„æ¤œè¨¼
"""

import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

import numpy as np
import cv2

from features.evaluation.anime_image_preprocessor import AnimeImagePreprocessor
from features.evaluation.enhanced_detection_systems import EnhancedFaceDetector, FaceDetection

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class FaceDetectionPipelineTest:
    """å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¼·åŒ–ãƒ†ã‚¹ãƒˆ"""
    
    def __init__(self):
        self.face_detector = EnhancedFaceDetector()
        self.preprocessor = AnimeImagePreprocessor()
        self.test_datasets = {
            "kana05": "/mnt/c/AItools/lora/train/yado/org/kana05_cursor_fix",
            "kana07": "/mnt/c/AItools/lora/train/yado/org/kana07_cursor_fix", 
            "kana08": "/mnt/c/AItools/lora/train/yado/org/kana08_cursor_fix"
        }
    
    def run_comprehensive_test(self) -> Dict:
        """åŒ…æ‹¬çš„å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ§ª å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¼·åŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        all_results = {}
        total_images = 0
        total_faces_detected = 0
        processing_times = []
        
        for dataset_name, dataset_path in self.test_datasets.items():
            if not os.path.exists(dataset_path):
                logger.warning(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæœªç™ºè¦‹: {dataset_path}")
                continue
            
            logger.info(f"ğŸ“‚ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ: {dataset_name}")
            dataset_results = self.test_dataset(dataset_path, dataset_name)
            all_results[dataset_name] = dataset_results
            
            # çµ±è¨ˆé›†è¨ˆ
            total_images += dataset_results['image_count']
            total_faces_detected += dataset_results['total_faces_detected']
            processing_times.extend(dataset_results['processing_times'])
        
        # ç·åˆçµ±è¨ˆè¨ˆç®—
        overall_stats = self.calculate_overall_statistics(
            all_results, total_images, total_faces_detected, processing_times
        )
        
        # çµæœãƒ¬ãƒãƒ¼ãƒˆ
        self.generate_improvement_report(all_results, overall_stats)
        
        return {
            'dataset_results': all_results,
            'overall_statistics': overall_stats,
            'test_completion_time': datetime.now().isoformat()
        }
    
    def test_dataset(self, dataset_path: str, dataset_name: str) -> Dict:
        """å˜ä¸€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ†ã‚¹ãƒˆ"""
        image_files = [f for f in os.listdir(dataset_path) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png')) 
                      and not f.endswith('_gt.png')]
        
        results = {
            'dataset_name': dataset_name,
            'image_count': len(image_files),
            'detection_results': [],
            'total_faces_detected': 0,
            'processing_times': [],
            'method_performance': {},
            'preprocessing_effectiveness': {}
        }
        
        method_counts = {}
        
        for image_file in image_files:
            image_path = os.path.join(dataset_path, image_file)
            
            try:
                # ç”»åƒèª­ã¿è¾¼ã¿
                image = cv2.imread(image_path)
                if image is None:
                    continue
                
                # å‰å‡¦ç†åŠ¹æœãƒ†ã‚¹ãƒˆ
                preprocessing_result = self.test_preprocessing_effectiveness(image)
                
                # é¡”æ¤œå‡ºå®Ÿè¡Œ
                start_time = datetime.now()
                face_detections = self.face_detector.detect_faces_comprehensive(image)
                processing_time = (datetime.now() - start_time).total_seconds()
                
                # çµæœè¨˜éŒ²
                detection_result = {
                    'image_file': image_file,
                    'faces_detected': len(face_detections),
                    'processing_time': processing_time,
                    'detections': [
                        {
                            'method': det.method,
                            'confidence': det.confidence,
                            'bbox': det.bbox
                        } for det in face_detections
                    ],
                    'preprocessing_stats': preprocessing_result
                }
                
                results['detection_results'].append(detection_result)
                results['total_faces_detected'] += len(face_detections)
                results['processing_times'].append(processing_time)
                
                # æ‰‹æ³•åˆ¥çµ±è¨ˆ
                for detection in face_detections:
                    method = detection.method
                    if method not in method_counts:
                        method_counts[method] = 0
                    method_counts[method] += 1
                
                logger.debug(f"  {image_file}: {len(face_detections)}ä»¶æ¤œå‡º ({processing_time:.2f}ç§’)")
            
            except Exception as e:
                logger.error(f"ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼ {image_file}: {e}")
        
        results['method_performance'] = method_counts
        return results
    
    def test_preprocessing_effectiveness(self, image: np.ndarray) -> Dict:
        """å‰å‡¦ç†åŠ¹æœæ¸¬å®š"""
        try:
            # å…ƒç”»åƒçµ±è¨ˆ
            original_brightness, needs_adjustment = self.preprocessor.detect_optimal_brightness(image)
            
            # å‰å‡¦ç†å®Ÿè¡Œ
            enhanced_image = self.preprocessor.enhance_for_face_detection(image)
            
            # å‡¦ç†å¾Œçµ±è¨ˆ
            enhanced_brightness, _ = self.preprocessor.detect_optimal_brightness(enhanced_image)
            
            # ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰ˆç”Ÿæˆ
            multi_scale_versions = self.preprocessor.create_multi_scale_versions(enhanced_image)
            
            return {
                'original_brightness': float(original_brightness),
                'enhanced_brightness': float(enhanced_brightness),
                'brightness_improvement': float(enhanced_brightness - original_brightness),
                'adjustment_needed': bool(needs_adjustment),
                'multi_scale_count': len(multi_scale_versions)
            }
        
        except Exception as e:
            logger.warning(f"å‰å‡¦ç†åŠ¹æœæ¸¬å®šã‚¨ãƒ©ãƒ¼: {e}")
            return {'error': str(e)}
    
    def calculate_overall_statistics(self, all_results: Dict, total_images: int, 
                                   total_faces: int, processing_times: List[float]) -> Dict:
        """ç·åˆçµ±è¨ˆè¨ˆç®—"""
        
        # åŸºæœ¬çµ±è¨ˆ
        face_detection_rate = (total_faces / total_images) if total_images > 0 else 0.0
        avg_processing_time = sum(processing_times) / len(processing_times) if processing_times else 0.0
        
        # æ‰‹æ³•åˆ¥çµ±è¨ˆ
        all_methods = {}
        for dataset_results in all_results.values():
            for method, count in dataset_results['method_performance'].items():
                if method not in all_methods:
                    all_methods[method] = 0
                all_methods[method] += count
        
        # å‰å‡¦ç†åŠ¹æœçµ±è¨ˆ
        brightness_improvements = []
        for dataset_results in all_results.values():
            for detection_result in dataset_results['detection_results']:
                preprocessing_stats = detection_result.get('preprocessing_stats', {})
                improvement = preprocessing_stats.get('brightness_improvement', 0)
                if improvement != 0:
                    brightness_improvements.append(improvement)
        
        avg_brightness_improvement = (sum(brightness_improvements) / len(brightness_improvements) 
                                    if brightness_improvements else 0.0)
        
        return {
            'total_images_processed': total_images,
            'total_faces_detected': total_faces,
            'overall_face_detection_rate': face_detection_rate,
            'average_processing_time': avg_processing_time,
            'method_distribution': all_methods,
            'average_brightness_improvement': avg_brightness_improvement,
            'images_with_preprocessing': len(brightness_improvements)
        }
    
    def generate_improvement_report(self, all_results: Dict, overall_stats: Dict):
        """æ”¹å–„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        
        print("\n" + "=" * 80)
        print("ğŸ¨ å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¼·åŒ–ãƒ†ã‚¹ãƒˆçµæœ (Week 1å®Œäº†ç¢ºèª)")
        print("=" * 80)
        
        print(f"\nğŸ“Š ç·åˆçµ±è¨ˆ:")
        print(f"  å‡¦ç†ç”»åƒæ•°: {overall_stats['total_images_processed']}æš")
        print(f"  ç·æ¤œå‡ºæ•°: {overall_stats['total_faces_detected']}ä»¶")
        print(f"  æ¤œå‡ºç‡: {overall_stats['overall_face_detection_rate']:.1%}")
        print(f"  å¹³å‡å‡¦ç†æ™‚é–“: {overall_stats['average_processing_time']:.2f}ç§’/ç”»åƒ")
        print(f"  å¹³å‡æ˜åº¦æ”¹å–„: {overall_stats['average_brightness_improvement']:+.1f}")
        
        print(f"\nğŸ” æ¤œå‡ºæ‰‹æ³•åˆ†å¸ƒ:")
        for method, count in overall_stats['method_distribution'].items():
            percentage = (count / overall_stats['total_faces_detected']) * 100 if overall_stats['total_faces_detected'] > 0 else 0
            print(f"  {method}: {count}ä»¶ ({percentage:.1f}%)")
        
        print(f"\nğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥è©³ç´°:")
        for dataset_name, results in all_results.items():
            detection_rate = (results['total_faces_detected'] / results['image_count']) if results['image_count'] > 0 else 0
            avg_time = sum(results['processing_times']) / len(results['processing_times']) if results['processing_times'] else 0
            
            print(f"  {dataset_name}:")
            print(f"    ç”»åƒæ•°: {results['image_count']}æš")
            print(f"    æ¤œå‡ºæ•°: {results['total_faces_detected']}ä»¶")
            print(f"    æ¤œå‡ºç‡: {detection_rate:.1%}")
            print(f"    å¹³å‡å‡¦ç†æ™‚é–“: {avg_time:.2f}ç§’")
        
        # Week 1ç›®æ¨™é”æˆè©•ä¾¡
        print(f"\nğŸ¯ Week 1ç›®æ¨™é”æˆè©•ä¾¡:")
        
        # ã‚¢ãƒ‹ãƒ¡é¡”ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ä½¿ç”¨ç¢ºèª
        anime_methods = [m for m in overall_stats['method_distribution'].keys() if 'anime' in m]
        anime_detection_count = sum(overall_stats['method_distribution'].get(m, 0) for m in anime_methods)
        
        print(f"  âœ… ã‚¢ãƒ‹ãƒ¡é¡”å°‚ç”¨ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰: {len(anime_methods)}ç¨®é¡ã®æ‰‹æ³•ä½¿ç”¨")
        print(f"  âœ… ã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–æ¤œå‡º: {anime_detection_count}ä»¶æ¤œå‡º")
        print(f"  âœ… å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: {overall_stats['images_with_preprocessing']}æšã«é©ç”¨")
        print(f"  âœ… ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«æ¤œå‡º: çµ±åˆå®Œäº†")
        
        # æ”¹å–„åŠ¹æœåˆ†æ
        target_detection_rate = 0.90  # 90%ç›®æ¨™
        current_rate = overall_stats['overall_face_detection_rate']
        improvement_needed = target_detection_rate - current_rate
        
        print(f"\nğŸ“‹ æ¬¡é€±ã«å‘ã‘ãŸåˆ†æ:")
        print(f"  ç¾åœ¨ã®é¡”æ¤œå‡ºç‡: {current_rate:.1%}")
        print(f"  ç›®æ¨™æ¤œå‡ºç‡: {target_detection_rate:.1%}")
        print(f"  å¿…è¦æ”¹å–„: {improvement_needed:+.1%}")
        
        if current_rate >= target_detection_rate:
            print(f"  ğŸ‰ Week 1ã§90%ç›®æ¨™é”æˆ!")
        else:
            print(f"  ğŸ“‹ Week 2ã§è¿½åŠ æ”¹å–„ãŒå¿…è¦")
        
        print("\n" + "=" * 80)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ§ª å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¼·åŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    try:
        tester = FaceDetectionPipelineTest()
        results = tester.run_comprehensive_test()
        
        # çµæœã‚’JSONã§ä¿å­˜
        output_file = f"enhanced_face_detection_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è©³ç´°çµæœä¿å­˜: {output_file}")
        print("âœ… Week 1å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¼·åŒ–ãƒ†ã‚¹ãƒˆå®Œäº†")
        
        return 0
    
    except Exception as e:
        logger.error(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return 1


if __name__ == "__main__":
    exit(main())