#!/usr/bin/env python3
"""
è¦–è¦šçš„æ„å›³åˆ†æå™¨
äººé–“ãŒæœ¬å½“ã«æŒ‡å®šã—ãŸã‹ã£ãŸé ˜åŸŸ vs å®Ÿéš›ã®æŠ½å‡ºç”»åƒã®æ¯”è¼ƒ
"""

import numpy as np
import cv2
import matplotlib.patches as patches
import matplotlib.pyplot as plt

import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class VisualIntentAnalyzer:
    """è¦–è¦šçš„æ„å›³åˆ†æ"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.output_dir = project_root / "visual_intent_analysis"
        self.output_dir.mkdir(exist_ok=True)
    
    def analyze_kana07_0023(self):
        """kana07_0023ã®è©³ç´°è¦–è¦šåˆ†æ"""
        # ãƒ‘ã‚¹è¨­å®š
        original_path = self.project_root / "lora/train/yado/org/kana07_cursor/kana07_0023.jpg"
        extracted_path = self.project_root / "lora/train/yado/clipped_boundingbox/kana07/kana07_0023.jpg"
        
        # ç”»åƒèª­ã¿è¾¼ã¿
        original_img = cv2.imread(str(original_path))
        extracted_img = cv2.imread(str(extracted_path))
        
        if original_img is None or extracted_img is None:
            print("âŒ ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—")
            return
        
        # BGRâ†’RGBå¤‰æ›
        original_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)
        extracted_rgb = cv2.cvtColor(extracted_img, cv2.COLOR_BGR2RGB)
        
        # åº§æ¨™æƒ…å ±ï¼ˆå‰å›ã®ãƒ‡ãƒãƒƒã‚°ã‹ã‚‰ï¼‰
        human_bbox = [0, 504, 1364, 1608]  # x, y, w, h
        ai_bbox = [0, 505, 1362, 1606]
        
        # å¯è¦–åŒ–ä½œæˆ
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. ã‚ªãƒªã‚¸ãƒŠãƒ« + äººé–“ãƒ©ãƒ™ãƒ«
        ax1 = axes[0, 0] 
        ax1.imshow(original_rgb)
        hx, hy, hw, hh = human_bbox
        rect_human = patches.Rectangle((hx, hy), hw, hh, 
                                     linewidth=3, edgecolor='red', facecolor='none', alpha=0.7)
        ax1.add_patch(rect_human)
        ax1.set_title("ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒ + äººé–“ãƒ©ãƒ™ãƒ«ï¼ˆèµ¤æ ï¼‰", fontsize=12)
        ax1.axis('off')
        
        # 2. ã‚ªãƒªã‚¸ãƒŠãƒ« + AIæŠ½å‡ºé ˜åŸŸ
        ax2 = axes[0, 1]
        ax2.imshow(original_rgb)
        ax, ay, aw, ah = ai_bbox
        rect_ai = patches.Rectangle((ax, ay), aw, ah,
                                  linewidth=3, edgecolor='blue', facecolor='none', alpha=0.7)
        ax2.add_patch(rect_ai)
        ax2.set_title("ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒ + AIæŠ½å‡ºé ˜åŸŸï¼ˆé’æ ï¼‰", fontsize=12)
        ax2.axis('off')
        
        # 3. äººé–“ãƒ©ãƒ™ãƒ«é ˜åŸŸã®ã‚¯ãƒ­ãƒƒãƒ—
        ax3 = axes[1, 0]
        human_crop = original_rgb[hy:hy+hh, hx:hx+hw]
        ax3.imshow(human_crop)
        ax3.set_title(f"äººé–“ãƒ©ãƒ™ãƒ«é ˜åŸŸ\n({hw}x{hh})", fontsize=12)
        ax3.axis('off')
        
        # 4. å®Ÿéš›ã®æŠ½å‡ºç”»åƒ
        ax4 = axes[1, 1]
        ax4.imshow(extracted_rgb)
        ax4.set_title(f"å®Ÿéš›ã®æŠ½å‡ºç”»åƒ\n({extracted_rgb.shape[1]}x{extracted_rgb.shape[0]})", fontsize=12)
        ax4.axis('off')
        
        plt.tight_layout()
        
        # ä¿å­˜
        save_path = self.output_dir / "kana07_0023_visual_intent_analysis.png"
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“Š è¦–è¦šåˆ†æçµæœ:")
        print(f"äººé–“ãƒ©ãƒ™ãƒ«: {hw}x{hh} = {hw*hh:,}ãƒ”ã‚¯ã‚»ãƒ«")
        print(f"å®Ÿéš›æŠ½å‡º: {extracted_rgb.shape[1]}x{extracted_rgb.shape[0]} = {extracted_rgb.shape[1]*extracted_rgb.shape[0]:,}ãƒ”ã‚¯ã‚»ãƒ«")
        print(f"é¢ç©æ¯”: {(extracted_rgb.shape[1]*extracted_rgb.shape[0])/(hw*hh):.1%}")
        print(f"å¯è¦–åŒ–ä¿å­˜: {save_path}")
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä½ç½®åˆ†æ
        self.analyze_character_positions(original_rgb, human_bbox, extracted_rgb)
    
    def analyze_character_positions(self, original_img: np.ndarray, 
                                  human_bbox: list, extracted_img: np.ndarray):
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä½ç½®ã®åˆ†æ"""
        print(f"\nğŸ­ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä½ç½®åˆ†æ:")
        
        h, w = original_img.shape[:2]
        hx, hy, hw, hh = human_bbox
        
        # äººé–“ãƒ©ãƒ™ãƒ«é ˜åŸŸã®ç”»åƒå†…æ¯”ç‡
        label_coverage = (hw * hh) / (w * h)
        print(f"äººé–“ãƒ©ãƒ™ãƒ«ç¯„å›²: {label_coverage:.1%} (ç”»åƒå…¨ä½“ã«å¯¾ã™ã‚‹æ¯”ç‡)")
        
        # æŠ½å‡ºç”»åƒã®ä½ç½®æ¨å®šï¼ˆå®Ÿéš›ã®æŠ½å‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚ºã‹ã‚‰ï¼‰
        extracted_h, extracted_w = extracted_img.shape[:2]
        
        print(f"å®Ÿéš›æŠ½å‡ºã‚µã‚¤ã‚º: {extracted_w}x{extracted_h}")
        print(f"äººé–“ãƒ©ãƒ™ãƒ«ã‚µã‚¤ã‚º: {hw}x{hh}")
        
        # æŠ½å‡ºç”»åƒãŒäººé–“ãƒ©ãƒ™ãƒ«å†…ã®ã©ã®éƒ¨åˆ†ã‹ã‚’æ¨å®š
        if extracted_w < hw and extracted_h < hh:
            print("âš ï¸  å®Ÿéš›ã®æŠ½å‡ºã¯äººé–“ãƒ©ãƒ™ãƒ«å†…ã®ä¸€éƒ¨åˆ†ã®ã¿")
            
            # ä¸Šéƒ¨ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ¨å®š
            if extracted_h < hh * 0.5:
                print("ğŸ“ æ¨å®šä½ç½®: äººé–“ãƒ©ãƒ™ãƒ«é ˜åŸŸã®ä¸Šéƒ¨")
                print("ğŸ’¡ ã“ã‚ŒãŒã€Œå·¦ä¸‹ã‚’æŒ‡å®šã—ãŸãŒä¸Šéƒ¨ã‚’æŠ½å‡ºã€å•é¡Œã®è¨¼æ‹ ")
        
        # çµè«–
        print(f"\nğŸš¨ å•é¡Œã®æ§‹é€ :")
        print(f"1. äººé–“ã¯å·¦ä¸‹ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’æ„å›³")
        print(f"2. ã—ã‹ã—åºƒã„ç¯„å›²ï¼ˆ{label_coverage:.1%}ï¼‰ã‚’ãƒ©ãƒ™ãƒ«ä»˜ã‘")
        print(f"3. AIã¯åŒã˜åºƒã„ç¯„å›²å†…ã®ä¸Šéƒ¨ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’æŠ½å‡º")
        print(f"4. åº§æ¨™ã¯ä¸€è‡´ã™ã‚‹ãŒã€æ„å›³ã—ãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¯ç•°ãªã‚‹")
    
    def generate_analysis_report(self):
        """åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = """# è¦–è¦šçš„æ„å›³åˆ†æãƒ¬ãƒãƒ¼ãƒˆ - kana07_0023

## ğŸ” å•é¡Œã®è©³ç´°æ§‹é€ 

### åº§æ¨™æƒ…å ±
- **äººé–“ãƒ©ãƒ™ãƒ«**: (0, 504, 1364, 1608) - åºƒç¯„å›²æŒ‡å®š
- **AIæŠ½å‡ºé ˜åŸŸ**: (0, 505, 1362, 1606) - ã»ã¼åŒä¸€
- **IoU**: 0.997 - æ•°å€¤çš„ã«ã¯å®Œç’§

### å®Ÿéš›ã®å†…å®¹
- **äººé–“ãƒ©ãƒ™ãƒ«é ˜åŸŸ**: 1364Ã—1608 = 2,193,312ãƒ”ã‚¯ã‚»ãƒ«ï¼ˆç”»åƒã®76%ï¼‰
- **å®Ÿéš›ã®æŠ½å‡ºç”»åƒ**: 248Ã—264 = 65,472ãƒ”ã‚¯ã‚»ãƒ«ï¼ˆ3%ã®ã¿ï¼‰
- **æŠ½å‡ºä½ç½®**: äººé–“ãƒ©ãƒ™ãƒ«å†…ã®ä¸Šéƒ¨ï¼ˆç™½é«ªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ï¼‰

## ğŸš¨ æ ¹æœ¬å•é¡Œ

### 1. äººé–“ãƒ©ãƒ™ãƒ«ã®ç²—ã•
äººé–“ãŒå·¦ä¸‹ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’æ„å›³ã—ãŸãŒã€ç”»åƒã®å¤§éƒ¨åˆ†ã‚’å›²ã‚€ç²—ã„ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚’è¡Œã£ãŸã€‚

### 2. AIã®è§£é‡ˆå•é¡Œ  
AIã¯æ­£ç¢ºãªåº§æ¨™ç¯„å›²ã‚’ç‰¹å®šã—ãŸãŒã€ãã®ç¯„å›²å†…ã®ç•°ãªã‚‹ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ï¼ˆä¸Šéƒ¨ï¼‰ã‚’æŠ½å‡ºã—ãŸã€‚

### 3. è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã®ç›²ç‚¹
å¾“æ¥ã®IoUè©•ä¾¡ã¯åº§æ¨™ã®ä¸€è‡´ã®ã¿ã‚’ç¢ºèªã—ã€å®Ÿéš›ã®æŠ½å‡ºå†…å®¹ã‚’æ¤œè¨¼ã—ã¦ã„ãªã„ã€‚

## ğŸ’¡ è§£æ±ºç­–

### çŸ­æœŸå¯¾ç­–
1. **äººé–“ãƒ©ãƒ™ãƒ«ã®ç²¾å¯†åŒ–**: å€‹åˆ¥ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’æ­£ç¢ºã«ãƒ©ãƒ™ãƒªãƒ³ã‚°
2. **è¦–è¦šçš„æ¤œè¨¼**: æŠ½å‡ºçµæœã®å†…å®¹ç¢ºèªã‚’å¿…é ˆåŒ–

### é•·æœŸå¯¾ç­–  
1. **æ„å›³æ¨å®šAI**: äººé–“ã®è¦–è¦šçš„æ„å›³ã‚’ç†è§£ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
2. **ã‚³ãƒ³ãƒ†ã‚¯ã‚¹ãƒˆè©•ä¾¡**: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é–“ã®é–¢ä¿‚æ€§ã‚’è€ƒæ…®ã—ãŸè©•ä¾¡

---

ã“ã®äº‹ä¾‹ã¯ã€Œåº§æ¨™ä¸€è‡´â‰ å†…å®¹ä¸€è‡´ã€å•é¡Œã®å…¸å‹ä¾‹ã§ã‚ã‚Šã€
AIã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡ã«ãŠã„ã¦è¦–è¦šçš„æ¤œè¨¼ã®é‡è¦æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
"""
        
        report_path = self.output_dir / "visual_intent_analysis_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ğŸ“‹ åˆ†æãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    project_root = Path("/mnt/c/AItools")
    analyzer = VisualIntentAnalyzer(project_root)
    
    # kana07_0023ã®è©³ç´°åˆ†æ
    analyzer.analyze_kana07_0023()
    
    # åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    analyzer.generate_analysis_report()
    
    print(f"\nâœ… è¦–è¦šçš„æ„å›³åˆ†æå®Œäº†")
    print(f"kana07_0023å•é¡Œã®æ ¹æœ¬æ§‹é€ ã‚’è§£æ˜ã—ã¾ã—ãŸã€‚")


if __name__ == "__main__":
    main()