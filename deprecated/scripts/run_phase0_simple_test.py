#!/usr/bin/env python3
"""
Phase 0 ç°¡æ˜“ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®å‹•ä½œç¢ºèªã¨ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š
"""

import json
import logging
import sys
import time
from dataclasses import asdict
from pathlib import Path
from typing import Any, Dict, List

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã‚’è¿½åŠ 
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from features.common.progress_reporter import ProgressReporter
from features.common.project_tracker import ProjectTracker

logger = logging.getLogger(__name__)


def setup_logging():
    """ãƒ­ã‚®ãƒ³ã‚°è¨­å®š"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('phase0_simple_test.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )


def simulate_benchmark_results():
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
    import numpy as np

    # 101ãƒ•ã‚¡ã‚¤ãƒ«åˆ†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’ç”Ÿæˆ
    results = []
    
    # ç¾å®Ÿçš„ãªæ€§èƒ½ã‚’æ¨¡æ“¬ï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®æ¨å®šæ€§èƒ½ï¼‰
    success_rate = 0.35  # 35%ã®æˆåŠŸç‡ï¼ˆå³ã—ã‚ã®ç¾å®Ÿï¼‰
    
    for i in range(101):
        # æˆåŠŸ/å¤±æ•—ã®åˆ¤å®š
        is_success = np.random.random() < success_rate
        
        # IoUã‚¹ã‚³ã‚¢ç”Ÿæˆï¼ˆæˆåŠŸæ™‚ã¯é«˜ã‚ã€å¤±æ•—æ™‚ã¯ä½ã‚ï¼‰
        if is_success:
            iou_score = np.random.uniform(0.5, 0.9)  # æˆåŠŸæ™‚: 0.5-0.9
        else:
            iou_score = np.random.uniform(0.0, 0.5)  # å¤±æ•—æ™‚: 0.0-0.5
        
        # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
        confidence = np.random.uniform(0.1, 0.8)
        
        # å‡¦ç†æ™‚é–“ï¼ˆç¾å®Ÿçš„ãªç¯„å›²ï¼‰
        processing_time = np.random.uniform(4.0, 12.0)
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ•°
        character_count = np.random.randint(1, 6)
        
        # é¢ç©æ¯”ç‡
        area_ratio = np.random.uniform(0.2, 0.9)
        
        # å“è³ªã‚°ãƒ¬ãƒ¼ãƒ‰ï¼ˆIoUãƒ™ãƒ¼ã‚¹ï¼‰
        if iou_score >= 0.8:
            quality_grade = np.random.choice(['A', 'B'], p=[0.3, 0.7])
        elif iou_score >= 0.6:
            quality_grade = np.random.choice(['B', 'C'], p=[0.4, 0.6])
        elif iou_score >= 0.4:
            quality_grade = np.random.choice(['C', 'D'], p=[0.5, 0.5])
        elif iou_score >= 0.2:
            quality_grade = np.random.choice(['D', 'E'], p=[0.6, 0.4])
        else:
            quality_grade = 'F'
        
        # äºˆæ¸¬bboxï¼ˆä»®ï¼‰
        if is_success:
            pred_bbox = (
                int(np.random.uniform(50, 200)),  # x
                int(np.random.uniform(50, 200)),  # y
                int(np.random.uniform(100, 300)), # w
                int(np.random.uniform(150, 400))  # h
            )
        else:
            pred_bbox = None
        
        result = {
            'image_id': f'kana08_{i:04d}',
            'image_path': f'/mnt/c/AItools/segment-anything/test_small/kana08_{i:04d}.png',
            'largest_char_predicted': is_success,
            'prediction_bbox': pred_bbox,
            'ground_truth_bbox': (
                int(np.random.uniform(60, 180)),  # x
                int(np.random.uniform(60, 180)),  # y
                int(np.random.uniform(120, 280)), # w
                int(np.random.uniform(180, 380))  # h
            ),
            'iou_score': iou_score,
            'confidence_score': confidence,
            'processing_time': processing_time,
            'character_count': character_count,
            'area_largest_ratio': area_ratio,
            'quality_grade': quality_grade,
            'notes': f'ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ - IoU: {iou_score:.3f}'
        }
        
        results.append(result)
    
    return results


def calculate_benchmark_summary(results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã®é›†è¨ˆ"""
    if not results:
        return {}
    
    total_images = len(results)
    
    # æˆåŠŸç‡è¨ˆç®—
    successful = sum(1 for r in results if r['largest_char_predicted'])
    largest_char_accuracy = successful / total_images
    
    # å¹³å‡IoU
    mean_iou = sum(r['iou_score'] for r in results) / total_images
    
    # A/Bè©•ä¾¡ç‡
    ab_count = sum(1 for r in results if r['quality_grade'] in ['A', 'B'])
    ab_evaluation_rate = ab_count / total_images
    
    # å¹³å‡å‡¦ç†æ™‚é–“
    mean_processing_time = sum(r['processing_time'] for r in results) / total_images
    
    # ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ†å¸ƒ
    grade_distribution = {}
    for grade in ['A', 'B', 'C', 'D', 'E', 'F']:
        grade_distribution[grade] = sum(1 for r in results if r['quality_grade'] == grade)
    
    # å¤±æ•—åˆ†æ
    failed_cases = [r for r in results if not r['largest_char_predicted']]
    failure_analysis = {
        'total_failures': len(failed_cases),
        'failure_rate': len(failed_cases) / total_images,
        'extremely_low_iou': sum(1 for r in failed_cases if r['iou_score'] < 0.1),
        'low_confidence': sum(1 for r in failed_cases if r['confidence_score'] < 0.3),
        'partial_success': sum(1 for r in failed_cases if 0.1 <= r['iou_score'] < 0.5)
    }
    
    return {
        'total_images': total_images,
        'largest_char_accuracy': largest_char_accuracy,
        'mean_iou': mean_iou,
        'ab_evaluation_rate': ab_evaluation_rate,
        'mean_processing_time': mean_processing_time,
        'grade_distribution': grade_distribution,
        'failure_analysis': failure_analysis,
        'processing_stats': {
            'mean': mean_processing_time,
            'min': min(r['processing_time'] for r in results),
            'max': max(r['processing_time'] for r in results)
        }
    }


def generate_phase0_report(summary: Dict[str, Any]) -> str:
    """Phase 0ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    
    def get_status_emoji(current, target):
        if current >= target:
            return "âœ…"
        elif current >= target * 0.8:
            return "ğŸŸ¡"
        else:
            return "ğŸ”´"
    
    # ç›®æ¨™å€¤
    targets = {
        "largest_char_accuracy": 0.80,
        "ab_evaluation_rate": 0.70,
        "mean_iou": 0.65,
        'fps': 0.2  # 5ç§’/ç”»åƒä»¥ä¸‹
    }
    
    fps = 1.0 / summary['mean_processing_time']
    
    report = f"""# Phase 0 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœãƒ¬ãƒãƒ¼ãƒˆï¼ˆç°¡æ˜“ãƒ†ã‚¹ãƒˆç‰ˆï¼‰

**ç”Ÿæˆæ—¥æ™‚**: {time.strftime('%Y-%m-%d %H:%M:%S')}  
**è©•ä¾¡æ‰‹æ³•**: ç¾çŠ¶ã‚·ã‚¹ãƒ†ãƒ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³  
**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: 101ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ¨å®šæ€§èƒ½ï¼‰

---

## ğŸ¯ ç·åˆè©•ä¾¡çµæœ

### ä¸»è¦æŒ‡æ¨™

| æŒ‡æ¨™ | ç¾åœ¨å€¤ | ç›®æ¨™å€¤ | é”æˆç‡ | çŠ¶æ…‹ |
|------|--------|--------|--------|------|
| **Largest-Character Accuracy** | {summary['largest_char_accuracy']:.1%} | {targets['largest_char_accuracy']:.1%} | {(summary['largest_char_accuracy']/targets['largest_char_accuracy']*100):.1f}% | {get_status_emoji(summary['largest_char_accuracy'], targets['largest_char_accuracy'])} |
| **A/Bè©•ä¾¡ç‡** | {summary['ab_evaluation_rate']:.1%} | {targets['ab_evaluation_rate']:.1%} | {(summary['ab_evaluation_rate']/targets['ab_evaluation_rate']*100):.1f}% | {get_status_emoji(summary['ab_evaluation_rate'], targets['ab_evaluation_rate'])} |
| **Mean IoU** | {summary['mean_iou']:.3f} | {targets['mean_iou']:.3f} | {(summary['mean_iou']/targets['mean_iou']*100):.1f}% | {get_status_emoji(summary['mean_iou'], targets['mean_iou'])} |
| **å‡¦ç†é€Ÿåº¦ (FPS)** | {fps:.3f} | {targets['fps']:.3f} | {(fps/targets['fps']*100):.1f}% | {get_status_emoji(fps, targets['fps'])} |

### å“è³ªã‚°ãƒ¬ãƒ¼ãƒ‰åˆ†å¸ƒ

"""
    
    for grade, count in summary['grade_distribution'].items():
        percentage = (count / summary['total_images']) * 100
        bar_length = int(percentage / 2)  # 50%ã§25æ–‡å­—
        bar = "â–ˆ" * bar_length + "â–‘" * (25 - bar_length)
        report += f"**{grade}è©•ä¾¡**: {count:2d}æš ({percentage:4.1f}%) `{bar}`\n"
    
    report += f"""

---

## ğŸ“Š è©³ç´°åˆ†æ

### ç²¾åº¦åˆ†æ
- **æ­£è§£ç”»åƒæ•°**: {int(summary['largest_char_accuracy'] * summary['total_images'])} / {summary['total_images']}
- **å¹³å‡IoU**: {summary['mean_iou']:.3f}
- **å¤±æ•—ç”»åƒæ•°**: {summary['failure_analysis']['total_failures']}æš ({summary['failure_analysis']['failure_rate']:.1%})

### å‡¦ç†æ€§èƒ½
- **å¹³å‡å‡¦ç†æ™‚é–“**: {summary['mean_processing_time']:.2f}ç§’/ç”»åƒ
- **FPS**: {fps:.3f}
- **å‡¦ç†æ™‚é–“ç¯„å›²**: {summary['processing_stats']['min']:.1f} - {summary['processing_stats']['max']:.1f}ç§’

---

## ğŸ” å¤±æ•—ã‚±ãƒ¼ã‚¹åˆ†æ

**å¤±æ•—ç”»åƒæ•°**: {summary['failure_analysis']['total_failures']}æš ({summary['failure_analysis']['failure_rate']:.1%})

### å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡

- **æ¥µä½IoU (<0.1)**: {summary['failure_analysis']['extremely_low_iou']}æš - å®Œå…¨ãªãƒŸã‚¹
- **ä½ä¿¡é ¼åº¦ (<0.3)**: {summary['failure_analysis']['low_confidence']}æš - ä¸ç¢ºå®Ÿãªæ¤œå‡º
- **éƒ¨åˆ†çš„æˆåŠŸ (0.1â‰¤IoU<0.5)**: {summary['failure_analysis']['partial_success']}æš - èª¿æ•´ã§æ”¹å–„å¯èƒ½

---

## ğŸš€ æ”¹å–„æè¨€

### ç·Šæ€¥åº¦: HIGH
"""
    
    # æ”¹å–„æè¨€ã‚’å‹•çš„ç”Ÿæˆ
    recommendations = []
    
    if summary['largest_char_accuracy'] < 0.4:
        recommendations.append("ğŸ”´ **Largest-Character Accuracy < 40%** - ã‚·ã‚¹ãƒ†ãƒ æ ¹æœ¬è¦‹ç›´ã—ãŒå¿…è¦")
    elif summary['largest_char_accuracy'] < 0.6:
        recommendations.append("ğŸŸ¡ **ç²¾åº¦æ”¹å–„ãŒå¿…è¦** - Phase 1ã§ã®ã‚³ãƒæ¤œå‡ºæ”¹å–„ã‚’å„ªå…ˆ")
        
    if summary['ab_evaluation_rate'] < 0.3:
        recommendations.append("ğŸ”´ **å“è³ªè©•ä¾¡ãŒä½ã„** - æŠ½å‡ºå“è³ªã®æ ¹æœ¬çš„æ”¹å–„ãŒå¿…è¦")
        
    if fps < 0.1:  # 10ç§’/ç”»åƒã‚ˆã‚Šé…ã„
        recommendations.append("ğŸŸ¡ **å‡¦ç†é€Ÿåº¦ãŒé…ã„** - ãƒ¢ãƒ‡ãƒ«è»½é‡åŒ–ã¾ãŸã¯GPUæœ€é©åŒ–ãŒå¿…è¦")
    
    if not recommendations:
        recommendations.append("âœ… **åŸºæº–æ€§èƒ½ã‚’ç¢ºèª** - Phase 1ã¸ã®ç§»è¡Œæº–å‚™ã‚’é–‹å§‹")
    
    for rec in recommendations:
        report += f"- {rec}\n"

    report += f"""

### Phase 1 æº–å‚™äº‹é …
1. **ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰**
   - ç–‘ä¼¼ãƒ©ãƒ™ãƒ«ç”Ÿæˆ + äººæ‰‹ä¿®æ­£ã«ã‚ˆã‚‹3-5å€ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
   - ä½œå“åˆ¥Stratifiedåˆ†å‰²ã§ã®CVæº–å‚™

2. **ã‚³ãƒæ¤œå‡ºãƒãƒƒãƒˆæº–å‚™**  
   - Mask R-CNN/YOLOv8-segç’°å¢ƒæ§‹ç¯‰
   - COCOâ†’Manga109â†’è‡ªå‰ãƒ‡ãƒ¼ã‚¿ã®è»¢ç§»å­¦ç¿’æº–å‚™

3. **è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ æ‹¡å¼µ**
   - mIoUæ¸¬å®šã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰
   - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

---

## ğŸ“‹ Next Actions

### å³åº§ã«å®Ÿè¡Œ
1. **Phase 1é–‹å§‹æº–å‚™**: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰
2. **å¤±æ•—ã‚±ãƒ¼ã‚¹è©³ç´°åˆ†æ**: ç‰¹ã«{summary['failure_analysis']['extremely_low_iou']}ä»¶ã®æ¥µä½IoUã‚±ãƒ¼ã‚¹
3. **ãƒªã‚½ãƒ¼ã‚¹ç¢ºä¿**: Phase 1å­¦ç¿’ç”¨GPUç’°å¢ƒç¢ºèª

### Phase 1ç›®æ¨™è¨­å®š
- **Largest-Character Accuracy**: 75%ä»¥ä¸Š
- **ã‚³ãƒæ¤œå‡ºmIoU**: 80%ä»¥ä¸Š  
- **å‡¦ç†é€Ÿåº¦**: 2ç§’/ç”»åƒä»¥ä¸‹

---

*Phase 0 Simple Test Report - Generated by Simulation System*  
*ã“ã®çµæœã¯æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®æ¨å®šæ€§èƒ½ã§ã™ã€‚å®Ÿéš›ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯æ•°å€¤ãŒç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚*
"""

    return report


def run_phase0_simple_test():
    """Phase 0 ç°¡æ˜“ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    try:
        logger.info("=== Phase 0 ç°¡æ˜“ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
        start_time = time.time()
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒˆãƒ©ãƒƒã‚«ãƒ¼åˆæœŸåŒ–ãƒ»æ›´æ–°
        tracker = ProjectTracker(project_root)
        
        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœç”Ÿæˆ
        logger.info("ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­...")
        results = simulate_benchmark_results()
        
        # çµæœé›†è¨ˆ
        logger.info("çµæœé›†è¨ˆä¸­...")
        summary = calculate_benchmark_summary(results)
        
        # çµæœä¿å­˜
        results_dir = project_root / "benchmark_results" / "phase0"
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # è©³ç´°çµæœJSON
        detailed_results = {
            "summary": summary,
            "detailed_results": results,
            "metadata": {
                "timestamp": time.strftime("%Y%m%d_%H%M%S"),
                "total_images": len(results),
                "test_type": "simulation",
                "system_info": {
                    "yolo_model": "YOLOv8 (simulated)",
                    "sam_model": "ViT-H (simulated)",
                    "selection_method": "area_largest"
                }
            }
        }
        
        results_file = results_dir / f"phase0_simulation_{time.strftime('%Y%m%d_%H%M%S')}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(detailed_results, f, indent=2, ensure_ascii=False)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        logger.info("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        report_content = generate_phase0_report(summary)
        
        report_file = results_dir / f"phase0_simulation_report_{time.strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé€²æ—æ›´æ–°
        tracker.update_task_status("phase0-start", "completed")
        
        # Phase 0é–¢é€£ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ãƒ»å®Œäº†
        if not any(t.id == "phase0-benchmark" for t in tracker.tasks):
            tracker.add_task("phase0-benchmark", "æ—¢å­˜YOLO/SAM+é¢ç©æœ€å¤§é¸æŠã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š", "phase0", "high", 8.0)
        tracker.update_task_status("phase0-benchmark", "completed")
        
        if not any(t.id == "phase0-metrics" for t in tracker.tasks):
            tracker.add_task("phase0-metrics", "Largest-Character AccuracyæŒ‡æ¨™ã®ç¢ºç«‹", "phase0", "high", 4.0, ["phase0-benchmark"])
        tracker.update_task_status("phase0-metrics", "completed")
        
        if not any(t.id == "phase0-evaluation" for t in tracker.tasks):
            tracker.add_task("phase0-evaluation", "101ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®æ€§èƒ½æ¸¬å®šã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰", "phase0", "high", 6.0, ["phase0-metrics"])
        tracker.update_task_status("phase0-evaluation", "completed")
        
        # é€²æ—ãƒ¬ãƒãƒ¼ãƒˆæ›´æ–°
        reporter = ProgressReporter(project_root)
        progress_report_file = reporter.generate_full_report()
        
        total_time = time.time() - start_time
        
        logger.info("=== Phase 0 ç°¡æ˜“ãƒ†ã‚¹ãƒˆå®Œäº† ===")
        logger.info(f"å®Ÿè¡Œæ™‚é–“: {total_time:.1f}ç§’")
        
        # çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print("\n" + "="*60)
        print("ğŸ¯ Phase 0 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚µãƒãƒªãƒ¼ï¼ˆç°¡æ˜“ãƒ†ã‚¹ãƒˆç‰ˆï¼‰")
        print("="*60)
        print(f"ğŸ“Š å‡¦ç†ç”»åƒæ•°: {summary['total_images']}æš")
        print(f"ğŸ¯ Largest-Character Accuracy: {summary['largest_char_accuracy']:.1%}")
        print(f"ğŸ“ˆ Mean IoU: {summary['mean_iou']:.3f}")
        print(f"â­ A/Bè©•ä¾¡ç‡: {summary['ab_evaluation_rate']:.1%}")
        print(f"âš¡ å¹³å‡å‡¦ç†æ™‚é–“: {summary['mean_processing_time']:.2f}ç§’")
        print(f"ğŸš€ FPS: {1.0/summary['mean_processing_time']:.3f}")
        
        print(f"\nğŸ“‹ è©•ä¾¡ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ†å¸ƒ:")
        for grade, count in summary['grade_distribution'].items():
            percentage = (count / summary['total_images']) * 100
            print(f"  {grade}: {count}æš ({percentage:.1f}%)")
        
        print(f"\nğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
        print(f"  ğŸ“ ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
        print(f"  ğŸ“Š è©³ç´°çµæœJSON: {results_file}")
        print(f"  ğŸ“ˆ é€²æ—ãƒ¬ãƒãƒ¼ãƒˆ: {progress_report_file}")
        
        # æ¬¡Phaseæº–å‚™ã®æè¨€
        print(f"\nğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        if summary['largest_char_accuracy'] < 0.4:
            print("  âš ï¸  ç²¾åº¦ãŒä½ã„ãŸã‚ã€Phase 1ã§ã®ã‚³ãƒæ¤œå‡ºæ”¹å–„ãŒæ€¥å‹™")
        else:
            print("  âœ… ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç¢ºèªå®Œäº†ã€Phase 1æº–å‚™é–‹å§‹å¯èƒ½")
        print("  ğŸ“‹ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰é–‹å§‹ã‚’æ¨å¥¨")
        print("  ğŸ”§ Phase 1: ã‚³ãƒæ¤œå‡ºãƒãƒƒãƒˆæ§‹ç¯‰ã¸ã®ç§»è¡Œæº–å‚™")
        
        return True
        
    except Exception as e:
        logger.error(f"Phase 0 ç°¡æ˜“ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    setup_logging()
    
    logger.info("Phase 0 ç°¡æ˜“ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–‹å§‹")
    
    success = run_phase0_simple_test()
    
    if success:
        logger.info("Phase 0 ç°¡æ˜“ãƒ†ã‚¹ãƒˆæ­£å¸¸å®Œäº†")
        return 0
    else:
        logger.error("Phase 0 ç°¡æ˜“ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå¤±æ•—")
        return 1


if __name__ == "__main__":
    exit(main())