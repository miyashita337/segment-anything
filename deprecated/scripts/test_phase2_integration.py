#!/usr/bin/env python3
"""
Phase 2 Integration Test - Phase 2æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ
å¢ƒç•Œèªè­˜å¼·åŒ–ã€æ‰‹è¶³ä¿è­·ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å„ªå…ˆé †ä½å­¦ç¿’ã®çµ±åˆå‹•ä½œç¢ºèª
"""

import numpy as np
import cv2

import json
import logging
import time
# æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from features.extraction.robust_extractor import RobustCharacterExtractor
# Phase 2ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from features.processing.advanced_boundary_detector import AdvancedBoundaryDetector
from features.processing.character_priority_learning import CharacterPriorityLearning
from features.processing.limb_protection_system import LimbProtectionSystem
from features.processing.preprocessing.color_preserving_enhancer import ColorPreservingEnhancer
from pathlib import Path
from typing import Any, Dict, List, Tuple

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class Phase2IntegratedSystem:
    """Phase 2çµ±åˆæ”¹å–„ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        # Phase 2æ–°ã‚·ã‚¹ãƒ†ãƒ 
        self.boundary_detector = AdvancedBoundaryDetector(
            enable_panel_detection=True,
            enable_multi_stage_edge=True,
            enable_boundary_completion=True
        )
        
        self.limb_protector = LimbProtectionSystem(
            enable_pose_estimation=True,
            enable_limb_completion=True,
            protection_margin=15
        )
        
        self.character_priority = CharacterPriorityLearning(
            enable_face_detection=True,
            enable_position_analysis=True,
            enable_size_priority=True
        )
        
        # æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ 
        self.robust_extractor = RobustCharacterExtractor()
        self.color_enhancer = ColorPreservingEnhancer()
        
        logger.info("Phase 2çµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

    def process_image_integrated(self, 
                               image_path: Path, 
                               output_path: Path) -> Dict[str, Any]:
        """
        çµ±åˆå‡¦ç†ã«ã‚ˆã‚‹ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡º
        
        Args:
            image_path: å…¥åŠ›ç”»åƒãƒ‘ã‚¹
            output_path: å‡ºåŠ›ç”»åƒãƒ‘ã‚¹
            
        Returns:
            å‡¦ç†çµæœã®è©³ç´°æƒ…å ±
        """
        start_time = time.time()
        logger.info(f"çµ±åˆå‡¦ç†é–‹å§‹: {image_path.name}")
        
        # ç”»åƒèª­ã¿è¾¼ã¿
        image = cv2.imread(str(image_path))
        if image is None:
            return {"error": f"ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {image_path}"}
        
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        result = {
            "input_path": str(image_path),
            "output_path": str(output_path),
            "image_shape": image_rgb.shape,
            "processing_steps": [],
            "phase2_analysis": {},
            "final_result": {},
            "processing_time": 0.0,
            "success": False
        }
        
        try:
            # ã‚¹ãƒ†ãƒƒãƒ—1: é«˜åº¦å¢ƒç•Œå¼·åŒ–
            step1_start = time.time()
            boundary_enhanced, boundary_analysis = self.boundary_detector.enhance_boundaries_advanced(
                image_rgb
            )
            step1_time = time.time() - step1_start
            
            result["processing_steps"].append({
                "step": "boundary_enhancement",
                "time": step1_time,
                "analysis": boundary_analysis
            })
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: è‰²ä¿æŒå¼·åŒ–
            step2_start = time.time()
            color_enhanced = self.color_enhancer.enhance_image_boundaries(boundary_enhanced)
            step2_time = time.time() - step2_start
            
            result["processing_steps"].append({
                "step": "color_enhancement", 
                "time": step2_time
            })
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ­ãƒã‚¹ãƒˆæŠ½å‡ºï¼ˆè¤‡æ•°å€™è£œå–å¾—ï¼‰
            step3_start = time.time()
            extraction_result = self.robust_extractor.extract_character_robust(
                image_path, output_path, verbose=False
            )
            step3_time = time.time() - step3_start
            
            result["processing_steps"].append({
                "step": "robust_extraction",
                "time": step3_time,
                "methods_used": extraction_result.get("methods_used", []),
                "best_method": extraction_result.get("best_method", "unknown")
            })
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å€™è£œåˆ†æï¼ˆãƒ€ãƒŸãƒ¼å€™è£œã§ä»£æ›¿ï¼‰
            step4_start = time.time()
            dummy_candidates = self._create_dummy_candidates(image_rgb, extraction_result)
            prioritized_candidates, priority_analysis = self.character_priority.prioritize_characters(
                color_enhanced, dummy_candidates
            )
            step4_time = time.time() - step4_start
            
            result["processing_steps"].append({
                "step": "character_prioritization",
                "time": step4_time,
                "candidates_analyzed": len(dummy_candidates),
                "primary_character": priority_analysis.get("primary_character")
            })
            
            # ã‚¹ãƒ†ãƒƒãƒ—5: æ‰‹è¶³ä¿è­·å‡¦ç†
            step5_start = time.time()
            if extraction_result.get("success", False):
                # æŠ½å‡ºã•ã‚ŒãŸãƒã‚¹ã‚¯ã‚’èª­ã¿è¾¼ã¿
                if output_path.exists():
                    extracted_image = cv2.imread(str(output_path))
                    if extracted_image is not None:
                        extracted_rgb = cv2.cvtColor(extracted_image, cv2.COLOR_BGR2RGB)
                        
                        # ç°¡æ˜“ãƒã‚¹ã‚¯ç”Ÿæˆ
                        gray = cv2.cvtColor(extracted_rgb, cv2.COLOR_RGB2GRAY)
                        _, mask = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)
                        
                        # æ‰‹è¶³ä¿è­·é©ç”¨
                        protected_mask, limb_analysis = self.limb_protector.protect_limbs_in_mask(
                            color_enhanced, mask
                        )
                        
                        # ä¿è­·ã•ã‚ŒãŸãƒã‚¹ã‚¯ã§æœ€çµ‚ç”»åƒã‚’ä½œæˆ
                        final_image = self._apply_protected_mask(color_enhanced, protected_mask)
                        
                        # æœ€çµ‚çµæœä¿å­˜
                        final_bgr = cv2.cvtColor(final_image, cv2.COLOR_RGB2BGR)
                        cv2.imwrite(str(output_path), final_bgr)
                        
                        result["processing_steps"].append({
                            "step": "limb_protection",
                            "time": time.time() - step5_start,
                            "protection_applied": limb_analysis.get("protection_applied", False),
                            "protection_quality": limb_analysis.get("protection_quality", 0.0)
                        })
            
            # Phase 2åˆ†æçµæœçµ±åˆ
            result["phase2_analysis"] = {
                "boundary_enhancement": boundary_analysis,
                "character_priority": priority_analysis,
                "limb_protection": result["processing_steps"][-1] if len(result["processing_steps"]) >= 5 else {}
            }
            
            # æœ€çµ‚çµæœ
            result["final_result"] = {
                "extraction_success": extraction_result.get("success", False),
                "quality_score": extraction_result.get("quality_score", 0.0),
                "output_exists": output_path.exists(),
                "phase2_enhancements": {
                    "boundary_quality": boundary_analysis.get("enhancement_quality", 0.0),
                    "priority_score": priority_analysis.get("primary_character", {}).get("priority_score", 0.0),
                    "limb_protection": result["processing_steps"][-1].get("protection_quality", 0.0) if len(result["processing_steps"]) >= 5 else 0.0
                }
            }
            
            result["success"] = True
            
        except Exception as e:
            logger.error(f"çµ±åˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            result["error"] = str(e)
        
        result["processing_time"] = time.time() - start_time
        logger.info(f"çµ±åˆå‡¦ç†å®Œäº†: {result['processing_time']:.2f}ç§’")
        
        return result

    def _create_dummy_candidates(self, 
                               image: np.ndarray, 
                               extraction_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æŠ½å‡ºçµæœã‹ã‚‰ãƒ€ãƒŸãƒ¼å€™è£œã‚’ç”Ÿæˆ"""
        height, width = image.shape[:2]
        
        # åŸºæœ¬å€™è£œï¼ˆä¸­å¤®ï¼‰
        candidates = [{
            "bbox": (width//4, height//4, width//2, height//2),
            "mask": np.ones((height//2, width//2), dtype=np.uint8) * 255,
            "confidence": extraction_result.get("quality_score", 0.7),
            "area": (width//2) * (height//2),
            "center": (width//2, height//2)
        }]
        
        # è¿½åŠ å€™è£œï¼ˆç•°ãªã‚‹ä½ç½®ãƒ»ã‚µã‚¤ã‚ºï¼‰
        if extraction_result.get("success", False):
            candidates.extend([
                {
                    "bbox": (width//6, height//6, width//3, height//3),
                    "mask": np.ones((height//3, width//3), dtype=np.uint8) * 255,
                    "confidence": 0.6,
                    "area": (width//3) * (height//3),
                    "center": (width//3, height//3)
                },
                {
                    "bbox": (width//2, height//3, width//4, height//4),
                    "mask": np.ones((height//4, width//4), dtype=np.uint8) * 255,
                    "confidence": 0.5,
                    "area": (width//4) * (height//4),
                    "center": (5*width//8, 5*height//12)
                }
            ])
        
        return candidates

    def _apply_protected_mask(self, 
                            image: np.ndarray, 
                            mask: np.ndarray) -> np.ndarray:
        """ä¿è­·ã•ã‚ŒãŸãƒã‚¹ã‚¯ã‚’ç”»åƒã«é©ç”¨"""
        if len(mask.shape) == 3:
            mask_gray = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)
        else:
            mask_gray = mask.copy()
        
        # ãƒã‚¹ã‚¯ã‚’3ãƒãƒ£ãƒ³ãƒãƒ«ã«å¤‰æ›
        mask_3ch = cv2.cvtColor(mask_gray, cv2.COLOR_GRAY2RGB)
        
        # ãƒã‚¹ã‚¯ã«ã‚ˆã‚‹æŠ½å‡º
        result = cv2.bitwise_and(image, mask_3ch)
        
        # èƒŒæ™¯ã‚’é€æ˜åŒ–ï¼ˆç™½èƒŒæ™¯ï¼‰
        background = np.ones_like(image) * 255
        mask_inv = cv2.bitwise_not(mask_gray)
        mask_inv_3ch = cv2.cvtColor(mask_inv, cv2.COLOR_GRAY2RGB)
        background_part = cv2.bitwise_and(background, mask_inv_3ch)
        
        final_result = cv2.add(result, background_part)
        return final_result


def run_integration_test():
    """çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸ§ª Phase 2çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    integrated_system = Phase2IntegratedSystem()
    
    # ãƒ†ã‚¹ãƒˆç”»åƒ
    test_images = [
        Path("/mnt/c/AItools/lora/train/yado/org/kaname08/kaname08_0001.jpg"),
        Path("/mnt/c/AItools/lora/train/yado/org/kaname08/kaname08_0002.jpg"),
        Path("/mnt/c/AItools/lora/train/yado/org/kaname08/kaname08_0009.jpg")
    ]
    
    test_results = []
    
    for i, test_image in enumerate(test_images):
        if not test_image.exists():
            print(f"âš ï¸ ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_image}")
            continue
        
        print(f"\\nğŸ“¸ ãƒ†ã‚¹ãƒˆ {i+1}/3: {test_image.name}")
        
        # å‡ºåŠ›ãƒ‘ã‚¹
        output_path = Path(f"/tmp/phase2_integration_test_{i+1}.jpg")
        
        # çµ±åˆå‡¦ç†å®Ÿè¡Œ
        result = integrated_system.process_image_integrated(test_image, output_path)
        
        if result["success"]:
            print(f"âœ… å‡¦ç†æˆåŠŸ ({result['processing_time']:.2f}ç§’)")
            
            # Phase 2æ”¹å–„åŠ¹æœ
            enhancements = result["final_result"]["phase2_enhancements"]
            print(f"   å¢ƒç•Œå¼·åŒ–å“è³ª: {enhancements['boundary_quality']:.3f}")
            print(f"   ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å„ªå…ˆåº¦: {enhancements['priority_score']:.3f}")
            print(f"   æ‰‹è¶³ä¿è­·å“è³ª: {enhancements['limb_protection']:.3f}")
            
            # å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—æ™‚é–“
            for step in result["processing_steps"]:
                print(f"   {step['step']}: {step['time']:.3f}ç§’")
                
        else:
            print(f"âŒ å‡¦ç†å¤±æ•—: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
        
        test_results.append(result)
    
    # çµ±åˆãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼
    print("\\nğŸ“Š çµ±åˆãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
    successful_tests = [r for r in test_results if r["success"]]
    print(f"æˆåŠŸç‡: {len(successful_tests)}/{len(test_results)} ({len(successful_tests)/len(test_results)*100:.1f}%)")
    
    if successful_tests:
        avg_time = sum(r["processing_time"] for r in successful_tests) / len(successful_tests)
        print(f"å¹³å‡å‡¦ç†æ™‚é–“: {avg_time:.2f}ç§’")
        
        # Phase 2æ”¹å–„åŠ¹æœã®å¹³å‡
        avg_boundary = sum(r["final_result"]["phase2_enhancements"]["boundary_quality"] 
                          for r in successful_tests) / len(successful_tests)
        avg_priority = sum(r["final_result"]["phase2_enhancements"]["priority_score"] 
                          for r in successful_tests) / len(successful_tests)
        avg_limb = sum(r["final_result"]["phase2_enhancements"]["limb_protection"] 
                      for r in successful_tests) / len(successful_tests)
        
        print(f"å¹³å‡æ”¹å–„åŠ¹æœ:")
        print(f"  å¢ƒç•Œå¼·åŒ–: {avg_boundary:.3f}")
        print(f"  ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å„ªå…ˆ: {avg_priority:.3f}")
        print(f"  æ‰‹è¶³ä¿è­·: {avg_limb:.3f}")
    
    # çµæœã‚’JSONã§ä¿å­˜
    results_path = Path("/tmp/phase2_integration_test_results.json")
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(test_results, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\\nğŸ’¾ è©³ç´°çµæœä¿å­˜: {results_path}")
    print("ğŸ‰ Phase 2çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†")


if __name__ == "__main__":
    run_integration_test()