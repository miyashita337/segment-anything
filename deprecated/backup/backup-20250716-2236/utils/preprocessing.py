#!/usr/bin/env python3
"""
Image Preprocessing Utilities
Extracted and modularized from original sam_yolo_character_segment.py
"""

import numpy as np
import cv2

from pathlib import Path
from typing import List, Optional, Tuple


def load_and_validate_image(image_path: str) -> Optional[np.ndarray]:
    """
    ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§æ¤œè¨¼
    
    Args:
        image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
    Returns:
        èª­ã¿è¾¼ã‚“ã ç”»åƒ (BGR format) ã¾ãŸã¯ None
    """
    try:
        if not Path(image_path).exists():
            print(f"âŒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
            return None
        
        image = cv2.imread(image_path)
        if image is None:
            print(f"âŒ ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {image_path}")
            return None
        
        # ç”»åƒã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        height, width = image.shape[:2]
        if height < 32 or width < 32:
            print(f"âŒ ç”»åƒã‚µã‚¤ã‚ºãŒå°ã•ã™ãã¾ã™: {width}x{height}")
            return None
        
        print(f"âœ… ç”»åƒèª­ã¿è¾¼ã¿æˆåŠŸ: {width}x{height}, {image_path}")
        return image
        
    except Exception as e:
        print(f"âŒ ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def resize_image_if_needed(image: np.ndarray, 
                         max_size: int = 1024,
                         min_size: int = 512) -> Tuple[np.ndarray, float]:
    """
    å¿…è¦ã«å¿œã˜ã¦ç”»åƒã‚’ãƒªã‚µã‚¤ã‚º
    
    Args:
        image: å…¥åŠ›ç”»åƒ
        max_size: æœ€å¤§ã‚µã‚¤ã‚º
        min_size: æœ€å°ã‚µã‚¤ã‚º
        
    Returns:
        ãƒªã‚µã‚¤ã‚ºå¾Œã®ç”»åƒã¨ã‚¹ã‚±ãƒ¼ãƒ«æ¯”
    """
    height, width = image.shape[:2]
    original_size = max(height, width)
    
    # ãƒªã‚µã‚¤ã‚ºãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
    if original_size <= max_size and min(height, width) >= min_size:
        return image, 1.0
    
    # ã‚¹ã‚±ãƒ¼ãƒ«è¨ˆç®—
    if original_size > max_size:
        scale = max_size / original_size
    else:
        scale = min_size / min(height, width)
    
    # æ–°ã—ã„ã‚µã‚¤ã‚ºè¨ˆç®—
    new_width = int(width * scale)
    new_height = int(height * scale)
    
    # ãƒªã‚µã‚¤ã‚ºå®Ÿè¡Œ
    resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
    
    print(f"ğŸ”„ ç”»åƒãƒªã‚µã‚¤ã‚º: {width}x{height} â†’ {new_width}x{new_height} (scale={scale:.3f})")
    
    return resized, scale


def normalize_image_for_sam(image: np.ndarray) -> np.ndarray:
    """
    SAMç”¨ã«ç”»åƒã‚’æ­£è¦åŒ– (BGR â†’ RGB)
    
    Args:
        image: å…¥åŠ›ç”»åƒ (BGR format)
        
    Returns:
        æ­£è¦åŒ–ã•ã‚ŒãŸç”»åƒ (RGB format)
    """
    if len(image.shape) == 3 and image.shape[2] == 3:
        # BGR to RGB
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        return rgb_image
    else:
        return image


def is_color_image(image: np.ndarray, threshold: float = 0.01) -> bool:
    """
    ç”»åƒãŒã‚«ãƒ©ãƒ¼ç”»åƒã‹ã©ã†ã‹ã‚’åˆ¤å®š
    
    Args:
        image: å…¥åŠ›ç”»åƒ (BGR/RGB)
        threshold: ã‚«ãƒ©ãƒ¼åˆ¤å®šã®é–¾å€¤
        
    Returns:
        True if ã‚«ãƒ©ãƒ¼ç”»åƒ, False if ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒ
    """
    if len(image.shape) != 3 or image.shape[2] != 3:
        return False
    
    # RGBãƒãƒ£ãƒ³ãƒãƒ«é–“ã®å·®åˆ†ã‚’è¨ˆç®—
    r, g, b = cv2.split(image)
    
    # å„ãƒãƒ£ãƒ³ãƒãƒ«é–“ã®æ¨™æº–åå·®ã‚’è¨ˆç®—
    diff_rg = np.std(r.astype(np.float32) - g.astype(np.float32))
    diff_rb = np.std(r.astype(np.float32) - b.astype(np.float32))
    diff_gb = np.std(g.astype(np.float32) - b.astype(np.float32))
    
    # ã„ãšã‚Œã‹ã®ãƒãƒ£ãƒ³ãƒãƒ«é–“å·®åˆ†ãŒé–¾å€¤ã‚’è¶…ãˆã‚Œã°ã‚«ãƒ©ãƒ¼ç”»åƒ
    max_diff = max(diff_rg, diff_rb, diff_gb)
    is_color = max_diff > threshold
    
    print(f"ã‚«ãƒ©ãƒ¼åˆ¤å®š: æœ€å¤§ãƒãƒ£ãƒ³ãƒãƒ«å·®åˆ†={max_diff:.3f}, é–¾å€¤={threshold}, çµæœ={'ã‚«ãƒ©ãƒ¼' if is_color else 'ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«'}")
    
    return is_color


def enhance_image_contrast(image: np.ndarray, alpha: float = 1.2, beta: int = 10) -> np.ndarray:
    """
    ç”»åƒã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å¼·åŒ–
    
    Args:
        image: å…¥åŠ›ç”»åƒ
        alpha: ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆä¿‚æ•°
        beta: æ˜åº¦èª¿æ•´å€¤
        
    Returns:
        ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–å¾Œã®ç”»åƒ
    """
    enhanced = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)
    return enhanced


def apply_gaussian_blur(image: np.ndarray, kernel_size: int = 5) -> np.ndarray:
    """
    ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ã‚’é©ç”¨
    
    Args:
        image: å…¥åŠ›ç”»åƒ
        kernel_size: ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºï¼ˆå¥‡æ•°ï¼‰
        
    Returns:
        ãƒ–ãƒ©ãƒ¼é©ç”¨å¾Œã®ç”»åƒ
    """
    # kernel_sizeãŒå¶æ•°ã®å ´åˆã¯+1ã—ã¦å¥‡æ•°ã«ã™ã‚‹
    if kernel_size % 2 == 0:
        kernel_size += 1
    
    blurred = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)
    return blurred


def detect_edges(image: np.ndarray, 
                low_threshold: int = 50, 
                high_threshold: int = 150) -> np.ndarray:
    """
    ã‚¨ãƒƒã‚¸æ¤œå‡º
    
    Args:
        image: å…¥åŠ›ç”»åƒ
        low_threshold: ä½é–¾å€¤
        high_threshold: é«˜é–¾å€¤
        
    Returns:
        ã‚¨ãƒƒã‚¸ç”»åƒ
    """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
    edges = cv2.Canny(gray, low_threshold, high_threshold)
    return edges


def crop_image_to_bbox(image: np.ndarray, 
                      bbox: Tuple[int, int, int, int],
                      padding: int = 10) -> np.ndarray:
    """
    ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã«åŸºã¥ã„ã¦ç”»åƒã‚’ã‚¯ãƒ­ãƒƒãƒ—
    
    Args:
        image: å…¥åŠ›ç”»åƒ
        bbox: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ [x, y, width, height]
        padding: ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å€¤
        
    Returns:
        ã‚¯ãƒ­ãƒƒãƒ—ã•ã‚ŒãŸç”»åƒ
    """
    x, y, w, h = bbox
    height, width = image.shape[:2]
    
    # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’è€ƒæ…®ã—ãŸåº§æ¨™è¨ˆç®—
    x1 = max(0, x - padding)
    y1 = max(0, y - padding)
    x2 = min(width, x + w + padding)
    y2 = min(height, y + h + padding)
    
    cropped = image[y1:y2, x1:x2]
    return cropped


def calculate_image_statistics(image: np.ndarray) -> dict:
    """
    ç”»åƒã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
    
    Args:
        image: å…¥åŠ›ç”»åƒ
        
    Returns:
        çµ±è¨ˆæƒ…å ±ã®è¾æ›¸
    """
    height, width = image.shape[:2]
    
    stats = {
        'width': width,
        'height': height,
        'area': width * height,
        'aspect_ratio': height / width if width > 0 else 0,
        'channels': image.shape[2] if len(image.shape) == 3 else 1
    }
    
    # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›ã—ã¦çµ±è¨ˆè¨ˆç®—
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    stats.update({
        'mean_brightness': np.mean(gray),
        'std_brightness': np.std(gray),
        'min_brightness': np.min(gray),
        'max_brightness': np.max(gray)
    })
    
    return stats


def preprocess_image_pipeline(image_path: str,
                            max_size: int = 1024,
                            enhance_contrast: bool = False) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], float]:
    """
    ç”»åƒå‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    
    Args:
        image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        max_size: æœ€å¤§ã‚µã‚¤ã‚º
        enhance_contrast: ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–ã‚’è¡Œã†ã‹
        
    Returns:
        (å‡¦ç†æ¸ˆã¿ç”»åƒBGR, å‡¦ç†æ¸ˆã¿ç”»åƒRGB, ã‚¹ã‚±ãƒ¼ãƒ«æ¯”) ã®ã‚¿ãƒ—ãƒ«
    """
    # ç”»åƒèª­ã¿è¾¼ã¿
    image_bgr = load_and_validate_image(image_path)
    if image_bgr is None:
        return None, None, 0.0
    
    # ãƒªã‚µã‚¤ã‚º
    image_bgr, scale = resize_image_if_needed(image_bgr, max_size=max_size)
    
    # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if enhance_contrast:
        image_bgr = enhance_image_contrast(image_bgr)
        print("âœ¨ ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–é©ç”¨")
    
    # SAMç”¨ã«RGBã«å¤‰æ›
    image_rgb = normalize_image_for_sam(image_bgr)
    
    # çµ±è¨ˆæƒ…å ±å‡ºåŠ›
    stats = calculate_image_statistics(image_bgr)
    color_type = "ã‚«ãƒ©ãƒ¼" if is_color_image(image_bgr) else "ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«"
    print(f"ğŸ“Š ç”»åƒçµ±è¨ˆ: {stats['width']}x{stats['height']}, "
          f"å¹³å‡è¼åº¦: {stats['mean_brightness']:.1f}, {color_type}")
    
    return image_bgr, image_rgb, scale


if __name__ == "__main__":
    # Test preprocessing functions
    test_image_path = "../assets/masks1.png"
    
    if Path(test_image_path).exists():
        print("ğŸ§ª Preprocessing test starting...")
        
        bgr_img, rgb_img, scale = preprocess_image_pipeline(test_image_path)
        
        if bgr_img is not None:
            print("âœ… Preprocessing pipeline test successful")
            print(f"   Scale: {scale}")
            print(f"   BGR shape: {bgr_img.shape}")
            print(f"   RGB shape: {rgb_img.shape}")
        else:
            print("âŒ Preprocessing pipeline test failed")
    else:
        print(f"âš ï¸ Test image not found: {test_image_path}")
        print("âœ… Preprocessing module loaded successfully")