#!/usr/bin/env python3
"""
Week 3æœ€çµ‚ç›®æ¨™é”æˆç¢ºèªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ  + SCIæœ€é©åŒ–ã®åŠ¹æœæ¸¬å®š

ç›®æ¨™æŒ‡æ¨™:
- é¡”æ¤œå‡ºç‡: 90%ä»¥ä¸Š
- ãƒãƒ¼ã‚ºæ¤œå‡ºç‡: 80%ä»¥ä¸Š  
- SCIç·åˆã‚¹ã‚³ã‚¢: 0.70ä»¥ä¸Š
"""

import cv2
import json
import logging
import numpy as np
import sys
import time
from dataclasses import asdict, dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from features.evaluation.detection_ensemble_system import DetectionEnsembleSystem
from features.evaluation.objective_evaluation_system import ObjectiveEvaluationSystem

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class BenchmarkResult:
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ"""

    image_path: str
    face_detection_success: bool
    face_confidence: float
    pose_detection_success: bool
    pose_confidence: float
    sci_score: float
    sci_anime_score: float
    ensemble_confidence: float
    processing_time: float
    improvement_metrics: Dict[str, float]


@dataclass
class FinalBenchmarkReport:
    """æœ€çµ‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¬ãƒãƒ¼ãƒˆ"""

    timestamp: datetime
    total_images: int
    face_detection_rate: float
    pose_detection_rate: float
    sci_average: float
    sci_anime_average: float
    target_achievement: Dict[str, bool]
    detailed_results: List[BenchmarkResult]
    performance_summary: Dict[str, float]
    ensemble_effectiveness: Dict[str, float]


class Week3FinalBenchmark:
    """Week 3æœ€çµ‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.Week3FinalBenchmark")

        # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self.ensemble_system = DetectionEnsembleSystem()
        self.evaluation_system = ObjectiveEvaluationSystem()

        # ç›®æ¨™å€¤è¨­å®š
        self.targets = {
            "face_detection_rate": 0.90,  # 90%
            "pose_detection_rate": 0.80,  # 80%
            "sci_score": 0.70,  # 0.70
        }

        self.logger.info("Week 3æœ€çµ‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

    def run_final_benchmark(self, test_images_dir: str = "test_small") -> FinalBenchmarkReport:
        """æœ€çµ‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        start_time = datetime.now()
        self.logger.info("Week 3æœ€çµ‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")

        # ãƒ†ã‚¹ãƒˆç”»åƒã®åé›†
        test_images = self._collect_test_images(test_images_dir)
        if not test_images:
            raise ValueError(f"ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_images_dir}")

        self.logger.info(f"ãƒ†ã‚¹ãƒˆç”»åƒæ•°: {len(test_images)}æš")

        # å„ç”»åƒã§ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
        detailed_results = []
        total_processing_time = 0.0

        for i, image_path in enumerate(test_images, 1):
            self.logger.info(f"å‡¦ç†ä¸­ ({i}/{len(test_images)}): {Path(image_path).name}")

            try:
                result = self._benchmark_single_image(image_path)
                detailed_results.append(result)
                total_processing_time += result.processing_time

            except Exception as e:
                self.logger.error(f"ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼ ({image_path}): {e}")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆçµæœã‚’è¿½åŠ 
                detailed_results.append(
                    BenchmarkResult(
                        image_path=str(image_path),
                        face_detection_success=False,
                        face_confidence=0.0,
                        pose_detection_success=False,
                        pose_confidence=0.0,
                        sci_score=0.0,
                        sci_anime_score=0.0,
                        ensemble_confidence=0.0,
                        processing_time=0.0,
                        improvement_metrics={},
                    )
                )

        # çµ±è¨ˆè¨ˆç®—
        statistics = self._calculate_benchmark_statistics(detailed_results)

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åŠ¹æœåˆ†æ
        ensemble_effectiveness = self._analyze_ensemble_effectiveness(detailed_results)

        # ç›®æ¨™é”æˆåˆ¤å®š
        target_achievement = {
            "face_detection_rate": statistics["face_detection_rate"] >= self.targets["face_detection_rate"],
            "pose_detection_rate": statistics["pose_detection_rate"] >= self.targets["pose_detection_rate"],
            "sci_score": statistics["sci_anime_average"] >= self.targets["sci_score"],
        }

        total_time = (datetime.now() - start_time).total_seconds()
        self.logger.info(f"Week 3æœ€çµ‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº† ({total_time:.2f}ç§’)")

        return FinalBenchmarkReport(
            timestamp=start_time,
            total_images=len(test_images),
            face_detection_rate=statistics["face_detection_rate"],
            pose_detection_rate=statistics["pose_detection_rate"],
            sci_average=statistics["sci_average"],
            sci_anime_average=statistics["sci_anime_average"],
            target_achievement=target_achievement,
            detailed_results=detailed_results,
            performance_summary=statistics,
            ensemble_effectiveness=ensemble_effectiveness,
        )

    def _benchmark_single_image(self, image_path: str) -> BenchmarkResult:
        """å˜ä¸€ç”»åƒã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        start_time = time.time()

        # ç”»åƒèª­ã¿è¾¼ã¿
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—: {image_path}")

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ¤œå‡ºå®Ÿè¡Œ
        ensemble_result = self.ensemble_system.detect_comprehensive_ensemble(
            image, target_face_rate=0.90, target_pose_rate=0.80
        )

        # SCIè©•ä¾¡ï¼ˆå¾“æ¥ vs ã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–ï¼‰
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        sci_result_standard = self.evaluation_system.evaluate_single_extraction(rgb_image, anime_optimized=False)
        sci_result_anime = self.evaluation_system.evaluate_single_extraction(rgb_image, anime_optimized=True)

        # æ”¹å–„æŒ‡æ¨™è¨ˆç®—
        improvement_metrics = {
            "ensemble_boost": ensemble_result.ensemble_confidence - max(
                [d.confidence for d in ensemble_result.face_detections], default=0.0
            ),
            "sci_anime_improvement": sci_result_anime.sci_total - sci_result_standard.sci_total,
            "detection_diversity": len(ensemble_result.method_contributions),
        }

        processing_time = time.time() - start_time

        return BenchmarkResult(
            image_path=str(image_path),
            face_detection_success=len(ensemble_result.face_detections) > 0,
            face_confidence=max([d.confidence for d in ensemble_result.face_detections], default=0.0),
            pose_detection_success=ensemble_result.pose_result.detected,
            pose_confidence=ensemble_result.pose_result.confidence,
            sci_score=sci_result_standard.sci_total,
            sci_anime_score=sci_result_anime.sci_total,
            ensemble_confidence=ensemble_result.ensemble_confidence,
            processing_time=processing_time,
            improvement_metrics=improvement_metrics,
        )

    def _collect_test_images(self, test_dir: str) -> List[Path]:
        """ãƒ†ã‚¹ãƒˆç”»åƒã®åé›†"""
        test_path = Path(test_dir)
        if not test_path.exists():
            test_path = project_root / test_dir

        if not test_path.exists():
            return []

        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­
        image_extensions = {".jpg", ".jpeg", ".png", ".bmp", ".tiff"}

        images = []
        for ext in image_extensions:
            images.extend(test_path.glob(f"*{ext}"))
            images.extend(test_path.glob(f"*{ext.upper()}"))

        return sorted(images)[:20]  # æœ€å¤§20æšã«åˆ¶é™

    def _calculate_benchmark_statistics(self, results: List[BenchmarkResult]) -> Dict[str, float]:
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµ±è¨ˆè¨ˆç®—"""
        if not results:
            return {}

        # æ¤œå‡ºæˆåŠŸç‡
        face_successes = sum(1 for r in results if r.face_detection_success)
        pose_successes = sum(1 for r in results if r.pose_detection_success)

        face_detection_rate = face_successes / len(results)
        pose_detection_rate = pose_successes / len(results)

        # å¹³å‡ä¿¡é ¼åº¦
        avg_face_confidence = np.mean([r.face_confidence for r in results])
        avg_pose_confidence = np.mean([r.pose_confidence for r in results])
        avg_ensemble_confidence = np.mean([r.ensemble_confidence for r in results])

        # SCIå¹³å‡
        sci_average = np.mean([r.sci_score for r in results])
        sci_anime_average = np.mean([r.sci_anime_score for r in results])

        # å‡¦ç†æ™‚é–“çµ±è¨ˆ
        avg_processing_time = np.mean([r.processing_time for r in results])

        return {
            "face_detection_rate": face_detection_rate,
            "pose_detection_rate": pose_detection_rate,
            "avg_face_confidence": avg_face_confidence,
            "avg_pose_confidence": avg_pose_confidence,
            "avg_ensemble_confidence": avg_ensemble_confidence,
            "sci_average": sci_average,
            "sci_anime_average": sci_anime_average,
            "avg_processing_time": avg_processing_time,
            "total_processing_time": sum(r.processing_time for r in results),
        }

    def _analyze_ensemble_effectiveness(self, results: List[BenchmarkResult]) -> Dict[str, float]:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åŠ¹æœåˆ†æ"""
        if not results:
            return {}

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«ã‚ˆã‚‹æ”¹å–„åŠ¹æœ
        ensemble_improvements = [r.improvement_metrics.get("ensemble_boost", 0.0) for r in results]
        avg_ensemble_improvement = np.mean(ensemble_improvements)

        # SCI ã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–æ”¹å–„åŠ¹æœ
        sci_improvements = [r.improvement_metrics.get("sci_anime_improvement", 0.0) for r in results]
        avg_sci_improvement = np.mean(sci_improvements)

        # æ‰‹æ³•å¤šæ§˜æ€§
        diversity_scores = [r.improvement_metrics.get("detection_diversity", 1.0) for r in results]
        avg_diversity = np.mean(diversity_scores)

        # ç›®æ¨™é”æˆç”»åƒæ•°
        target_achieving_images = sum(
            1
            for r in results
            if r.face_detection_success and r.pose_detection_success and r.sci_anime_score >= 0.70
        )

        target_achievement_rate = target_achieving_images / len(results)

        return {
            "avg_ensemble_improvement": avg_ensemble_improvement,
            "avg_sci_improvement": avg_sci_improvement,
            "avg_method_diversity": avg_diversity,
            "target_achievement_rate": target_achievement_rate,
            "total_target_achieving_images": target_achieving_images,
        }

    def save_benchmark_report(self, report: FinalBenchmarkReport, output_file: str = None) -> str:
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
        if output_file is None:
            timestamp = report.timestamp.strftime("%Y%m%d_%H%M%S")
            output_file = f"week3_final_benchmark_report_{timestamp}.json"

        # JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºç”¨ã«datetimeã¨numpyå‹ã‚’å¤‰æ›
        report_dict = asdict(report)
        report_dict["timestamp"] = report.timestamp.isoformat()
        
        # numpy bool_ã‚’Python boolã«å¤‰æ›
        def convert_numpy_types(obj):
            if isinstance(obj, np.bool_):
                return bool(obj)
            elif isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, dict):
                return {k: convert_numpy_types(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(v) for v in obj]
            return obj
        
        report_dict = convert_numpy_types(report_dict)

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(report_dict, f, indent=2, ensure_ascii=False)

        self.logger.info(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {output_file}")
        return output_file

    def print_benchmark_summary(self, report: FinalBenchmarkReport):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print("\n" + "=" * 60)
        print("ğŸš€ Week 3æœ€çµ‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚µãƒãƒªãƒ¼")
        print("=" * 60)

        print(f"\nğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"  å¯¾è±¡ç”»åƒæ•°: {report.total_images}æš")
        print(f"  å‡¦ç†æ™‚é–“: {report.performance_summary['total_processing_time']:.2f}ç§’")
        print(f"  å¹³å‡å‡¦ç†æ™‚é–“: {report.performance_summary['avg_processing_time']:.2f}ç§’/æš")

        print(f"\nğŸ¯ ç›®æ¨™é”æˆåº¦:")
        face_status = "âœ…" if report.target_achievement["face_detection_rate"] else "âŒ"
        pose_status = "âœ…" if report.target_achievement["pose_detection_rate"] else "âŒ"
        sci_status = "âœ…" if report.target_achievement["sci_score"] else "âŒ"

        print(f"  {face_status} é¡”æ¤œå‡ºç‡: {report.face_detection_rate:.1%} (ç›®æ¨™90%)")
        print(f"  {pose_status} ãƒãƒ¼ã‚ºæ¤œå‡ºç‡: {report.pose_detection_rate:.1%} (ç›®æ¨™80%)")
        print(f"  {sci_status} SCIç·åˆ: {report.sci_anime_average:.3f} (ç›®æ¨™0.70)")

        print(f"\nğŸ”§ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åŠ¹æœ:")
        print(f"  å¹³å‡ä¿¡é ¼åº¦å‘ä¸Š: {report.ensemble_effectiveness['avg_ensemble_improvement']:.3f}")
        print(f"  SCIæ”¹å–„åŠ¹æœ: {report.ensemble_effectiveness['avg_sci_improvement']:.3f}")
        print(f"  ç›®æ¨™é”æˆç”»åƒ: {report.ensemble_effectiveness['total_target_achieving_images']}/{report.total_images}æš")

        # ç·åˆè©•ä¾¡
        all_targets_achieved = all(report.target_achievement.values())
        if all_targets_achieved:
            print(f"\nğŸ‰ Week 3ç›®æ¨™å®Œå…¨é”æˆï¼")
        else:
            print(f"\nâš ï¸  ä¸€éƒ¨ç›®æ¨™æœªé”æˆ")

        print("=" * 60)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    import argparse

    parser = argparse.ArgumentParser(description="Week 3æœ€çµ‚ç›®æ¨™é”æˆç¢ºèª")
    parser.add_argument("--test-dir", default="test_small", help="ãƒ†ã‚¹ãƒˆç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--output", help="ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å")
    args = parser.parse_args()

    try:
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
        benchmark = Week3FinalBenchmark()
        report = benchmark.run_final_benchmark(args.test_dir)

        # çµæœè¡¨ç¤º
        benchmark.print_benchmark_summary(report)

        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        output_file = benchmark.save_benchmark_report(report, args.output)
        print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {output_file}")

        # æˆåŠŸåˆ¤å®š
        all_achieved = all(report.target_achievement.values())
        sys.exit(0 if all_achieved else 1)

    except Exception as e:
        logger.error(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()