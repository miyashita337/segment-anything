#!/usr/bin/env python3
"""
æ­£è§£ãƒã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ„ãƒ¼ãƒ«
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½œæˆã—ãŸæ­£è§£ãƒã‚¹ã‚¯ï¼ˆground truthï¼‰ã®å“è³ªã¨æ•´åˆæ€§ã‚’ç¢ºèª

Usage:
    python tools/validate_evaluation_data.py --directory /path/to/masks/
    python tools/validate_evaluation_data.py --directory /path/to/masks/ --fix-issues
    python tools/validate_evaluation_data.py --check-all
"""

import os
import sys
import argparse
import logging
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass

import numpy as np
import cv2
from PIL import Image

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class ValidationResult:
    """æ¤œè¨¼çµæœãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    file_path: str
    is_valid: bool
    issues: List[str]
    recommendations: List[str]
    quality_score: float


@dataclass
class OverallValidationReport:
    """å…¨ä½“æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ"""
    total_files: int
    valid_files: int
    invalid_files: int
    file_results: List[ValidationResult]
    summary_issues: List[str]
    summary_recommendations: List[str]
    overall_quality: float


class GroundTruthValidator:
    """æ­£è§£ãƒã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.GroundTruthValidator")
        
        # æ¤œè¨¼åŸºæº–
        self.validation_criteria = {
            'min_white_ratio': 0.01,    # æœ€å°ç™½è‰²é ˜åŸŸæ¯”ç‡ï¼ˆ1%ï¼‰
            'max_white_ratio': 0.95,    # æœ€å¤§ç™½è‰²é ˜åŸŸæ¯”ç‡ï¼ˆ95%ï¼‰
            'min_resolution': (50, 50), # æœ€å°è§£åƒåº¦
            'max_resolution': (4000, 4000), # æœ€å¤§è§£åƒåº¦
            'required_channels': 1,      # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¿…é ˆ
            'valid_extensions': ['.png', '.jpg', '.jpeg'],
            'naming_patterns': ['_gt.png', '_ground_truth.png', 'gt_']
        }
    
    def validate_directory(self, directory: str, fix_issues: bool = False) -> OverallValidationReport:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®æ­£è§£ãƒã‚¹ã‚¯ã‚’ä¸€æ‹¬æ¤œè¨¼"""
        directory_path = Path(directory)
        
        if not directory_path.exists():
            raise FileNotFoundError(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {directory}")
        
        self.logger.info(f"ğŸ” æ¤œè¨¼é–‹å§‹: {directory}")
        
        # æ­£è§£ãƒã‚¹ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        mask_files = self._find_ground_truth_files(directory_path)
        
        if not mask_files:
            self.logger.warning("âš ï¸ æ­£è§£ãƒã‚¹ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return OverallValidationReport(
                total_files=0,
                valid_files=0,
                invalid_files=0,
                file_results=[],
                summary_issues=["æ­£è§£ãƒã‚¹ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"],
                summary_recommendations=["_gt.pngå½¢å¼ã§ãƒã‚¹ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„"],
                overall_quality=0.0
            )
        
        self.logger.info(f"ğŸ“ æ¤œè¨¼å¯¾è±¡: {len(mask_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        
        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
        validation_results = []
        for mask_file in mask_files:
            try:
                result = self._validate_single_file(mask_file, fix_issues)
                validation_results.append(result)
                
                status = "âœ…" if result.is_valid else "âŒ"
                self.logger.info(f"{status} {mask_file.name}: {result.quality_score:.3f}")
                
            except Exception as e:
                self.logger.error(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ {mask_file.name}: {e}")
                validation_results.append(ValidationResult(
                    file_path=str(mask_file),
                    is_valid=False,
                    issues=[f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}"],
                    recommendations=["ãƒ•ã‚¡ã‚¤ãƒ«ã®ç ´æã‚’ç¢ºèªã—ã¦ãã ã•ã„"],
                    quality_score=0.0
                ))
        
        # å…¨ä½“ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = self._generate_overall_report(validation_results)
        
        self.logger.info(f"âœ… æ¤œè¨¼å®Œäº†: {report.valid_files}/{report.total_files}ãƒ•ã‚¡ã‚¤ãƒ«æœ‰åŠ¹")
        
        return report
    
    def _find_ground_truth_files(self, directory: Path) -> List[Path]:
        """æ­£è§£ãƒã‚¹ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        mask_files = []
        
        # æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³
        patterns = ['*_gt.png', '*_ground_truth.png', 'gt_*.png']
        
        for pattern in patterns:
            mask_files.extend(list(directory.glob(pattern)))
        
        # é‡è¤‡é™¤å»ã¨ã‚½ãƒ¼ãƒˆ
        mask_files = sorted(list(set(mask_files)))
        
        return mask_files
    
    def _validate_single_file(self, file_path: Path, fix_issues: bool = False) -> ValidationResult:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼"""
        issues = []
        recommendations = []
        quality_score = 1.0
        
        try:
            # 1. ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
            if not file_path.exists():
                issues.append("ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                quality_score = 0.0
                return ValidationResult(str(file_path), False, issues, recommendations, quality_score)
            
            # 2. ãƒ•ã‚¡ã‚¤ãƒ«åæ¤œè¨¼
            name_valid, name_issues, name_recs = self._validate_filename(file_path)
            if not name_valid:
                issues.extend(name_issues)
                recommendations.extend(name_recs)
                quality_score -= 0.1
            
            # 3. ç”»åƒèª­ã¿è¾¼ã¿
            try:
                mask = cv2.imread(str(file_path), cv2.IMREAD_GRAYSCALE)
                if mask is None:
                    # PILã§å†è©¦è¡Œ
                    pil_image = Image.open(file_path)
                    mask = np.array(pil_image.convert('L'))
            except Exception as e:
                issues.append(f"ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                quality_score = 0.0
                return ValidationResult(str(file_path), False, issues, recommendations, quality_score)
            
            # 4. ç”»åƒå½¢å¼æ¤œè¨¼
            format_valid, format_issues, format_recs, format_score = self._validate_image_format(mask, file_path)
            if not format_valid:
                issues.extend(format_issues)
                recommendations.extend(format_recs)
                quality_score -= format_score
            
            # 5. ç”»åƒå†…å®¹æ¤œè¨¼
            content_valid, content_issues, content_recs, content_score = self._validate_image_content(mask)
            if not content_valid:
                issues.extend(content_issues)
                recommendations.extend(content_recs)
                quality_score -= content_score
            
            # 6. å¯¾å¿œã™ã‚‹å…ƒç”»åƒç¢ºèª
            original_valid, original_issues, original_recs = self._validate_original_image(file_path)
            if not original_valid:
                issues.extend(original_issues)
                recommendations.extend(original_recs)
                quality_score -= 0.1
            
            # 7. ä¿®æ­£å‡¦ç†ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if fix_issues and issues:
                self._attempt_fixes(file_path, mask, issues)
            
            # æœ€çµ‚ã‚¹ã‚³ã‚¢èª¿æ•´
            quality_score = max(0.0, min(1.0, quality_score))
            is_valid = quality_score >= 0.7 and len(issues) == 0
            
            return ValidationResult(
                file_path=str(file_path),
                is_valid=is_valid,
                issues=issues,
                recommendations=recommendations,
                quality_score=quality_score
            )
            
        except Exception as e:
            return ValidationResult(
                file_path=str(file_path),
                is_valid=False,
                issues=[f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}"],
                recommendations=["æŠ€è¡“ã‚µãƒãƒ¼ãƒˆã«é€£çµ¡ã—ã¦ãã ã•ã„"],
                quality_score=0.0
            )
    
    def _validate_filename(self, file_path: Path) -> Tuple[bool, List[str], List[str]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«åæ¤œè¨¼"""
        issues = []
        recommendations = []
        
        # æ‹¡å¼µå­ç¢ºèª
        if file_path.suffix.lower() not in self.validation_criteria['valid_extensions']:
            issues.append(f"éå¯¾å¿œæ‹¡å¼µå­: {file_path.suffix}")
            recommendations.append("PNGå½¢å¼(.png)ã‚’æ¨å¥¨")
        
        # å‘½åè¦å‰‡ç¢ºèª
        filename = file_path.name.lower()
        pattern_found = any(pattern in filename for pattern in self.validation_criteria['naming_patterns'])
        
        if not pattern_found:
            issues.append("æ¨™æº–å‘½åè¦å‰‡ã«å¾“ã£ã¦ã„ã¾ã›ã‚“")
            recommendations.append("ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ '{å…ƒç”»åƒå}_gt.png' ã«å¤‰æ›´ã—ã¦ãã ã•ã„")
        
        return len(issues) == 0, issues, recommendations
    
    def _validate_image_format(self, mask: np.ndarray, file_path: Path) -> Tuple[bool, List[str], List[str], float]:
        """ç”»åƒå½¢å¼æ¤œè¨¼"""
        issues = []
        recommendations = []
        score_penalty = 0.0
        
        # è§£åƒåº¦ç¢ºèª
        height, width = mask.shape[:2]
        min_h, min_w = self.validation_criteria['min_resolution']
        max_h, max_w = self.validation_criteria['max_resolution']
        
        if height < min_h or width < min_w:
            issues.append(f"è§£åƒåº¦ãŒä½ã™ãã¾ã™: {width}x{height}")
            recommendations.append(f"æœ€å°{min_w}x{min_h}ä»¥ä¸Šã«ã—ã¦ãã ã•ã„")
            score_penalty += 0.3
        
        if height > max_h or width > max_w:
            issues.append(f"è§£åƒåº¦ãŒé«˜ã™ãã¾ã™: {width}x{height}")
            recommendations.append(f"æœ€å¤§{max_w}x{max_h}ä»¥ä¸‹ã«ã—ã¦ãã ã•ã„")
            score_penalty += 0.1
        
        # ãƒãƒ£ãƒ³ãƒãƒ«æ•°ç¢ºèª
        if len(mask.shape) != 2:
            issues.append(f"ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {len(mask.shape)}ãƒãƒ£ãƒ³ãƒãƒ«")
            recommendations.append("ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒã§ä¿å­˜ã—ã¦ãã ã•ã„")
            score_penalty += 0.2
        
        return len(issues) == 0, issues, recommendations, score_penalty
    
    def _validate_image_content(self, mask: np.ndarray) -> Tuple[bool, List[str], List[str], float]:
        """ç”»åƒå†…å®¹æ¤œè¨¼"""
        issues = []
        recommendations = []
        score_penalty = 0.0
        
        # ãƒã‚¤ãƒŠãƒªãƒã‚¹ã‚¯ç¢ºèª
        unique_values = np.unique(mask)
        
        # å®Œå…¨ãƒã‚¤ãƒŠãƒªï¼ˆ0ã¨255ã®ã¿ï¼‰ã§ãªã„å ´åˆã¯è­¦å‘Š
        if not (len(unique_values) == 2 and 0 in unique_values and 255 in unique_values):
            if len(unique_values) > 10:
                issues.append("ãƒã‚¤ãƒŠãƒªãƒã‚¹ã‚¯ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆå¤šéšèª¿å€¤æ¤œå‡ºï¼‰")
                recommendations.append("ç™½(255)ã¨é»’(0)ã®ã¿ã®ç”»åƒã«ã—ã¦ãã ã•ã„")
                score_penalty += 0.3
            else:
                # ã»ã¼ãƒã‚¤ãƒŠãƒªã®å ´åˆã¯è»½å¾®ãªè­¦å‘Š
                recommendations.append("å¯èƒ½ãªé™ã‚Šç´”ç²‹ãªç™½(255)ã¨é»’(0)ã§æç”»ã—ã¦ãã ã•ã„")
                score_penalty += 0.1
        
        # ç™½è‰²é ˜åŸŸæ¯”ç‡ç¢ºèª
        white_pixels = np.sum(mask > 127)  # é–¾å€¤127ä»¥ä¸Šã‚’ç™½ã¨ã¿ãªã™
        total_pixels = mask.size
        white_ratio = white_pixels / total_pixels
        
        min_ratio = self.validation_criteria['min_white_ratio']
        max_ratio = self.validation_criteria['max_white_ratio']
        
        if white_ratio < min_ratio:
            issues.append(f"ç™½è‰²é ˜åŸŸãŒå°‘ãªã™ãã¾ã™: {white_ratio:.3f}")
            recommendations.append("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼éƒ¨åˆ†ã‚’ç™½è‰²ã§æç”»ã—ã¦ãã ã•ã„")
            score_penalty += 0.4
        
        if white_ratio > max_ratio:
            issues.append(f"ç™½è‰²é ˜åŸŸãŒå¤šã™ãã¾ã™: {white_ratio:.3f}")
            recommendations.append("èƒŒæ™¯ã¯é»’è‰²ã§æç”»ã—ã¦ãã ã•ã„")
            score_penalty += 0.2
        
        # ãƒã‚¤ã‚ºç¢ºèªï¼ˆå°ã•ãªç™½è‰²é ˜åŸŸã®æ¤œå‡ºï¼‰
        if white_ratio > 0:
            contours, _ = cv2.findContours(
                (mask > 127).astype(np.uint8), 
                cv2.RETR_EXTERNAL, 
                cv2.CHAIN_APPROX_SIMPLE
            )
            
            if len(contours) > 5:  # å¤šæ•°ã®ç‹¬ç«‹é ˜åŸŸãŒã‚ã‚‹å ´åˆ
                issues.append(f"å¤šæ•°ã®ç‹¬ç«‹ã—ãŸç™½è‰²é ˜åŸŸ: {len(contours)}å€‹")
                recommendations.append("ãƒã‚¤ã‚ºã‚’é™¤å»ã—ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼éƒ¨åˆ†ã®ã¿ã‚’æç”»ã—ã¦ãã ã•ã„")
                score_penalty += 0.1
        
        return len(issues) == 0, issues, recommendations, score_penalty
    
    def _validate_original_image(self, mask_path: Path) -> Tuple[bool, List[str], List[str]]:
        """å¯¾å¿œã™ã‚‹å…ƒç”»åƒã®ç¢ºèª"""
        issues = []
        recommendations = []
        
        # å…ƒç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ¨å®š
        mask_name = mask_path.stem
        
        # _gt, _ground_truthç­‰ã‚’é™¤å»ã—ã¦å…ƒãƒ•ã‚¡ã‚¤ãƒ«åã‚’å¾©å…ƒ
        for pattern in ['_gt', '_ground_truth']:
            if mask_name.endswith(pattern):
                original_name = mask_name[:-len(pattern)]
                break
        else:
            if mask_name.startswith('gt_'):
                original_name = mask_name[3:]
            else:
                original_name = mask_name
        
        # å…ƒç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        original_extensions = ['.jpg', '.jpeg', '.png', '.webp']
        original_found = False
        
        for ext in original_extensions:
            original_path = mask_path.parent / f"{original_name}{ext}"
            if original_path.exists():
                original_found = True
                break
        
        if not original_found:
            issues.append(f"å¯¾å¿œã™ã‚‹å…ƒç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {original_name}")
            recommendations.append("å…ƒç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒåŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
        return original_found, issues, recommendations
    
    def _attempt_fixes(self, file_path: Path, mask: np.ndarray, issues: List[str]):
        """è‡ªå‹•ä¿®æ­£ã®è©¦è¡Œ"""
        try:
            # ãƒã‚¤ãƒŠãƒªåŒ–å‡¦ç†
            if "ãƒã‚¤ãƒŠãƒªãƒã‚¹ã‚¯ã§ã¯ã‚ã‚Šã¾ã›ã‚“" in str(issues):
                _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)
                backup_path = file_path.with_suffix(f'.backup{file_path.suffix}')
                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
                cv2.imwrite(str(backup_path), mask)
                # ä¿®æ­£ç‰ˆä¿å­˜
                cv2.imwrite(str(file_path), binary_mask)
                self.logger.info(f"ğŸ”§ è‡ªå‹•ä¿®æ­£å®Œäº†: {file_path.name} (ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_path.name})")
        
        except Exception as e:
            self.logger.warning(f"âš ï¸ è‡ªå‹•ä¿®æ­£å¤±æ•— {file_path.name}: {e}")
    
    def _generate_overall_report(self, validation_results: List[ValidationResult]) -> OverallValidationReport:
        """å…¨ä½“ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        total_files = len(validation_results)
        valid_files = sum(1 for r in validation_results if r.is_valid)
        invalid_files = total_files - valid_files
        
        # å…±é€šå•é¡Œã®é›†è¨ˆ
        all_issues = []
        all_recommendations = []
        
        for result in validation_results:
            all_issues.extend(result.issues)
            all_recommendations.extend(result.recommendations)
        
        # é »å‡ºå•é¡Œã‚’ã‚µãƒãƒªãƒ¼ã«
        summary_issues = list(set(all_issues))[:5]  # ä¸Šä½5ä»¶
        summary_recommendations = list(set(all_recommendations))[:5]  # ä¸Šä½5ä»¶
        
        # å…¨ä½“å“è³ªã‚¹ã‚³ã‚¢
        if total_files > 0:
            overall_quality = sum(r.quality_score for r in validation_results) / total_files
        else:
            overall_quality = 0.0
        
        return OverallValidationReport(
            total_files=total_files,
            valid_files=valid_files,
            invalid_files=invalid_files,
            file_results=validation_results,
            summary_issues=summary_issues,
            summary_recommendations=summary_recommendations,
            overall_quality=overall_quality
        )


class ValidationReportGenerator:
    """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    
    def __init__(self, output_dir: str = "validation_reports"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.logger = logging.getLogger(f"{__name__}.ValidationReportGenerator")
    
    def generate_report(self, report: OverallValidationReport, directory: str) -> str:
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        directory_name = Path(directory).name
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ
        report_path = self.output_dir / f"validation_{directory_name}_{timestamp}.txt"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(self._generate_report_content(report, directory))
        
        self.logger.info(f"ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}")
        return str(report_path)
    
    def _generate_report_content(self, report: OverallValidationReport, directory: str) -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ç”Ÿæˆ"""
        content = f"""
=============================================================
ğŸ” æ­£è§£ãƒã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ
=============================================================

ğŸ“… æ¤œè¨¼æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ“ æ¤œè¨¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {directory}

ğŸ“Š æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼:
  ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {report.total_files}
  âœ… æœ‰åŠ¹ãƒ•ã‚¡ã‚¤ãƒ«: {report.valid_files}
  âŒ ç„¡åŠ¹ãƒ•ã‚¡ã‚¤ãƒ«: {report.invalid_files}
  ğŸ“ˆ å…¨ä½“å“è³ªã‚¹ã‚³ã‚¢: {report.overall_quality:.3f} / 1.000

ğŸ¯ å“è³ªè©•ä¾¡:
  {self._get_quality_assessment(report.overall_quality)}

"""
        
        # ä¸»è¦å•é¡Œ
        if report.summary_issues:
            content += "âš ï¸ ä¸»è¦ãªå•é¡Œ:\n"
            for issue in report.summary_issues:
                content += f"  â€¢ {issue}\n"
            content += "\n"
        
        # æ¨å¥¨æ”¹å–„ç­–
        if report.summary_recommendations:
            content += "ğŸ’¡ æ¨å¥¨æ”¹å–„ç­–:\n"
            for rec in report.summary_recommendations:
                content += f"  â€¢ {rec}\n"
            content += "\n"
        
        # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«çµæœ
        content += "ğŸ“‹ å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼çµæœ:\n"
        content += "=" * 60 + "\n"
        
        for result in report.file_results:
            status = "âœ… æœ‰åŠ¹" if result.is_valid else "âŒ ç„¡åŠ¹"
            filename = Path(result.file_path).name
            
            content += f"{status} | {filename} | ã‚¹ã‚³ã‚¢: {result.quality_score:.3f}\n"
            
            if result.issues:
                for issue in result.issues:
                    content += f"    âš ï¸ {issue}\n"
            
            if result.recommendations:
                for rec in result.recommendations:
                    content += f"    ğŸ’¡ {rec}\n"
            
            content += "\n"
        
        # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
        content += self._generate_next_steps(report)
        
        return content
    
    def _get_quality_assessment(self, score: float) -> str:
        """å“è³ªè©•ä¾¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
        if score >= 0.9:
            return "ğŸ‰ å„ªç§€ - é«˜å“è³ªãªãƒã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿ã§ã™"
        elif score >= 0.7:
            return "âœ… è‰¯å¥½ - è»½å¾®ãªæ”¹å–„ã§ä½¿ç”¨å¯èƒ½ã§ã™"
        elif score >= 0.5:
            return "âš ï¸ è¦æ”¹å–„ - ã„ãã¤ã‹ã®å•é¡ŒãŒã‚ã‚Šã¾ã™"
        else:
            return "âŒ å“è³ªä¸è¶³ - å¤§å¹…ãªä¿®æ­£ãŒå¿…è¦ã§ã™"
    
    def _generate_next_steps(self, report: OverallValidationReport) -> str:
        """æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ææ¡ˆ"""
        content = "ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\n"
        content += "=" * 30 + "\n"
        
        if report.overall_quality >= 0.7:
            content += "âœ… å“è³ªåŸºæº–ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã„ã¾ã™\n"
            content += "  â€¢ PLAè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã§å®¢è¦³çš„è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\n"
            content += "  â€¢ ã‚³ãƒãƒ³ãƒ‰ä¾‹: python tools/run_objective_evaluation.py --batch [ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª]\n\n"
        else:
            content += "âš ï¸ å“è³ªæ”¹å–„ãŒå¿…è¦ã§ã™\n"
            content += "  â€¢ ä¸Šè¨˜ã®æ¨å¥¨æ”¹å–„ç­–ã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„\n"
            content += "  â€¢ ä¿®æ­£å¾Œã€å†åº¦æ¤œè¨¼ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\n"
            content += "  â€¢ ã‚³ãƒãƒ³ãƒ‰ä¾‹: python tools/validate_evaluation_data.py --directory [ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª] --fix-issues\n\n"
        
        content += "ğŸ“ˆ é€²æ—ç®¡ç†:\n"
        content += "  â€¢ PROGRESS_TRACKER.mdã§ä½œæ¥­é€²æ—ã‚’æ›´æ–°\n"
        content += "  â€¢ ç›®æ¨™: 15æšã®æ­£è§£ãƒã‚¹ã‚¯å®Œæˆ\n"
        content += f"  â€¢ ç¾åœ¨: {report.valid_files}æšå®Œäº†æ¸ˆã¿\n\n"
        
        return content


def main():
    parser = argparse.ArgumentParser(description="æ­£è§£ãƒã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ„ãƒ¼ãƒ«")
    parser.add_argument("--directory", "-d", help="æ¤œè¨¼å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--check-all", action="store_true", help="å…¨ã¦ã®æ—¢çŸ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œè¨¼")
    parser.add_argument("--fix-issues", action="store_true", help="å¯èƒ½ãªå•é¡Œã‚’è‡ªå‹•ä¿®æ­£")
    parser.add_argument("--output", help="ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª", default="validation_reports")
    parser.add_argument("--verbose", "-v", action="store_true", help="è©³ç´°ãƒ­ã‚°å‡ºåŠ›")
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        validator = GroundTruthValidator()
        report_generator = ValidationReportGenerator(args.output)
        
        # æ¤œè¨¼å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ±ºå®š
        if args.check_all:
            # æ—¢çŸ¥ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å…¨ã¦æ¤œè¨¼
            directories = [
                "/mnt/c/AItools/lora/train/yado/org/kana08_cursor_fix/",
                "/mnt/c/AItools/lora/train/yado/org/kana07_cursor_fix/",
                "/mnt/c/AItools/lora/train/yado/org/kana05_cursor_fix/"
            ]
            directories = [d for d in directories if Path(d).exists()]
        elif args.directory:
            directories = [args.directory]
        else:
            print("âŒ ã‚¨ãƒ©ãƒ¼: --directory ã¾ãŸã¯ --check-all ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            return 1
        
        all_reports = []
        
        for directory in directories:
            print(f"\n{'='*60}")
            print(f"ğŸ” æ¤œè¨¼é–‹å§‹: {directory}")
            print(f"{'='*60}")
            
            # æ¤œè¨¼å®Ÿè¡Œ
            report = validator.validate_directory(directory, args.fix_issues)
            all_reports.append((directory, report))
            
            # çµæœè¡¨ç¤º
            print(f"\nğŸ“Š æ¤œè¨¼çµæœ:")
            print(f"  ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {report.total_files}")
            print(f"  âœ… æœ‰åŠ¹: {report.valid_files}")
            print(f"  âŒ ç„¡åŠ¹: {report.invalid_files}")
            print(f"  ğŸ“ˆ å“è³ªã‚¹ã‚³ã‚¢: {report.overall_quality:.3f}")
            
            if report.summary_issues:
                print(f"\nâš ï¸ ä¸»è¦ãªå•é¡Œ:")
                for issue in report.summary_issues[:3]:
                    print(f"  â€¢ {issue}")
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report_path = report_generator.generate_report(report, directory)
            print(f"\nğŸ“‹ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
        
        # å…¨ä½“ã‚µãƒãƒªãƒ¼
        if len(all_reports) > 1:
            print(f"\n{'='*60}")
            print(f"ğŸ“ˆ å…¨ä½“ã‚µãƒãƒªãƒ¼")
            print(f"{'='*60}")
            
            total_files = sum(r[1].total_files for r in all_reports)
            total_valid = sum(r[1].valid_files for r in all_reports)
            avg_quality = sum(r[1].overall_quality for r in all_reports) / len(all_reports)
            
            print(f"  ç·æ¤œè¨¼ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}")
            print(f"  ç·æœ‰åŠ¹ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_valid}")
            print(f"  å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {avg_quality:.3f}")
            print(f"  å®Œäº†ç‡: {total_valid/15*100:.1f}% (ç›®æ¨™15æš)")
        
        return 0
        
    except Exception as e:
        logger.error(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)