#!/usr/bin/env python3
"""
Phase 1 ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ 
ç–‘ä¼¼ãƒ©ãƒ™ãƒ«ç”Ÿæˆ + äººæ‰‹ä¿®æ­£ã«ã‚ˆã‚‹3-5å€ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
"""

import numpy as np
import cv2

import json
import logging
import shutil
import time
from dataclasses import asdict, dataclass
from pathlib import Path
from PIL import Image, ImageEnhance, ImageFilter
from typing import Any, Dict, List, Optional, Tuple

# albumentationsã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    import albumentations as A
    ALBUMENTATIONS_AVAILABLE = True
except ImportError:
    ALBUMENTATIONS_AVAILABLE = False
    print("WARNING: albumentations not available, using basic augmentation")

logger = logging.getLogger(__name__)


@dataclass
class PseudoLabel:
    """ç–‘ä¼¼ãƒ©ãƒ™ãƒ«"""
    image_id: str
    source_image_path: str
    augmented_image_path: str
    original_bbox: Tuple[int, int, int, int]
    transformed_bbox: Tuple[int, int, int, int]
    confidence_score: float
    augmentation_type: str
    requires_manual_review: bool
    notes: str


@dataclass
class DataExpansionResult:
    """ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µçµæœ"""
    original_count: int
    generated_count: int
    total_count: int
    expansion_ratio: float
    pseudo_labels: List[PseudoLabel]
    augmentation_stats: Dict[str, int]
    quality_distribution: Dict[str, int]


class DataExpansionSystem:
    """ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, project_root: Path):
        """
        åˆæœŸåŒ–
        
        Args:
            project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.project_root = project_root
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åŸå‰‡: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆç›´ä¸‹ã¸ã®ç”»åƒå‡ºåŠ›ç¦æ­¢
        self.output_dir = Path("/mnt/c/AItools/lora/train/yado/expanded")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ‹¡å¼µç”»åƒãƒ»ãƒ©ãƒ™ãƒ«ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.images_dir = self.output_dir / "images"
        self.labels_dir = self.output_dir / "labels"
        self.review_dir = self.output_dir / "manual_review"
        
        for dir_path in [self.images_dir, self.labels_dir, self.review_dir]:
            dir_path.mkdir(exist_ok=True)
        
        # å…ƒãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        self.labels_file = project_root / "extracted_labels.json"
        self.original_labels = self.load_original_labels()
        
        # æ‹¡å¼µè¨­å®š
        self.target_expansion_ratio = 4.0  # 4å€æ‹¡å¼µ
        self.manual_review_threshold = 0.6  # ä¿¡é ¼åº¦0.6ä»¥ä¸‹ã¯æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼
        
        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®šç¾©
        self.augmentation_pipeline = self.setup_augmentation_pipeline()
        
    def load_original_labels(self) -> Dict[str, Any]:
        """å…ƒãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            if not self.labels_file.exists():
                logger.warning(f"ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.labels_file}")
                return {}
            
            with open(self.labels_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆã¯è¾æ›¸å½¢å¼ã«å¤‰æ›
            if isinstance(data, list):
                converted_data = {}
                for item in data:
                    filename = item.get('filename', '')
                    if filename:
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ‹¡å¼µå­ã‚’é™¤å»ã—ã¦IDã¨ã™ã‚‹
                        image_id = filename.rsplit('.', 1)[0]
                        # æœ€åˆã®èµ¤æ åº§æ¨™ã‚’ä½¿ç”¨
                        if item.get('red_boxes') and len(item['red_boxes']) > 0:
                            first_box = item['red_boxes'][0]
                            bbox_data = first_box.get('bbox', {})
                            converted_data[image_id] = {
                                'red_box_coords': [
                                    bbox_data.get('x', 0),
                                    bbox_data.get('y', 0),
                                    bbox_data.get('width', 0),
                                    bbox_data.get('height', 0)
                                ]
                            }
                data = converted_data
            
            logger.info(f"å…ƒãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(data)}ãƒ•ã‚¡ã‚¤ãƒ«")
            return data
            
        except Exception as e:
            logger.error(f"ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def setup_augmentation_pipeline(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š"""
        
        if ALBUMENTATIONS_AVAILABLE:
            return self.setup_albumentations_pipeline()
        else:
            return self.setup_basic_pipeline()
    
    def setup_albumentations_pipeline(self) -> Dict[str, Any]:
        """Albumentationsã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
        
        # 1. è»½å¾®ãªå¤‰æ›ï¼ˆé«˜ä¿¡é ¼åº¦ï¼‰
        light_transform = A.Compose([
            A.HorizontalFlip(p=0.5),
            A.Rotate(limit=5, p=0.7),
            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),
            A.GaussNoise(var_limit=(10, 30), p=0.3),
        ], bbox_params=A.BboxParams(format='xywh', label_fields=['class_labels']))
        
        # 2. ä¸­ç¨‹åº¦å¤‰æ›ï¼ˆä¸­ä¿¡é ¼åº¦ï¼‰
        medium_transform = A.Compose([
            A.OneOf([
                A.HorizontalFlip(p=1.0),
                A.Rotate(limit=10, p=1.0),
                A.RandomScale(scale_limit=0.1, p=1.0),
            ], p=0.8),
            A.OneOf([
                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),
                A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=1.0),
                A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=1.0),
            ], p=0.6),
            A.GaussNoise(var_limit=(10, 50), p=0.4),
        ], bbox_params=A.BboxParams(format='xywh', label_fields=['class_labels']))
        
        # 3. å¼·ã„å¤‰æ›ï¼ˆä½ä¿¡é ¼åº¦ãƒ»è¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰
        strong_transform = A.Compose([
            A.OneOf([
                A.HorizontalFlip(p=1.0),
                A.Rotate(limit=15, p=1.0),
                A.RandomScale(scale_limit=0.2, p=1.0),
                A.ElasticTransform(alpha=50, sigma=5, p=1.0),
            ], p=0.9),
            A.OneOf([
                A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=1.0),
                A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=25, val_shift_limit=20, p=1.0),
                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=1.0),
            ], p=0.8),
            A.OneOf([
                A.GaussNoise(var_limit=(20, 80), p=1.0),
                A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=1.0),
                A.MultiplicativeNoise(multiplier=[0.9, 1.1], per_channel=True, p=1.0),
            ], p=0.5),
            A.OneOf([
                A.MotionBlur(blur_limit=5, p=1.0),
                A.MedianBlur(blur_limit=3, p=1.0),
                A.GaussianBlur(blur_limit=3, p=1.0),
            ], p=0.3),
        ], bbox_params=A.BboxParams(format='xywh', label_fields=['class_labels']))
        
        return {
            'light': light_transform,
            'medium': medium_transform,
            'strong': strong_transform
        }
    
    def setup_basic_pipeline(self) -> Dict[str, Any]:
        """åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆalbumentationsä¸ä½¿ç”¨ï¼‰"""
        return {
            'light': self.basic_light_transform,
            'medium': self.basic_medium_transform,
            'strong': self.basic_strong_transform
        }
    
    def basic_light_transform(self, image: np.ndarray, bbox: Tuple[int, int, int, int]) -> Tuple[np.ndarray, Tuple[int, int, int, int]]:
        """åŸºæœ¬çš„ãªè»½å¾®å¤‰æ›"""
        aug_image = image.copy()
        x, y, w, h = bbox
        
        # æ°´å¹³åè»¢ï¼ˆ50%ç¢ºç‡ï¼‰
        if np.random.random() < 0.5:
            aug_image = cv2.flip(aug_image, 1)
            x = aug_image.shape[1] - x - w
        
        # è»½å¾®ãªæ˜åº¦èª¿æ•´
        brightness = np.random.uniform(0.9, 1.1)
        aug_image = np.clip(aug_image * brightness, 0, 255).astype(np.uint8)
        
        return aug_image, (x, y, w, h)
    
    def basic_medium_transform(self, image: np.ndarray, bbox: Tuple[int, int, int, int]) -> Tuple[np.ndarray, Tuple[int, int, int, int]]:
        """åŸºæœ¬çš„ãªä¸­ç¨‹åº¦å¤‰æ›"""
        aug_image = image.copy()
        x, y, w, h = bbox
        
        # æ°´å¹³åè»¢
        if np.random.random() < 0.5:
            aug_image = cv2.flip(aug_image, 1)
            x = aug_image.shape[1] - x - w
        
        # æ˜åº¦ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´
        brightness = np.random.uniform(0.8, 1.2)
        contrast = np.random.uniform(0.8, 1.2)
        aug_image = np.clip(aug_image * contrast + (brightness - 1) * 127, 0, 255).astype(np.uint8)
        
        # ãƒã‚¤ã‚ºè¿½åŠ 
        noise = np.random.normal(0, 25, aug_image.shape).astype(np.uint8)
        aug_image = np.clip(aug_image.astype(int) + noise, 0, 255).astype(np.uint8)
        
        return aug_image, (x, y, w, h)
    
    def basic_strong_transform(self, image: np.ndarray, bbox: Tuple[int, int, int, int]) -> Tuple[np.ndarray, Tuple[int, int, int, int]]:
        """åŸºæœ¬çš„ãªå¼·ã„å¤‰æ›"""
        aug_image = image.copy()
        x, y, w, h = bbox
        
        # æ°´å¹³åè»¢
        if np.random.random() < 0.5:
            aug_image = cv2.flip(aug_image, 1)
            x = aug_image.shape[1] - x - w
        
        # å¼·ã„æ˜åº¦ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´
        brightness = np.random.uniform(0.6, 1.4)
        contrast = np.random.uniform(0.6, 1.4)
        aug_image = np.clip(aug_image * contrast + (brightness - 1) * 127, 0, 255).astype(np.uint8)
        
        # å¼·ã„ãƒã‚¤ã‚ºè¿½åŠ 
        noise = np.random.normal(0, 40, aug_image.shape).astype(np.uint8)
        aug_image = np.clip(aug_image.astype(int) + noise, 0, 255).astype(np.uint8)
        
        # è»½å¾®ãªãƒ–ãƒ©ãƒ¼
        if np.random.random() < 0.3:
            aug_image = cv2.GaussianBlur(aug_image, (3, 3), 0)
        
        return aug_image, (x, y, w, h)
    
    def calculate_confidence_score(self, augmentation_type: str, 
                                 bbox_change_ratio: float,
                                 intensity_factor: float) -> float:
        """
        ç–‘ä¼¼ãƒ©ãƒ™ãƒ«ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
        
        Args:
            augmentation_type: å¤‰æ›ã‚¿ã‚¤ãƒ—
            bbox_change_ratio: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹å¤‰åŒ–ç‡
            intensity_factor: å¤‰æ›å¼·åº¦ä¿‚æ•°
            
        Returns:
            0.0-1.0ã®ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
        """
        # ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦
        base_confidence = {
            'light': 0.9,
            'medium': 0.7,
            'strong': 0.5
        }.get(augmentation_type, 0.5)
        
        # bboxå¤‰åŒ–ã«ã‚ˆã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£
        bbox_penalty = min(bbox_change_ratio * 0.5, 0.3)
        
        # å¼·åº¦ã«ã‚ˆã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£  
        intensity_penalty = min(intensity_factor * 0.2, 0.2)
        
        # æœ€çµ‚ä¿¡é ¼åº¦
        confidence = base_confidence - bbox_penalty - intensity_penalty
        return max(0.0, min(1.0, confidence))
    
    def apply_augmentation(self, image: np.ndarray, bbox: Tuple[int, int, int, int],
                          aug_type: str) -> Tuple[np.ndarray, Tuple[int, int, int, int], float]:
        """
        ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé©ç”¨
        
        Args:
            image: å…¥åŠ›ç”»åƒ
            bbox: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ [x, y, w, h]
            aug_type: æ‹¡å¼µã‚¿ã‚¤ãƒ—
            
        Returns:
            (æ‹¡å¼µç”»åƒ, å¤‰æ›å¾Œbbox, ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢)
        """
        try:
            x, y, w, h = bbox
            
            if ALBUMENTATIONS_AVAILABLE:
                # Albumentationsä½¿ç”¨
                bboxes = [[x, y, w, h]]
                class_labels = ['character']
                
                # å¤‰æ›é©ç”¨
                transform = self.augmentation_pipeline[aug_type]
                transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)
                
                # çµæœå–å¾—
                aug_image = transformed['image']
                transformed_bboxes = transformed['bboxes']
                
                if not transformed_bboxes:
                    # å¤‰æ›å¾Œã«bboxãŒæ¶ˆå¤±ã—ãŸå ´åˆ
                    return aug_image, (0, 0, 0, 0), 0.0
                
                new_bbox = tuple(map(int, transformed_bboxes[0]))
            else:
                # åŸºæœ¬å¤‰æ›ä½¿ç”¨
                transform_func = self.augmentation_pipeline[aug_type]
                aug_image, new_bbox = transform_func(image, bbox)
            
            # bboxå¤‰åŒ–ç‡è¨ˆç®—
            original_area = w * h
            new_area = new_bbox[2] * new_bbox[3]
            area_change_ratio = abs(new_area - original_area) / max(original_area, 1)
            
            # å¼·åº¦ä¿‚æ•°è¨ˆç®—ï¼ˆç”»åƒå¤‰åŒ–ã®ç¨‹åº¦ï¼‰
            intensity_factor = self.calculate_image_change_intensity(image, aug_image)
            
            # ä¿¡é ¼åº¦è¨ˆç®—
            confidence = self.calculate_confidence_score(aug_type, area_change_ratio, intensity_factor)
            
            return aug_image, new_bbox, confidence
            
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
            return image, bbox, 0.0
    
    def calculate_image_change_intensity(self, original: np.ndarray, augmented: np.ndarray) -> float:
        """ç”»åƒå¤‰åŒ–å¼·åº¦è¨ˆç®—"""
        try:
            # MSEè¨ˆç®—
            mse = np.mean((original.astype(float) - augmented.astype(float)) ** 2)
            # æ­£è¦åŒ–ï¼ˆ0-1ç¯„å›²ï¼‰
            intensity = min(mse / 1000.0, 1.0)
            return intensity
        except:
            return 0.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    def generate_pseudo_labels(self) -> DataExpansionResult:
        """ç–‘ä¼¼ãƒ©ãƒ™ãƒ«ç”Ÿæˆãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        try:
            logger.info("ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé–‹å§‹")
            start_time = time.time()
            
            original_count = len(self.original_labels)
            target_generated = int(original_count * (self.target_expansion_ratio - 1))
            
            pseudo_labels = []
            augmentation_stats = {'light': 0, 'medium': 0, 'strong': 0}
            quality_distribution = {'high': 0, 'medium': 0, 'low': 0}
            
            generated_count = 0
            
            # å„ç”»åƒã«å¯¾ã—ã¦è¤‡æ•°ã®æ‹¡å¼µã‚’ç”Ÿæˆ
            augmentations_per_image = max(1, target_generated // original_count)
            
            for image_id, label_data in self.original_labels.items():
                if generated_count >= target_generated:
                    break
                
                # å…ƒç”»åƒèª­ã¿è¾¼ã¿
                image_path = self.find_image_file(image_id)
                if not image_path:
                    logger.warning(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_id}")
                    continue
                
                image = cv2.imread(str(image_path))
                if image is None:
                    logger.warning(f"ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—: {image_path}")
                    continue
                
                original_bbox = tuple(label_data['red_box_coords'])
                
                # è¤‡æ•°ã®æ‹¡å¼µã‚’ç”Ÿæˆ
                for aug_idx in range(augmentations_per_image):
                    if generated_count >= target_generated:
                        break
                    
                    # æ‹¡å¼µã‚¿ã‚¤ãƒ—é¸æŠï¼ˆæ®µéšçš„ã«å¼·åº¦ã‚’ä¸Šã’ã‚‹ï¼‰
                    if aug_idx == 0:
                        aug_type = 'light'
                    elif aug_idx <= 2:
                        aug_type = 'medium'
                    else:
                        aug_type = 'strong'
                    
                    # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé©ç”¨
                    aug_image, transformed_bbox, confidence = self.apply_augmentation(
                        image, original_bbox, aug_type
                    )
                    
                    # ç„¡åŠ¹ãªçµæœã¯ã‚¹ã‚­ãƒƒãƒ—
                    if transformed_bbox == (0, 0, 0, 0) or confidence < 0.1:
                        continue
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                    aug_image_id = f"{image_id}_aug_{aug_type}_{aug_idx:02d}"
                    aug_image_path = self.images_dir / f"{aug_image_id}.png"
                    
                    cv2.imwrite(str(aug_image_path), aug_image)
                    
                    # å“è³ªåˆ†é¡
                    if confidence >= 0.8:
                        quality = 'high'
                    elif confidence >= 0.6:
                        quality = 'medium'
                    else:
                        quality = 'low'
                    
                    # ç–‘ä¼¼ãƒ©ãƒ™ãƒ«ä½œæˆ
                    pseudo_label = PseudoLabel(
                        image_id=aug_image_id,
                        source_image_path=str(image_path),
                        augmented_image_path=str(aug_image_path),
                        original_bbox=original_bbox,
                        transformed_bbox=transformed_bbox,
                        confidence_score=confidence,
                        augmentation_type=aug_type,
                        requires_manual_review=confidence < self.manual_review_threshold,
                        notes=f"Generated from {image_id} using {aug_type} augmentation"
                    )
                    
                    pseudo_labels.append(pseudo_label)
                    augmentation_stats[aug_type] += 1
                    quality_distribution[quality] += 1
                    generated_count += 1
                    
                    # æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡ã¯åˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚‚ã‚³ãƒ”ãƒ¼
                    if pseudo_label.requires_manual_review:
                        review_path = self.review_dir / f"{aug_image_id}.png"
                        shutil.copy2(aug_image_path, review_path)
                
                # é€²æ—è¡¨ç¤º
                if (len(pseudo_labels) % 50) == 0:
                    logger.info(f"ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé€²è¡Œä¸­: {len(pseudo_labels)}/{target_generated} ç”Ÿæˆæ¸ˆã¿")
            
            # ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            self.save_pseudo_labels(pseudo_labels)
            
            # çµæœä½œæˆ
            result = DataExpansionResult(
                original_count=original_count,
                generated_count=len(pseudo_labels),
                total_count=original_count + len(pseudo_labels),
                expansion_ratio=(original_count + len(pseudo_labels)) / original_count,
                pseudo_labels=pseudo_labels,
                augmentation_stats=augmentation_stats,
                quality_distribution=quality_distribution
            )
            
            total_time = time.time() - start_time
            logger.info(f"ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå®Œäº†: {len(pseudo_labels)}ä»¶ç”Ÿæˆ ({total_time:.1f}ç§’)")
            
            return result
            
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def find_image_file(self, image_id: str) -> Optional[Path]:
        """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢"""
        possible_extensions = ['.png', '.jpg', '.jpeg']
        search_dirs = [
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å ´æ‰€ï¼ˆå„ªå…ˆï¼‰
            Path("/mnt/c/AItools/lora/train/yado/org/kana05_cursor"),
            Path("/mnt/c/AItools/lora/train/yado/org/kana07_cursor"), 
            Path("/mnt/c/AItools/lora/train/yado/org/kana08_cursor"),
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ãƒ‘ã‚¹
            self.project_root / "test_small",
            self.project_root,
        ]
        
        for directory in search_dirs:
            for ext in possible_extensions:
                image_path = directory / f"{image_id}{ext}"
                if image_path.exists():
                    return image_path
        
        return None
    
    def save_pseudo_labels(self, pseudo_labels: List[PseudoLabel]):
        """ç–‘ä¼¼ãƒ©ãƒ™ãƒ«ä¿å­˜"""
        try:
            # JSONå½¢å¼ã§ä¿å­˜
            labels_data = {
                pl.image_id: {
                    'red_box_coords': list(pl.transformed_bbox),
                    'confidence_score': pl.confidence_score,
                    'augmentation_type': pl.augmentation_type,
                    'requires_manual_review': pl.requires_manual_review,
                    'source_image_id': pl.image_id.split('_aug_')[0],
                    'original_bbox': list(pl.original_bbox),
                    'notes': pl.notes
                }
                for pl in pseudo_labels
            }
            
            # è©³ç´°ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆnumpyé…åˆ—ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›ï¼‰
            detailed_file = self.labels_dir / "pseudo_labels_detailed.json"
            detailed_data = []
            for pl in pseudo_labels:
                pl_dict = asdict(pl)
                # numpyé…åˆ—ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›
                if hasattr(pl_dict.get('mask'), 'tolist'):
                    pl_dict['mask'] = None  # ãƒã‚¹ã‚¯ã¯å·¨å¤§ãªãŸã‚ä¿å­˜ã—ãªã„
                detailed_data.append(pl_dict)
            
            with open(detailed_file, 'w', encoding='utf-8') as f:
                json.dump(detailed_data, f, indent=2, ensure_ascii=False)
            
            # ç°¡æ˜“ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ—¢å­˜å½¢å¼äº’æ›ï¼‰
            simple_file = self.labels_dir / "pseudo_labels_simple.json"
            with open(simple_file, 'w', encoding='utf-8') as f:
                json.dump(labels_data, f, indent=2, ensure_ascii=False)
            
            # çµ±åˆãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ + ç–‘ä¼¼ãƒ©ãƒ™ãƒ«ï¼‰
            combined_data = {**self.original_labels, **labels_data}
            combined_file = self.labels_dir / "combined_labels.json"
            with open(combined_file, 'w', encoding='utf-8') as f:
                json.dump(combined_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ç–‘ä¼¼ãƒ©ãƒ™ãƒ«ä¿å­˜: {len(pseudo_labels)}ä»¶")
            
        except Exception as e:
            logger.error(f"ç–‘ä¼¼ãƒ©ãƒ™ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def create_expansion_report(self, result: DataExpansionResult) -> str:
        """ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        
        manual_review_count = sum(1 for pl in result.pseudo_labels if pl.requires_manual_review)
        
        report = f"""# Phase 1 ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ¬ãƒãƒ¼ãƒˆ

**å®Ÿè¡Œæ—¥æ™‚**: {time.strftime('%Y-%m-%d %H:%M:%S')}

---

## ğŸ“Š æ‹¡å¼µçµæœã‚µãƒãƒªãƒ¼

### ãƒ‡ãƒ¼ã‚¿æ•°
- **å…ƒãƒ‡ãƒ¼ã‚¿**: {result.original_count}ä»¶
- **ç”Ÿæˆãƒ‡ãƒ¼ã‚¿**: {result.generated_count}ä»¶
- **ç·ãƒ‡ãƒ¼ã‚¿æ•°**: {result.total_count}ä»¶
- **æ‹¡å¼µå€ç‡**: {result.expansion_ratio:.1f}å€

### å“è³ªåˆ†å¸ƒ
"""
        
        for quality, count in result.quality_distribution.items():
            percentage = (count / result.generated_count) * 100 if result.generated_count > 0 else 0
            report += f"- **{quality.upper()}å“è³ª**: {count}ä»¶ ({percentage:.1f}%)\n"
        
        report += f"""

### æ‹¡å¼µæ‰‹æ³•åˆ†å¸ƒ
"""
        
        for aug_type, count in result.augmentation_stats.items():
            percentage = (count / result.generated_count) * 100 if result.generated_count > 0 else 0
            report += f"- **{aug_type.upper()}å¤‰æ›**: {count}ä»¶ ({percentage:.1f}%)\n"
        
        report += f"""

---

## ğŸ” å“è³ªç®¡ç†

### æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡
- **è¦ãƒ¬ãƒ“ãƒ¥ãƒ¼**: {manual_review_count}ä»¶
- **ãƒ¬ãƒ“ãƒ¥ãƒ¼ç‡**: {manual_review_count/result.generated_count*100:.1f}%
- **ãƒ¬ãƒ“ãƒ¥ãƒ¼åŸºæº–**: ä¿¡é ¼åº¦ < {self.manual_review_threshold}

### ä¿¡é ¼åº¦çµ±è¨ˆ
"""
        
        confidences = [pl.confidence_score for pl in result.pseudo_labels]
        if confidences:
            report += f"""- **å¹³å‡ä¿¡é ¼åº¦**: {np.mean(confidences):.3f}
- **ä¿¡é ¼åº¦ç¯„å›²**: {min(confidences):.3f} - {max(confidences):.3f}
- **æ¨™æº–åå·®**: {np.std(confidences):.3f}
"""
        
        report += f"""

---

## ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ
```
expanded_dataset/
â”œâ”€â”€ images/              # æ‹¡å¼µç”»åƒ ({result.generated_count}ä»¶)
â”œâ”€â”€ labels/              # ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”œâ”€â”€ pseudo_labels_detailed.json
â”‚   â”œâ”€â”€ pseudo_labels_simple.json  
â”‚   â””â”€â”€ combined_labels.json
â””â”€â”€ manual_review/       # æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡ ({manual_review_count}ä»¶)
```

### é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«
- **combined_labels.json**: å…ƒãƒ‡ãƒ¼ã‚¿ + ç–‘ä¼¼ãƒ©ãƒ™ãƒ«çµ±åˆç‰ˆï¼ˆPhase 1å­¦ç¿’ç”¨ï¼‰
- **manual_review/**: ä¿¡é ¼åº¦ã®ä½ã„ç”»åƒï¼ˆäººæ‰‹ç¢ºèªæ¨å¥¨ï¼‰

---

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### å³åº§ã«å®Ÿè¡Œ
1. **æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼**: `manual_review/`ã®{manual_review_count}ä»¶ã‚’ç¢ºèª
2. **å“è³ªç¢ºèª**: ä½ä¿¡é ¼åº¦ã‚µãƒ³ãƒ—ãƒ«ã®ç›®è¦–ç¢ºèª
3. **Phase 1å­¦ç¿’æº–å‚™**: `combined_labels.json`ã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒæ¤œå‡ºãƒãƒƒãƒˆå­¦ç¿’é–‹å§‹

### Phase 1å­¦ç¿’è¨­å®š
- **å­¦ç¿’ãƒ‡ãƒ¼ã‚¿**: {result.total_count}ä»¶
- **æ¤œè¨¼åˆ†å‰²**: Stratified 5-fold CVæ¨å¥¨
- **ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼**: `combined_labels.json`ä½¿ç”¨

---

*Generated by Data Expansion System v1.0*
"""
        
        return report


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
    logging.basicConfig(level=logging.INFO)
    
    project_root = Path("/mnt/c/AItools/segment-anything")
    
    # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    expansion_system = DataExpansionSystem(project_root)
    
    # ç–‘ä¼¼ãƒ©ãƒ™ãƒ«ç”Ÿæˆå®Ÿè¡Œ
    result = expansion_system.generate_pseudo_labels()
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = expansion_system.create_expansion_report(result)
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    report_file = expansion_system.output_dir / f"expansion_report_{time.strftime('%Y%m%d_%H%M%S')}.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("\n" + "="*60)
    print("ğŸ“Š Phase 1 ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå®Œäº†")
    print("="*60)
    print(f"å…ƒãƒ‡ãƒ¼ã‚¿: {result.original_count}ä»¶")
    print(f"ç”Ÿæˆãƒ‡ãƒ¼ã‚¿: {result.generated_count}ä»¶")
    print(f"æ‹¡å¼µå€ç‡: {result.expansion_ratio:.1f}å€")
    print(f"æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡: {sum(1 for pl in result.pseudo_labels if pl.requires_manual_review)}ä»¶")
    print(f"ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")


if __name__ == "__main__":
    main()