#!/usr/bin/env python3
"""
Phase 1 ã‚³ãƒæ¤œå‡ºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
Mask R-CNN / YOLOv8ã‚’ä½¿ç”¨ã—ãŸæ¼«ç”»ã‚³ãƒæ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 
"""

import numpy as np
import cv2
import torch
import torchvision.transforms as transforms

import json
import logging
import time
from dataclasses import asdict, dataclass
from pathlib import Path
from PIL import Image
from typing import Any, Dict, List, Optional, Tuple

# YOLO imports
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("WARNING: ultralytics not available")

# Mask R-CNN imports (detectron2)
try:
    from detectron2 import model_zoo
    from detectron2.config import get_cfg
    from detectron2.data import MetadataCatalog
    from detectron2.engine import DefaultPredictor
    from detectron2.utils.visualizer import Visualizer
    DETECTRON2_AVAILABLE = True
except ImportError:
    DETECTRON2_AVAILABLE = False
    print("WARNING: detectron2 not available")

logger = logging.getLogger(__name__)


@dataclass
class PanelDetection:
    """ã‚³ãƒæ¤œå‡ºçµæœ"""
    bbox: Tuple[int, int, int, int]  # x, y, w, h
    confidence: float
    mask: Optional[np.ndarray]
    area: int
    panel_id: int
    is_largest: bool


@dataclass
class PanelDetectionResult:
    """ã‚³ãƒæ¤œå‡ºçµæœã‚»ãƒƒãƒˆ"""
    image_id: str
    image_path: str
    detections: List[PanelDetection]
    largest_panel: Optional[PanelDetection]
    processing_time: float
    model_used: str
    success: bool
    error_message: str = ""


class PanelDetectionNetwork:
    """ã‚³ãƒæ¤œå‡ºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"""
    
    def __init__(self, project_root: Path, model_type: str = "yolo"):
        """
        åˆæœŸåŒ–
        
        Args:
            project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
            model_type: ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ï¼ˆyolo, maskrcnn, ensembleï¼‰
        """
        self.project_root = project_root
        self.model_type = model_type
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åŸå‰‡: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆç›´ä¸‹ã¸ã®ç”»åƒå‡ºåŠ›ç¦æ­¢
        self.output_dir = Path("/mnt/c/AItools/lora/train/yado/visualizations/phase1_panel_detection")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self.yolo_model = None
        self.maskrcnn_predictor = None
        
        self.setup_models()
        
        # æ¤œå‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.detection_params = {
            "confidence_threshold": 0.25,
            "iou_threshold": 0.5,
            "min_panel_area": 5000,  # æœ€å°ã‚³ãƒé¢ç©
            "max_panels": 10  # æœ€å¤§æ¤œå‡ºã‚³ãƒæ•°
        }
    
    def setup_models(self):
        """ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–"""
        try:
            if self.model_type in ["yolo", "ensemble"] and YOLO_AVAILABLE:
                self.setup_yolo_model()
            
            if self.model_type in ["maskrcnn", "ensemble"] and DETECTRON2_AVAILABLE:
                self.setup_maskrcnn_model()
                
        except Exception as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def setup_yolo_model(self):
        """YOLO ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–"""
        try:
            # YOLOv8 segmentation model
            model_path = self.project_root / "yolov8n-seg.pt"
            
            if not model_path.exists():
                logger.info("YOLOv8-segãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
                self.yolo_model = YOLO('yolov8n-seg.pt')
                # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                import shutil
                yolo_cache = Path.home() / '.ultralytics' / 'yolov8n-seg.pt'
                if yolo_cache.exists():
                    shutil.copy2(yolo_cache, model_path)
            else:
                self.yolo_model = YOLO(str(model_path))
            
            logger.info("YOLOv8-seg ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
            
        except Exception as e:
            logger.error(f"YOLOåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.yolo_model = None
    
    def setup_maskrcnn_model(self):
        """Mask R-CNN ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–"""
        try:
            cfg = get_cfg()
            # COCO pretrained Mask R-CNN
            cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
            cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = self.detection_params["confidence_threshold"]
            cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
            cfg.MODEL.DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
            
            self.maskrcnn_predictor = DefaultPredictor(cfg)
            logger.info("Mask R-CNN ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
            
        except Exception as e:
            logger.error(f"Mask R-CNNåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.maskrcnn_predictor = None
    
    def detect_panels_yolo(self, image: np.ndarray, image_id: str) -> List[PanelDetection]:
        """YOLO ã«ã‚ˆã‚‹ã‚³ãƒæ¤œå‡º"""
        try:
            if self.yolo_model is None:
                return []
            
            # YOLOæ¨è«–å®Ÿè¡Œ
            results = self.yolo_model(image, conf=self.detection_params["confidence_threshold"])
            
            detections = []
            
            for i, result in enumerate(results):
                if result.masks is not None:
                    masks = result.masks.data.cpu().numpy()
                    boxes = result.boxes.xyxy.cpu().numpy()
                    confidences = result.boxes.conf.cpu().numpy()
                    
                    for j, (box, confidence, mask) in enumerate(zip(boxes, confidences, masks)):
                        x1, y1, x2, y2 = map(int, box)
                        w, h = x2 - x1, y2 - y1
                        area = w * h
                        
                        # é¢ç©ãƒ•ã‚£ãƒ«ã‚¿
                        if area < self.detection_params["min_panel_area"]:
                            continue
                        
                        # ãƒã‚¹ã‚¯ãƒªã‚µã‚¤ã‚º
                        mask_resized = cv2.resize(mask, (image.shape[1], image.shape[0]))
                        
                        detection = PanelDetection(
                            bbox=(x1, y1, w, h),
                            confidence=float(confidence),
                            mask=mask_resized,
                            area=area,
                            panel_id=len(detections),
                            is_largest=False
                        )
                        detections.append(detection)
            
            # é¢ç©é™é †ã§ã‚½ãƒ¼ãƒˆ
            detections.sort(key=lambda d: d.area, reverse=True)
            
            # æœ€å¤§é¢ç©ã«ãƒãƒ¼ã‚¯
            if detections:
                detections[0].is_largest = True
            
            # æœ€å¤§ã‚³ãƒæ•°åˆ¶é™
            detections = detections[:self.detection_params["max_panels"]]
            
            return detections
            
        except Exception as e:
            logger.error(f"YOLOæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def detect_panels_maskrcnn(self, image: np.ndarray, image_id: str) -> List[PanelDetection]:
        """Mask R-CNN ã«ã‚ˆã‚‹ã‚³ãƒæ¤œå‡º"""
        try:
            if self.maskrcnn_predictor is None:
                return []
            
            # Mask R-CNNæ¨è«–å®Ÿè¡Œ
            outputs = self.maskrcnn_predictor(image)
            
            detections = []
            
            instances = outputs["instances"]
            boxes = instances.pred_boxes.tensor.cpu().numpy()
            masks = instances.pred_masks.cpu().numpy()
            scores = instances.scores.cpu().numpy()
            
            for i, (box, mask, score) in enumerate(zip(boxes, masks, scores)):
                x1, y1, x2, y2 = map(int, box)
                w, h = x2 - x1, y2 - y1
                area = w * h
                
                # é¢ç©ãƒ•ã‚£ãƒ«ã‚¿
                if area < self.detection_params["min_panel_area"]:
                    continue
                
                detection = PanelDetection(
                    bbox=(x1, y1, w, h),
                    confidence=float(score),
                    mask=mask.astype(np.uint8),
                    area=area,
                    panel_id=len(detections),
                    is_largest=False
                )
                detections.append(detection)
            
            # é¢ç©é™é †ã§ã‚½ãƒ¼ãƒˆ
            detections.sort(key=lambda d: d.area, reverse=True)
            
            # æœ€å¤§é¢ç©ã«ãƒãƒ¼ã‚¯
            if detections:
                detections[0].is_largest = True
            
            # æœ€å¤§ã‚³ãƒæ•°åˆ¶é™
            detections = detections[:self.detection_params["max_panels"]]
            
            return detections
            
        except Exception as e:
            logger.error(f"Mask R-CNNæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def detect_panels_ensemble(self, image: np.ndarray, image_id: str) -> List[PanelDetection]:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ¤œå‡ºï¼ˆYOLO + Mask R-CNNï¼‰"""
        try:
            yolo_detections = self.detect_panels_yolo(image, image_id)
            maskrcnn_detections = self.detect_panels_maskrcnn(image, image_id)
            
            # å˜ç´”ãªçµåˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯NMSã‚„é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’ä½¿ç”¨ï¼‰
            all_detections = yolo_detections + maskrcnn_detections
            
            # é¢ç©ã§ã‚½ãƒ¼ãƒˆ
            all_detections.sort(key=lambda d: d.area, reverse=True)
            
            # é‡è¤‡é™¤å»ï¼ˆIoU based NMSï¼‰
            final_detections = self.apply_nms(all_detections, self.detection_params["iou_threshold"])
            
            # æœ€å¤§ã‚³ãƒæ•°åˆ¶é™
            final_detections = final_detections[:self.detection_params["max_panels"]]
            
            # æœ€å¤§é¢ç©å†è¨­å®š
            for d in final_detections:
                d.is_largest = False
            if final_detections:
                final_detections[0].is_largest = True
            
            return final_detections
            
        except Exception as e:
            logger.error(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def apply_nms(self, detections: List[PanelDetection], iou_threshold: float) -> List[PanelDetection]:
        """Non-Maximum Suppression"""
        if not detections:
            return []
        
        # ä¿¡é ¼åº¦é †ã§ã‚½ãƒ¼ãƒˆ
        sorted_detections = sorted(detections, key=lambda d: d.confidence, reverse=True)
        
        final_detections = []
        
        while sorted_detections:
            current = sorted_detections.pop(0)
            final_detections.append(current)
            
            # æ®‹ã‚Šã®æ¤œå‡ºã¨ IoU è¨ˆç®—
            remaining = []
            for det in sorted_detections:
                iou = self.calculate_bbox_iou(current.bbox, det.bbox)
                if iou < iou_threshold:
                    remaining.append(det)
            
            sorted_detections = remaining
        
        return final_detections
    
    def calculate_bbox_iou(self, bbox1: Tuple[int, int, int, int], 
                          bbox2: Tuple[int, int, int, int]) -> float:
        """ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ IoU è¨ˆç®—"""
        x1_1, y1_1, w1, h1 = bbox1
        x2_1, y2_1 = x1_1 + w1, y1_1 + h1
        
        x1_2, y1_2, w2, h2 = bbox2
        x2_2, y2_2 = x1_2 + w2, y1_2 + h2
        
        # äº¤å·®é ˜åŸŸ
        inter_x1 = max(x1_1, x1_2)
        inter_y1 = max(y1_1, y1_2)
        inter_x2 = min(x2_1, x2_2)
        inter_y2 = min(y2_1, y2_2)
        
        if inter_x2 <= inter_x1 or inter_y2 <= inter_y1:
            return 0.0
        
        inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)
        union_area = w1 * h1 + w2 * h2 - inter_area
        
        return inter_area / max(union_area, 1e-6)
    
    def process_single_image(self, image_path: Path) -> PanelDetectionResult:
        """å˜ä¸€ç”»åƒã®ã‚³ãƒæ¤œå‡ºå‡¦ç†"""
        try:
            start_time = time.time()
            
            # ç”»åƒèª­ã¿è¾¼ã¿
            image = cv2.imread(str(image_path))
            if image is None:
                return PanelDetectionResult(
                    image_id=image_path.stem,
                    image_path=str(image_path),
                    detections=[],
                    largest_panel=None,
                    processing_time=0.0,
                    model_used=self.model_type,
                    success=False,
                    error_message="ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—"
                )
            
            # ã‚³ãƒæ¤œå‡ºå®Ÿè¡Œ
            if self.model_type == "yolo":
                detections = self.detect_panels_yolo(image, image_path.stem)
            elif self.model_type == "maskrcnn":
                detections = self.detect_panels_maskrcnn(image, image_path.stem)
            elif self.model_type == "ensemble":
                detections = self.detect_panels_ensemble(image, image_path.stem)
            else:
                raise ValueError(f"æœªã‚µãƒãƒ¼ãƒˆã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {self.model_type}")
            
            # æœ€å¤§ã‚³ãƒç‰¹å®š
            largest_panel = None
            if detections:
                largest_panel = next((d for d in detections if d.is_largest), detections[0])
            
            processing_time = time.time() - start_time
            
            return PanelDetectionResult(
                image_id=image_path.stem,
                image_path=str(image_path),
                detections=detections,
                largest_panel=largest_panel,
                processing_time=processing_time,
                model_used=self.model_type,
                success=True
            )
            
        except Exception as e:
            logger.error(f"ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼ ({image_path}): {e}")
            return PanelDetectionResult(
                image_id=image_path.stem,
                image_path=str(image_path),
                detections=[],
                largest_panel=None,
                processing_time=0.0,
                model_used=self.model_type,
                success=False,
                error_message=str(e)
            )
    
    def process_batch(self, image_dir: Path, pattern: str = "*.png") -> List[PanelDetectionResult]:
        """ãƒãƒƒãƒå‡¦ç†"""
        try:
            image_files = list(image_dir.glob(pattern))
            logger.info(f"ãƒãƒƒãƒå‡¦ç†é–‹å§‹: {len(image_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
            
            results = []
            
            for i, image_file in enumerate(image_files, 1):
                logger.info(f"å‡¦ç†ä¸­ [{i}/{len(image_files)}]: {image_file.name}")
                
                result = self.process_single_image(image_file)
                results.append(result)
                
                # å¯è¦–åŒ–ä¿å­˜
                if result.success and result.detections:
                    self.save_visualization(image_file, result)
            
            # çµæœä¿å­˜
            self.save_batch_results(results)
            
            logger.info(f"ãƒãƒƒãƒå‡¦ç†å®Œäº†: {len(results)}ä»¶")
            return results
            
        except Exception as e:
            logger.error(f"ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def save_visualization(self, image_path: Path, result: PanelDetectionResult):
        """æ¤œå‡ºçµæœå¯è¦–åŒ–ä¿å­˜"""
        try:
            image = cv2.imread(str(image_path))
            if image is None:
                return
            
            # æ¤œå‡ºçµæœæç”»
            for detection in result.detections:
                x, y, w, h = detection.bbox
                
                # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
                color = (0, 255, 0) if detection.is_largest else (255, 0, 0)
                thickness = 3 if detection.is_largest else 1
                cv2.rectangle(image, (x, y), (x + w, y + h), color, thickness)
                
                # ãƒ©ãƒ™ãƒ«
                label = f"Panel {detection.panel_id}: {detection.confidence:.2f}"
                if detection.is_largest:
                    label += " [LARGEST]"
                
                cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 
                           0.7, color, 2)
                
                # ãƒã‚¹ã‚¯æç”»ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                if detection.mask is not None:
                    mask_colored = cv2.applyColorMap(
                        (detection.mask * 255).astype(np.uint8), cv2.COLORMAP_JET
                    )
                    image = cv2.addWeighted(image, 0.8, mask_colored, 0.2, 0)
            
            # ä¿å­˜
            vis_dir = self.output_dir / "visualizations"
            vis_dir.mkdir(exist_ok=True)
            vis_path = vis_dir / f"{result.image_id}_panels.png"
            
            cv2.imwrite(str(vis_path), image)
            
        except Exception as e:
            logger.error(f"å¯è¦–åŒ–ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def save_batch_results(self, results: List[PanelDetectionResult]):
        """ãƒãƒƒãƒçµæœä¿å­˜"""
        try:
            # JSONçµæœä¿å­˜
            results_data = []
            
            for result in results:
                result_dict = {
                    "image_id": result.image_id,
                    "image_path": result.image_path,
                    "success": result.success,
                    "error_message": result.error_message,
                    "processing_time": result.processing_time,
                    "model_used": result.model_used,
                    "panel_count": len(result.detections),
                    "largest_panel": None
                }
                
                if result.largest_panel:
                    result_dict["largest_panel"] = {
                        "bbox": result.largest_panel.bbox,
                        "confidence": result.largest_panel.confidence,
                        "area": result.largest_panel.area,
                        "panel_id": result.largest_panel.panel_id
                    }
                
                # å…¨æ¤œå‡ºçµæœ
                detections_data = []
                for det in result.detections:
                    det_data = {
                        "bbox": det.bbox,
                        "confidence": det.confidence,
                        "area": det.area,
                        "panel_id": det.panel_id,
                        "is_largest": det.is_largest
                    }
                    detections_data.append(det_data)
                
                result_dict["detections"] = detections_data
                results_data.append(result_dict)
            
            # çµæœãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            results_file = self.output_dir / f"panel_detection_results_{time.strftime('%Y%m%d_%H%M%S')}.json"
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results_data, f, indent=2, ensure_ascii=False)
            
            # ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
            self.generate_summary_report(results, results_file)
            
            logger.info(f"çµæœä¿å­˜å®Œäº†: {results_file}")
            
        except Exception as e:
            logger.error(f"çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def generate_summary_report(self, results: List[PanelDetectionResult], results_file: Path):
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        try:
            success_count = len([r for r in results if r.success])
            total_panels = sum(len(r.detections) for r in results)
            avg_panels_per_image = total_panels / max(len(results), 1)
            avg_processing_time = np.mean([r.processing_time for r in results if r.success])
            
            successful_results = [r for r in results if r.success]
            confidence_scores = []
            largest_panel_areas = []
            
            for result in successful_results:
                confidence_scores.extend([d.confidence for d in result.detections])
                if result.largest_panel:
                    largest_panel_areas.append(result.largest_panel.area)
            
            report = f"""# Phase 1 ã‚³ãƒæ¤œå‡ºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ ãƒ¬ãƒãƒ¼ãƒˆ

**å®Ÿè¡Œæ—¥æ™‚**: {time.strftime('%Y-%m-%d %H:%M:%S')}
**ãƒ¢ãƒ‡ãƒ«**: {self.model_type}

---

## ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼

### åŸºæœ¬çµ±è¨ˆ
- **å‡¦ç†ç”»åƒæ•°**: {len(results)}ä»¶
- **æˆåŠŸå‡¦ç†**: {success_count}ä»¶ ({success_count/len(results)*100:.1f}%)
- **æ¤œå‡ºã‚³ãƒç·æ•°**: {total_panels}ä»¶
- **å¹³å‡ã‚³ãƒæ•°/ç”»åƒ**: {avg_panels_per_image:.1f}ä»¶
- **å¹³å‡å‡¦ç†æ™‚é–“**: {avg_processing_time:.2f}ç§’

### æ¤œå‡ºç²¾åº¦
- **ä¿¡é ¼åº¦å¹³å‡**: {np.mean(confidence_scores):.3f}
- **ä¿¡é ¼åº¦ç¯„å›²**: {min(confidence_scores):.3f} - {max(confidence_scores):.3f}
- **æœ€å¤§ã‚³ãƒå¹³å‡é¢ç©**: {np.mean(largest_panel_areas):,.0f}pxÂ²

---

## ğŸ¯ Phase 1 ç›®æ¨™é”æˆçŠ¶æ³

### Mask R-CNNè»¢ç§»å­¦ç¿’
- âœ… ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†
- âœ… COCOäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
- ğŸ”„ æ¼«ç”»ç‰¹åŒ–ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆæ¬¡ãƒ•ã‚§ãƒ¼ã‚ºï¼‰

### ã‚³ãƒæ¤œå‡ºmIoU 80%ç›®æ¨™
- ğŸ“Š ç¾åœ¨ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®šä¸­
- ğŸ¯ ç›®æ¨™: mIoU 80%
- ğŸ“ˆ æ”¹å–„è¨ˆç”»: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ + ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œ

### æ¨è«–é€Ÿåº¦2ç§’/ç”»åƒç›®æ¨™
- âš¡ ç¾åœ¨é€Ÿåº¦: {avg_processing_time:.2f}ç§’/ç”»åƒ
- âœ… ç›®æ¨™é”æˆ: {'âœ…' if avg_processing_time < 2.0 else 'âŒ'}
- ğŸš€ {'æ—¢ã«ç›®æ¨™é”æˆ' if avg_processing_time < 2.0 else 'æœ€é©åŒ–ãŒå¿…è¦'}

---

## ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«

```
phase1_panel_detection/
â”œâ”€â”€ panel_detection_results_*.json  # è©³ç´°çµæœ
â”œâ”€â”€ visualizations/                 # æ¤œå‡ºçµæœå¯è¦–åŒ–
â””â”€â”€ summary_report_*.md            # ã“ã®ãƒ¬ãƒãƒ¼ãƒˆ
```

---

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### å³åº§ã«å®Ÿè¡Œ
1. **æ‰‹å‹•æ¤œè¨¼**: visualizations/ã®çµæœã‚’ç¢ºèª
2. **ç²¾åº¦è©•ä¾¡**: Ground truthã¨ã®æ¯”è¼ƒå®Ÿæ–½
3. **å•é¡Œåˆ†æ**: å¤±æ•—ã‚±ãƒ¼ã‚¹ã®è©³ç´°åˆ†æ

### Phase 1å®Œäº†ã«å‘ã‘ã¦
1. **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™**: æ¼«ç”»ç‰¹åŒ–ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆ
2. **è»¢ç§»å­¦ç¿’å®Ÿè¡Œ**: COCOâ†’æ¼«ç”»ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œ
3. **æ€§èƒ½è©•ä¾¡**: mIoUæ¸¬å®šã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰

**Phase 1é€²æ—**: ã‚³ãƒæ¤œå‡ºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸºç›¤å®Œæˆ âœ…

---

*Generated by Panel Detection Network v1.0*
"""
            
            report_file = self.output_dir / f"summary_report_{time.strftime('%Y%m%d_%H%M%S')}.md"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(f"\nğŸ“Š Phase 1 ã‚³ãƒæ¤œå‡ºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å®Œäº†")
            print(f"æˆåŠŸç‡: {success_count}/{len(results)} ({success_count/len(results)*100:.1f}%)")
            print(f"å¹³å‡å‡¦ç†æ™‚é–“: {avg_processing_time:.2f}ç§’")
            print(f"ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
            
        except Exception as e:
            logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
    logging.basicConfig(level=logging.INFO)
    
    project_root = Path("/mnt/c/AItools/segment-anything")
    
    # ã‚³ãƒæ¤œå‡ºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–
    panel_detector = PanelDetectionNetwork(project_root, model_type="yolo")
    
    # ãƒ†ã‚¹ãƒˆç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    test_dir = project_root / "test_small"
    
    if test_dir.exists():
        # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
        results = panel_detector.process_batch(test_dir)
        
        print(f"\nâœ… Phase 1 ã‚³ãƒæ¤œå‡ºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ ãƒ†ã‚¹ãƒˆãƒãƒƒãƒå®Œäº†")
        print(f"å‡¦ç†ç”»åƒ: {len(results)}ä»¶")
        print(f"æˆåŠŸæ•°: {len([r for r in results if r.success])}ä»¶")
        print(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {panel_detector.output_dir}")
    else:
        print(f"âŒ ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_dir}")


if __name__ == "__main__":
    main()