#!/usr/bin/env python3
"""
Advanced Boundary Detector - Phase 2å¢ƒç•Œèªè­˜å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ 
è¤‡é›‘ãªã‚³ãƒå‰²ã‚Šå°‚ç”¨å‡¦ç†ã¨ã‚¨ãƒƒã‚¸æ¤œå‡ºã®å¤šæ®µéšé©ç”¨
"""

import numpy as np
import cv2

import json
import logging
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


class AdvancedBoundaryDetector:
    """Phase 2å¢ƒç•Œèªè­˜å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self,
                 enable_panel_detection: bool = True,
                 enable_multi_stage_edge: bool = True,
                 enable_boundary_completion: bool = True):
        """
        Args:
            enable_panel_detection: ã‚³ãƒå¢ƒç•Œæ¤œå‡ºã®æœ‰åŠ¹åŒ–
            enable_multi_stage_edge: å¤šæ®µéšã‚¨ãƒƒã‚¸æ¤œå‡ºã®æœ‰åŠ¹åŒ–
            enable_boundary_completion: å¢ƒç•Œè£œå®Œã®æœ‰åŠ¹åŒ–
        """
        self.enable_panel_detection = enable_panel_detection
        self.enable_multi_stage_edge = enable_multi_stage_edge
        self.enable_boundary_completion = enable_boundary_completion
        
        # ã‚¨ãƒƒã‚¸æ¤œå‡ºã®æ®µéšè¨­å®š
        self.edge_stages = [
            {"name": "fine", "low": 30, "high": 80, "weight": 0.4},
            {"name": "medium", "low": 50, "high": 120, "weight": 0.4},
            {"name": "coarse", "low": 80, "high": 180, "weight": 0.2}
        ]
        
        logger.info(f"AdvancedBoundaryDetectoråˆæœŸåŒ–: panel={enable_panel_detection}, "
                   f"multi_edge={enable_multi_stage_edge}, completion={enable_boundary_completion}")

    def enhance_boundaries_advanced(self, 
                                  image: np.ndarray,
                                  mask: Optional[np.ndarray] = None) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        é«˜åº¦å¢ƒç•Œå¼·åŒ–å‡¦ç†
        
        Args:
            image: å…¥åŠ›ç”»åƒ (H, W, 3)
            mask: æ—¢å­˜ãƒã‚¹ã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            
        Returns:
            å¼·åŒ–ã•ã‚ŒãŸç”»åƒã¨åˆ†æçµæœ
        """
        logger.debug(f"é«˜åº¦å¢ƒç•Œå¼·åŒ–é–‹å§‹: {image.shape}")
        
        analysis_result = {
            "panel_info": {},
            "edge_analysis": {},
            "boundary_completion": {},
            "enhancement_quality": 0.0
        }
        
        enhanced_image = image.copy()
        
        # 1. ã‚³ãƒå¢ƒç•Œæ¤œå‡ºãƒ»åˆ†æ
        if self.enable_panel_detection:
            panel_info, panel_enhanced = self._detect_and_process_panels(enhanced_image)
            enhanced_image = panel_enhanced
            analysis_result["panel_info"] = panel_info
        
        # 2. å¤šæ®µéšã‚¨ãƒƒã‚¸æ¤œå‡º
        if self.enable_multi_stage_edge:
            edge_info, edge_enhanced = self._multi_stage_edge_detection(enhanced_image)
            enhanced_image = edge_enhanced
            analysis_result["edge_analysis"] = edge_info
        
        # 3. å¢ƒç•Œè£œå®Œå‡¦ç†
        if self.enable_boundary_completion:
            if mask is not None:
                completion_info, completion_enhanced = self._boundary_completion(enhanced_image, mask)
                enhanced_image = completion_enhanced
                analysis_result["boundary_completion"] = completion_info
        
        # 4. å…¨ä½“çš„ãªå“è³ªè©•ä¾¡
        analysis_result["enhancement_quality"] = self._evaluate_enhancement_quality(
            image, enhanced_image, analysis_result
        )
        
        logger.debug("é«˜åº¦å¢ƒç•Œå¼·åŒ–å®Œäº†")
        return enhanced_image, analysis_result

    def _detect_and_process_panels(self, image: np.ndarray) -> Tuple[Dict[str, Any], np.ndarray]:
        """ã‚³ãƒå¢ƒç•Œæ¤œå‡ºãƒ»å°‚ç”¨å‡¦ç†"""
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        
        # 1. åŸºæœ¬çš„ãªã‚³ãƒå¢ƒç•Œç·šæ¤œå‡º
        # ç¸¦ç·šãƒ»æ¨ªç·šã®æ¤œå‡ºï¼ˆæ¼«ç”»ã®ã‚³ãƒå¢ƒç•Œã¯ç›´ç·šãŒå¤šã„ï¼‰
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
        
        # ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼æ¼”ç®—ã§ç·šã‚’å¼·èª¿
        horizontal_lines = cv2.morphologyEx(gray, cv2.MORPH_OPEN, horizontal_kernel)
        vertical_lines = cv2.morphologyEx(gray, cv2.MORPH_OPEN, vertical_kernel)
        
        # 2. ã‚³ãƒå¢ƒç•Œã®çµ±åˆ
        panel_boundaries = cv2.addWeighted(horizontal_lines, 0.5, vertical_lines, 0.5, 0)
        
        # 3. ã‚³ãƒé ˜åŸŸã®åˆ†å‰²
        panel_regions = self._identify_panel_regions(panel_boundaries, image.shape)
        
        # 4. Lå­—å‹ãƒ»ä¸è¦å‰‡ã‚³ãƒã®æ¤œå‡º
        irregular_panels = self._detect_irregular_panels(panel_boundaries)
        
        # 5. ã‚³ãƒå¤–ã¯ã¿å‡ºã—é ˜åŸŸã®å‡¦ç†
        overflow_regions = self._detect_character_overflow(image, panel_boundaries)
        
        # 6. ã‚³ãƒæƒ…å ±ã«åŸºã¥ãç”»åƒå¼·åŒ–
        enhanced_image = self._enhance_based_on_panels(
            image, panel_regions, irregular_panels, overflow_regions
        )
        
        panel_info = {
            "panel_count": len(panel_regions),
            "irregular_count": len(irregular_panels),
            "overflow_regions": len(overflow_regions),
            "panel_complexity": self._calculate_panel_complexity(panel_boundaries),
            "dominant_panel_type": self._classify_panel_layout(panel_regions)
        }
        
        logger.debug(f"ã‚³ãƒæ¤œå‡ºçµæœ: {panel_info}")
        return panel_info, enhanced_image

    def _identify_panel_regions(self, boundaries: np.ndarray, image_shape: Tuple) -> List[Dict[str, Any]]:
        """ã‚³ãƒé ˜åŸŸã®ç‰¹å®š"""
        height, width = image_shape[:2]
        
        # è¼ªéƒ­æ¤œå‡º
        contours, _ = cv2.findContours(boundaries, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        panel_regions = []
        for i, contour in enumerate(contours):
            area = cv2.contourArea(contour)
            # å°ã•ã™ãã‚‹é ˜åŸŸã¯é™¤å¤–
            if area < (width * height * 0.05):
                continue
            
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = w / h if h > 0 else 1.0
            
            panel_regions.append({
                "id": i,
                "bbox": (x, y, w, h),
                "area": area,
                "aspect_ratio": aspect_ratio,
                "center": (x + w//2, y + h//2),
                "contour": contour
            })
        
        # é¢ç©é †ã§ã‚½ãƒ¼ãƒˆï¼ˆå¤§ãã„ã‚³ãƒã‹ã‚‰å‡¦ç†ï¼‰
        panel_regions.sort(key=lambda x: x["area"], reverse=True)
        
        return panel_regions

    def _detect_irregular_panels(self, boundaries: np.ndarray) -> List[Dict[str, Any]]:
        """Lå­—å‹ãƒ»ä¸è¦å‰‡ã‚³ãƒã®æ¤œå‡º"""
        # è¤‡é›‘ãªå½¢çŠ¶ã®ã‚³ãƒã‚’æ¤œå‡º
        contours, _ = cv2.findContours(boundaries, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        irregular_panels = []
        for i, contour in enumerate(contours):
            # å‡¸åŒ…ã¨å…ƒã®è¼ªéƒ­ã®é¢ç©æ¯”ã§è¤‡é›‘ã•ã‚’åˆ¤å®š
            hull = cv2.convexHull(contour)
            contour_area = cv2.contourArea(contour)
            hull_area = cv2.contourArea(hull)
            
            if hull_area > 0:
                complexity_ratio = contour_area / hull_area
                # è¤‡é›‘ãªå½¢çŠ¶ï¼ˆå‡¹ã¿ãŒå¤šã„ï¼‰ã‚’æ¤œå‡º
                if complexity_ratio < 0.8:
                    approx = cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)
                    
                    irregular_panels.append({
                        "id": i,
                        "contour": contour,
                        "complexity_ratio": complexity_ratio,
                        "vertex_count": len(approx),
                        "type": self._classify_irregular_shape(approx)
                    })
        
        return irregular_panels

    def _classify_irregular_shape(self, approx: np.ndarray) -> str:
        """ä¸è¦å‰‡å½¢çŠ¶ã®åˆ†é¡"""
        vertex_count = len(approx)
        
        if vertex_count <= 4:
            return "rectangular"
        elif vertex_count <= 6:
            return "l_shaped"
        elif vertex_count <= 8:
            return "complex_polygon"
        else:
            return "very_complex"

    def _detect_character_overflow(self, 
                                 image: np.ndarray, 
                                 boundaries: np.ndarray) -> List[Dict[str, Any]]:
        """ã‚³ãƒå¤–ã¯ã¿å‡ºã—ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®æ¤œå‡º"""
        # ã‚¨ãƒƒã‚¸ã®å¼·ã„é ˜åŸŸï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å¯èƒ½æ€§ï¼‰ã‚’æ¤œå‡º
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        
        # å¢ƒç•Œç·šä»˜è¿‘ã§ã‚¨ãƒƒã‚¸ãŒå¼·ã„é ˜åŸŸã‚’æ¢ã™
        boundary_dilated = cv2.dilate(boundaries, np.ones((20, 20), np.uint8), iterations=1)
        
        # å¢ƒç•Œç·šå‘¨è¾ºã®ã‚¨ãƒƒã‚¸ã‚’æŠ½å‡º
        overflow_candidates = cv2.bitwise_and(edges, boundary_dilated)
        
        # é€£çµæˆåˆ†åˆ†æ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(overflow_candidates)
        
        overflow_regions = []
        for i in range(1, num_labels):  # 0ã¯ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰
            area = stats[i, cv2.CC_STAT_AREA]
            if area > 100:  # ååˆ†ãªå¤§ãã•ã®ã‚¨ãƒƒã‚¸å¡Š
                x = stats[i, cv2.CC_STAT_LEFT]
                y = stats[i, cv2.CC_STAT_TOP]
                w = stats[i, cv2.CC_STAT_WIDTH]
                h = stats[i, cv2.CC_STAT_HEIGHT]
                
                overflow_regions.append({
                    "bbox": (x, y, w, h),
                    "area": area,
                    "center": centroids[i],
                    "edge_density": area / (w * h) if w * h > 0 else 0
                })
        
        return overflow_regions

    def _enhance_based_on_panels(self, 
                               image: np.ndarray,
                               panel_regions: List[Dict[str, Any]],
                               irregular_panels: List[Dict[str, Any]],
                               overflow_regions: List[Dict[str, Any]]) -> np.ndarray:
        """ã‚³ãƒæƒ…å ±ã«åŸºã¥ãç”»åƒå¼·åŒ–"""
        enhanced = image.copy().astype(np.float32)
        
        # 1. å„ã‚³ãƒé ˜åŸŸã§ã®é©å¿œçš„å‡¦ç†
        for panel in panel_regions:
            x, y, w, h = panel["bbox"]
            panel_roi = enhanced[y:y+h, x:x+w]
            
            # ã‚³ãƒã‚µã‚¤ã‚ºã«å¿œã˜ãŸå‡¦ç†å¼·åº¦èª¿æ•´
            if panel["area"] < (image.shape[0] * image.shape[1] * 0.2):
                # å°ã•ã„ã‚³ãƒ: ã‚ˆã‚Šå¼·ã„å¼·èª¿
                panel_roi *= 1.15
            else:
                # å¤§ãã„ã‚³ãƒ: æ§ãˆã‚ãªå¼·èª¿
                panel_roi *= 1.05
            
            enhanced[y:y+h, x:x+w] = panel_roi
        
        # 2. ä¸è¦å‰‡ã‚³ãƒã§ã®ç‰¹åˆ¥å‡¦ç†
        for irregular in irregular_panels:
            # è¤‡é›‘ãªå½¢çŠ¶ã®ã‚³ãƒå‘¨è¾ºã®ã‚¨ãƒƒã‚¸ã‚’å¼·åŒ–
            mask = np.zeros(image.shape[:2], dtype=np.uint8)
            cv2.fillPoly(mask, [irregular["contour"]], 255)
            
            # ãƒã‚¹ã‚¯é ˜åŸŸã®ã‚¨ãƒƒã‚¸ã‚’å¼·åŒ–
            gray = cv2.cvtColor(enhanced.astype(np.uint8), cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 30, 100)
            
            # ã‚¨ãƒƒã‚¸éƒ¨åˆ†ã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å‘ä¸Š
            edge_mask = (edges > 0) & (mask > 0)
            for c in range(3):
                channel = enhanced[:, :, c]
                channel[edge_mask] = np.clip(channel[edge_mask] * 1.3, 0, 255)
        
        # 3. ã¯ã¿å‡ºã—é ˜åŸŸã®ä¿è­·å‡¦ç†
        for overflow in overflow_regions:
            x, y, w, h = overflow["bbox"]
            # ã¯ã¿å‡ºã—é ˜åŸŸã®å¢ƒç•Œã‚’æ˜ç¢ºåŒ–
            roi = enhanced[y:y+h, x:x+w]
            roi *= 1.2  # å¼·ã‚ã®å¼·èª¿
            enhanced[y:y+h, x:x+w] = roi
        
        return np.clip(enhanced, 0, 255).astype(np.uint8)

    def _calculate_panel_complexity(self, boundaries: np.ndarray) -> float:
        """ã‚³ãƒå¢ƒç•Œã®è¤‡é›‘ã•ã‚’è¨ˆç®—"""
        # å¢ƒç•Œç·šã®ç·é•·ã•ã¨é¢ç©ã‹ã‚‰è¤‡é›‘ã•ã‚’è©•ä¾¡
        contours, _ = cv2.findContours(boundaries, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        total_perimeter = sum(cv2.arcLength(contour, True) for contour in contours)
        total_area = sum(cv2.contourArea(contour) for contour in contours)
        
        if total_area > 0:
            # å‘¨å›²é•·ã®2ä¹—ã‚’é¢ç©ã§å‰²ã£ãŸå€¤ï¼ˆå††å½¢åº¦ã®é€†æ•°ï¼‰
            complexity = (total_perimeter ** 2) / total_area
            return min(complexity / 100.0, 10.0)  # æ­£è¦åŒ–
        
        return 1.0

    def _classify_panel_layout(self, panel_regions: List[Dict[str, Any]]) -> str:
        """ã‚³ãƒãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®åˆ†é¡"""
        if len(panel_regions) <= 2:
            return "simple"
        elif len(panel_regions) <= 4:
            return "standard"
        elif len(panel_regions) <= 6:
            return "complex"
        else:
            return "very_complex"

    def _multi_stage_edge_detection(self, image: np.ndarray) -> Tuple[Dict[str, Any], np.ndarray]:
        """å¤šæ®µéšã‚¨ãƒƒã‚¸æ¤œå‡º"""
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        
        # å„æ®µéšã§ã®ã‚¨ãƒƒã‚¸æ¤œå‡º
        stage_edges = []
        edge_densities = []
        
        for stage in self.edge_stages:
            edges = cv2.Canny(gray, stage["low"], stage["high"])
            stage_edges.append(edges)
            
            # ã‚¨ãƒƒã‚¸å¯†åº¦è¨ˆç®—
            edge_density = np.sum(edges > 0) / edges.size
            edge_densities.append(edge_density)
        
        # é‡ã¿ä»˜ãçµ±åˆ
        combined_edges = np.zeros_like(stage_edges[0], dtype=np.float32)
        for edges, stage in zip(stage_edges, self.edge_stages):
            combined_edges += edges.astype(np.float32) * stage["weight"]
        
        combined_edges = np.clip(combined_edges, 0, 255).astype(np.uint8)
        
        # ã‚¨ãƒƒã‚¸æƒ…å ±ã«åŸºã¥ãç”»åƒå¼·åŒ–
        enhanced_image = self._enhance_with_edges(image, combined_edges)
        
        edge_info = {
            "stage_densities": edge_densities,
            "combined_density": np.sum(combined_edges > 0) / combined_edges.size,
            "dominant_stage": self.edge_stages[np.argmax(edge_densities)]["name"],
            "edge_uniformity": np.std(edge_densities)
        }
        
        logger.debug(f"å¤šæ®µéšã‚¨ãƒƒã‚¸æ¤œå‡ºçµæœ: {edge_info}")
        return edge_info, enhanced_image

    def _enhance_with_edges(self, image: np.ndarray, edges: np.ndarray) -> np.ndarray:
        """ã‚¨ãƒƒã‚¸æƒ…å ±ã‚’ç”¨ã„ãŸç”»åƒå¼·åŒ–"""
        enhanced = image.copy().astype(np.float32)
        
        # ã‚¨ãƒƒã‚¸éƒ¨åˆ†ã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å¼·åŒ–
        edge_mask = edges > 50
        
        for channel in range(3):
            channel_data = enhanced[:, :, channel]
            # ã‚¨ãƒƒã‚¸éƒ¨åˆ†ã‚’é©åº¦ã«å¼·èª¿
            channel_data[edge_mask] = np.clip(channel_data[edge_mask] * 1.1, 0, 255)
            enhanced[:, :, channel] = channel_data
        
        return enhanced.astype(np.uint8)

    def _boundary_completion(self, 
                           image: np.ndarray, 
                           mask: np.ndarray) -> Tuple[Dict[str, Any], np.ndarray]:
        """å¢ƒç•Œè£œå®Œå‡¦ç†"""
        # ãƒã‚¹ã‚¯ã®å¢ƒç•Œã‚’è§£æ
        if len(mask.shape) == 3:
            mask_gray = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)
        else:
            mask_gray = mask.copy()
        
        # å¢ƒç•Œã®è¼ªéƒ­ã‚’å–å¾—
        contours, _ = cv2.findContours(mask_gray > 0, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            return {"completion_applied": False}, image
        
        main_contour = max(contours, key=cv2.contourArea)
        
        # å¢ƒç•Œã®æ»‘ã‚‰ã‹ã•ã‚’è©•ä¾¡
        smoothness = self._evaluate_boundary_smoothness(main_contour)
        
        enhanced_image = image.copy()
        
        # å¢ƒç•ŒãŒç²—ã„å ´åˆã¯è£œå®Œå‡¦ç†ã‚’é©ç”¨
        if smoothness < 0.8:
            # å¢ƒç•Œå‘¨è¾ºã®å¼·åŒ–
            boundary_mask = np.zeros_like(mask_gray)
            cv2.drawContours(boundary_mask, [main_contour], -1, 255, thickness=3)
            
            # å¢ƒç•Œå‘¨è¾ºã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å¼·åŒ–
            enhanced_image = self._enhance_boundary_region(enhanced_image, boundary_mask)
        
        completion_info = {
            "completion_applied": smoothness < 0.8,
            "boundary_smoothness": smoothness,
            "contour_length": cv2.arcLength(main_contour, True),
            "contour_area": cv2.contourArea(main_contour)
        }
        
        return completion_info, enhanced_image

    def _evaluate_boundary_smoothness(self, contour: np.ndarray) -> float:
        """å¢ƒç•Œã®æ»‘ã‚‰ã‹ã•ã‚’è©•ä¾¡"""
        if len(contour) < 5:
            return 1.0
        
        # è¼ªéƒ­ã®è¿‘ä¼¼ç²¾åº¦ã§æ»‘ã‚‰ã‹ã•ã‚’åˆ¤å®š
        epsilon = 0.02 * cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, epsilon, True)
        
        # è¿‘ä¼¼å¾Œã®é ‚ç‚¹æ•°ãŒå°‘ãªã„ã»ã©æ»‘ã‚‰ã‹
        smoothness = 1.0 - (len(approx) / len(contour))
        return max(0.0, min(1.0, smoothness))

    def _enhance_boundary_region(self, image: np.ndarray, boundary_mask: np.ndarray) -> np.ndarray:
        """å¢ƒç•Œé ˜åŸŸã®å¼·åŒ–"""
        enhanced = image.copy().astype(np.float32)
        
        # å¢ƒç•Œãƒã‚¹ã‚¯ã‚’è†¨å¼µã•ã›ã¦å‘¨è¾ºé ˜åŸŸã‚‚å«ã‚ã‚‹
        kernel = np.ones((5, 5), np.uint8)
        expanded_boundary = cv2.dilate(boundary_mask, kernel, iterations=2)
        
        # å¢ƒç•Œå‘¨è¾ºé ˜åŸŸã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’é©åº¦ã«å¼·åŒ–
        boundary_pixels = expanded_boundary > 0
        
        for channel in range(3):
            channel_data = enhanced[:, :, channel]
            channel_data[boundary_pixels] = np.clip(channel_data[boundary_pixels] * 1.08, 0, 255)
            enhanced[:, :, channel] = channel_data
        
        return enhanced.astype(np.uint8)

    def _evaluate_enhancement_quality(self, 
                                    original: np.ndarray,
                                    enhanced: np.ndarray, 
                                    analysis_result: Dict[str, Any]) -> float:
        """å¼·åŒ–å“è³ªã®ç·åˆè©•ä¾¡"""
        # å„è¦ç´ ã®å“è³ªã‚¹ã‚³ã‚¢
        panel_score = min(1.0, analysis_result["panel_info"].get("panel_count", 0) / 6.0)
        edge_score = analysis_result["edge_analysis"].get("combined_density", 0) * 10.0
        
        completion_score = 1.0
        if analysis_result["boundary_completion"]:
            completion_score = analysis_result["boundary_completion"].get("boundary_smoothness", 1.0)
        
        # é‡ã¿ä»˜ãå¹³å‡
        overall_quality = (panel_score * 0.3 + 
                         min(edge_score, 1.0) * 0.4 + 
                         completion_score * 0.3)
        
        return min(1.0, overall_quality)


def test_advanced_boundary_detector():
    """é«˜åº¦å¢ƒç•Œæ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    detector = AdvancedBoundaryDetector(
        enable_panel_detection=True,
        enable_multi_stage_edge=True,
        enable_boundary_completion=True
    )
    
    # ãƒ†ã‚¹ãƒˆç”»åƒ
    test_image_path = Path("/mnt/c/AItools/lora/train/yado/org/kana08/kana08_0002.jpg")
    if test_image_path.exists():
        image = cv2.imread(str(test_image_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        print(f"ãƒ†ã‚¹ãƒˆç”»åƒèª­ã¿è¾¼ã¿: {image.shape}")
        
        # é«˜åº¦å¢ƒç•Œå¼·åŒ–å®Ÿè¡Œ
        enhanced, analysis = detector.enhance_boundaries_advanced(image)
        
        # åˆ†æçµæœè¡¨ç¤º
        print("\\nğŸ“Š é«˜åº¦å¢ƒç•Œå¼·åŒ–åˆ†æçµæœ:")
        print(f"ã‚³ãƒæƒ…å ±: {analysis['panel_info']}")
        print(f"ã‚¨ãƒƒã‚¸åˆ†æ: {analysis['edge_analysis']}")
        print(f"å¢ƒç•Œè£œå®Œ: {analysis['boundary_completion']}")
        print(f"å…¨ä½“å“è³ª: {analysis['enhancement_quality']:.3f}")
        
        # çµæœä¿å­˜
        output_path = Path("/tmp/advanced_boundary_test.jpg")
        cv2.imwrite(str(output_path), cv2.cvtColor(enhanced, cv2.COLOR_RGB2BGR))
        print(f"\\nğŸ’¾ çµæœä¿å­˜: {output_path}")
    else:
        print(f"ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_image_path}")


if __name__ == "__main__":
    test_advanced_boundary_detector()