#!/usr/bin/env python3
"""
Character Priority Learning System - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å„ªå…ˆé †ä½å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
ä¸»è¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¤å®šã¨ã‚³ãƒå†…ä½ç½®ã«ã‚ˆã‚‹é‡è¦åº¦è©•ä¾¡
"""

import numpy as np
import cv2

import json
import logging
import math
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


@dataclass
class CharacterCandidate:
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å€™è£œã®æƒ…å ±"""
    bbox: Tuple[int, int, int, int]  # (x, y, w, h)
    mask: np.ndarray
    confidence: float
    area: float
    center: Tuple[int, int]
    position_score: float = 0.0
    size_score: float = 0.0
    face_score: float = 0.0
    priority_score: float = 0.0


class CharacterPriorityLearning:
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å„ªå…ˆé †ä½å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self,
                 enable_face_detection: bool = True,
                 enable_position_analysis: bool = True,
                 enable_size_priority: bool = True):
        """
        Args:
            enable_face_detection: é¡”æ¤œå‡ºã«ã‚ˆã‚‹å„ªå…ˆé †ä½ä»˜ã‘ã®æœ‰åŠ¹åŒ–
            enable_position_analysis: ä½ç½®åˆ†æã«ã‚ˆã‚‹å„ªå…ˆé †ä½ä»˜ã‘ã®æœ‰åŠ¹åŒ–
            enable_size_priority: ã‚µã‚¤ã‚ºå„ªå…ˆé †ä½ä»˜ã‘ã®æœ‰åŠ¹åŒ–
        """
        self.enable_face_detection = enable_face_detection
        self.enable_position_analysis = enable_position_analysis
        self.enable_size_priority = enable_size_priority
        
        # é¡”æ¤œå‡ºå™¨
        if enable_face_detection:
            try:
                self.face_cascade = cv2.CascadeClassifier(
                    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
                )
                self.face_profile_cascade = cv2.CascadeClassifier(
                    cv2.data.haarcascades + 'haarcascade_profileface.xml'
                )
            except Exception as e:
                logger.warning(f"é¡”æ¤œå‡ºå™¨ã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
                self.enable_face_detection = False
        
        # ä½ç½®é‡ã¿ãƒãƒƒãƒ— (ä¸­å¤®ã»ã©é‡è¦)
        self.position_weight_map = self._create_position_weight_map()
        
        logger.info(f"CharacterPriorityLearningåˆæœŸåŒ–: face={enable_face_detection}, "
                   f"position={enable_position_analysis}, size={enable_size_priority}")

    def _create_position_weight_map(self) -> np.ndarray:
        """ä½ç½®é‡ã¿ãƒãƒƒãƒ—ã®ä½œæˆï¼ˆä¸­å¤®ãŒé‡è¦ã€ç«¯ã¯ä½é‡è¦åº¦ï¼‰"""
        # æ¨™æº–çš„ãªæ¼«ç”»ç”»åƒã‚µã‚¤ã‚ºæƒ³å®š
        height, width = 1000, 700
        
        # ä¸­å¤®ã‹ã‚‰ã®è·é›¢ã«åŸºã¥ãé‡ã¿ãƒãƒƒãƒ—
        y, x = np.ogrid[:height, :width]
        center_y, center_x = height // 2, width // 2
        
        # ä¸­å¤®ã‹ã‚‰ã®è·é›¢ã‚’è¨ˆç®—
        distance = np.sqrt((x - center_x)**2 + (y - center_y)**2)
        max_distance = np.sqrt(center_x**2 + center_y**2)
        
        # è·é›¢ã‚’0-1ã«æ­£è¦åŒ–ã—ã€é‡ã¿ã«å¤‰æ›ï¼ˆä¸­å¤®=1.0, ç«¯=0.2ï¼‰
        normalized_distance = distance / max_distance
        weight_map = 1.0 - 0.8 * normalized_distance
        
        return weight_map

    def prioritize_characters(self, 
                            image: np.ndarray,
                            character_candidates: List[Dict[str, Any]]) -> Tuple[List[CharacterCandidate], Dict[str, Any]]:
        """
        ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å€™è£œã®å„ªå…ˆé †ä½ä»˜ã‘
        
        Args:
            image: å…¥åŠ›ç”»åƒ (H, W, 3)
            character_candidates: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å€™è£œãƒªã‚¹ãƒˆ
            
        Returns:
            å„ªå…ˆé †ä½ä»˜ã‘ã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å€™è£œã¨åˆ†æçµæœ
        """
        logger.debug(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å„ªå…ˆé †ä½ä»˜ã‘é–‹å§‹: {len(character_candidates)}å€™è£œ")
        
        analysis_result = {
            "candidate_count": len(character_candidates),
            "face_detection_results": [],
            "position_analysis": [],
            "size_analysis": [],
            "final_ranking": [],
            "primary_character": None
        }
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å€™è£œã‚’CharacterCandidateã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        candidates = []
        for i, candidate in enumerate(character_candidates):
            char_candidate = CharacterCandidate(
                bbox=candidate.get("bbox", (0, 0, 0, 0)),
                mask=candidate.get("mask", np.zeros((100, 100), dtype=np.uint8)),
                confidence=candidate.get("confidence", 0.0),
                area=candidate.get("area", 0.0),
                center=candidate.get("center", (0, 0))
            )
            candidates.append(char_candidate)
        
        # 1. é¡”æ¤œå‡ºã«ã‚ˆã‚‹å„ªå…ˆé †ä½ä»˜ã‘
        if self.enable_face_detection and len(candidates) > 0:
            face_results = self._analyze_face_presence(image, candidates)
            analysis_result["face_detection_results"] = face_results
        
        # 2. ä½ç½®ã«ã‚ˆã‚‹å„ªå…ˆé †ä½ä»˜ã‘
        if self.enable_position_analysis:
            position_results = self._analyze_position_priority(image, candidates)
            analysis_result["position_analysis"] = position_results
        
        # 3. ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹å„ªå…ˆé †ä½ä»˜ã‘
        if self.enable_size_priority:
            size_results = self._analyze_size_priority(candidates)
            analysis_result["size_analysis"] = size_results
        
        # 4. ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        self._calculate_final_scores(candidates)
        
        # 5. å„ªå…ˆé †ä½ã§ã‚½ãƒ¼ãƒˆ
        candidates.sort(key=lambda x: x.priority_score, reverse=True)
        
        # 6. åˆ†æçµæœã®æ›´æ–°
        analysis_result["final_ranking"] = [
            {
                "index": i,
                "priority_score": candidate.priority_score,
                "position_score": candidate.position_score,
                "size_score": candidate.size_score,
                "face_score": candidate.face_score,
                "center": candidate.center,
                "area": candidate.area
            }
            for i, candidate in enumerate(candidates)
        ]
        
        if candidates:
            analysis_result["primary_character"] = {
                "index": 0,
                "priority_score": candidates[0].priority_score,
                "bbox": candidates[0].bbox,
                "center": candidates[0].center,
                "confidence": candidates[0].confidence
            }
        
        logger.debug(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å„ªå…ˆé †ä½ä»˜ã‘å®Œäº†: æœ€å„ªå…ˆ={candidates[0].priority_score:.3f}")
        return candidates, analysis_result

    def _analyze_face_presence(self, 
                             image: np.ndarray, 
                             candidates: List[CharacterCandidate]) -> List[Dict[str, Any]]:
        """é¡”æ¤œå‡ºã«ã‚ˆã‚‹å„ªå…ˆé †ä½åˆ†æ"""
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        face_results = []
        
        for i, candidate in enumerate(candidates):
            x, y, w, h = candidate.bbox
            
            # å€™è£œé ˜åŸŸã§ã®é¡”æ¤œå‡º
            roi_gray = gray[y:y+h, x:x+w]
            if roi_gray.size == 0:
                continue
            
            # æ­£é¢é¡”æ¤œå‡º
            frontal_faces = self.face_cascade.detectMultiScale(
                roi_gray, scaleFactor=1.1, minNeighbors=5, minSize=(20, 20)
            )
            
            # æ¨ªé¡”æ¤œå‡º
            profile_faces = self.face_profile_cascade.detectMultiScale(
                roi_gray, scaleFactor=1.1, minNeighbors=5, minSize=(20, 20)
            )
            
            total_faces = len(frontal_faces) + len(profile_faces)
            
            # é¡”ã®é¢ç©æ¯”è¨ˆç®—
            face_area_ratio = 0.0
            if total_faces > 0:
                total_face_area = sum(fw * fh for fx, fy, fw, fh in frontal_faces)
                total_face_area += sum(fw * fh for fx, fy, fw, fh in profile_faces)
                face_area_ratio = total_face_area / (w * h)
            
            # é¡”ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆé¡”ã®æ•°ã¨é¢ç©æ¯”ã‹ã‚‰ï¼‰
            face_score = min(1.0, total_faces * 0.5 + face_area_ratio * 2.0)
            candidate.face_score = face_score
            
            face_result = {
                "candidate_index": i,
                "frontal_faces": len(frontal_faces),
                "profile_faces": len(profile_faces),
                "total_faces": total_faces,
                "face_area_ratio": face_area_ratio,
                "face_score": face_score
            }
            face_results.append(face_result)
        
        return face_results

    def _analyze_position_priority(self, 
                                 image: np.ndarray, 
                                 candidates: List[CharacterCandidate]) -> List[Dict[str, Any]]:
        """ä½ç½®ã«ã‚ˆã‚‹å„ªå…ˆé †ä½åˆ†æ"""
        height, width = image.shape[:2]
        position_results = []
        
        # é‡ã¿ãƒãƒƒãƒ—ã‚’ãƒªã‚µã‚¤ã‚º
        weight_map = cv2.resize(self.position_weight_map, (width, height))
        
        for i, candidate in enumerate(candidates):
            cx, cy = candidate.center
            
            # å¢ƒç•Œãƒã‚§ãƒƒã‚¯
            cx = max(0, min(width - 1, cx))
            cy = max(0, min(height - 1, cy))
            
            # ä½ç½®ã‚¹ã‚³ã‚¢å–å¾—
            position_score = weight_map[cy, cx]
            
            # ä¸­å¤®ã‹ã‚‰ã®è·é›¢ã‚’è¨ˆç®—
            center_x, center_y = width // 2, height // 2
            distance_from_center = math.sqrt((cx - center_x)**2 + (cy - center_y)**2)
            max_distance = math.sqrt(center_x**2 + center_y**2)
            normalized_distance = distance_from_center / max_distance
            
            # ç”»åƒç«¯ã‹ã‚‰ã®è·é›¢ã‚‚è€ƒæ…®
            edge_distance = min(cx, cy, width - cx, height - cy)
            edge_penalty = 1.0 - (edge_distance / min(width, height) * 0.5)
            
            # æœ€çµ‚ä½ç½®ã‚¹ã‚³ã‚¢
            final_position_score = position_score * (1.0 - edge_penalty * 0.3)
            candidate.position_score = final_position_score
            
            position_result = {
                "candidate_index": i,
                "center": (cx, cy),
                "position_weight": position_score,
                "distance_from_center": distance_from_center,
                "normalized_distance": normalized_distance,
                "edge_distance": edge_distance,
                "edge_penalty": edge_penalty,
                "final_position_score": final_position_score
            }
            position_results.append(position_result)
        
        return position_results

    def _analyze_size_priority(self, candidates: List[CharacterCandidate]) -> List[Dict[str, Any]]:
        """ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹å„ªå…ˆé †ä½åˆ†æ"""
        if not candidates:
            return []
        
        # é¢ç©ã®çµ±è¨ˆæƒ…å ±
        areas = [candidate.area for candidate in candidates]
        max_area = max(areas)
        min_area = min(areas)
        area_range = max_area - min_area
        
        size_results = []
        
        for i, candidate in enumerate(candidates):
            # ç›¸å¯¾ã‚µã‚¤ã‚ºã‚¹ã‚³ã‚¢ï¼ˆå¤§ãã„ã»ã©é«˜ã‚¹ã‚³ã‚¢ï¼‰
            if area_range > 0:
                relative_size = (candidate.area - min_area) / area_range
            else:
                relative_size = 1.0
            
            # çµ¶å¯¾ã‚µã‚¤ã‚ºã‚¹ã‚³ã‚¢ï¼ˆé©åº¦ãªã‚µã‚¤ã‚ºãŒç†æƒ³ï¼‰
            # é¢ç©ãŒå…¨ä½“ã®5-80%ã®ç¯„å›²ãŒç†æƒ³çš„
            total_image_area = max_area * 10  # æ¨å®šç”»åƒé¢ç©
            area_ratio = candidate.area / total_image_area
            
            if 0.05 <= area_ratio <= 0.8:
                absolute_size_score = 1.0
            elif area_ratio < 0.05:
                # å°ã•ã™ãã‚‹å ´åˆ
                absolute_size_score = area_ratio / 0.05
            else:
                # å¤§ãã™ãã‚‹å ´åˆ
                absolute_size_score = max(0.1, 1.0 - (area_ratio - 0.8) / 0.2)
            
            # æœ€çµ‚ã‚µã‚¤ã‚ºã‚¹ã‚³ã‚¢
            size_score = relative_size * 0.6 + absolute_size_score * 0.4
            candidate.size_score = size_score
            
            size_result = {
                "candidate_index": i,
                "area": candidate.area,
                "relative_size": relative_size,
                "area_ratio": area_ratio,
                "absolute_size_score": absolute_size_score,
                "final_size_score": size_score
            }
            size_results.append(size_result)
        
        return size_results

    def _calculate_final_scores(self, candidates: List[CharacterCandidate]):
        """æœ€çµ‚å„ªå…ˆé †ä½ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        for candidate in candidates:
            # é‡ã¿ä»˜ãå¹³å‡ã§æœ€çµ‚ã‚¹ã‚³ã‚¢è¨ˆç®—
            priority_score = (
                candidate.face_score * 0.4 +      # é¡”ã®å­˜åœ¨ãŒæœ€é‡è¦
                candidate.position_score * 0.35 + # ä½ç½®ã‚‚é‡è¦
                candidate.size_score * 0.25       # ã‚µã‚¤ã‚ºã¯è£œåŠ©çš„
            )
            
            # å…ƒã®ä¿¡é ¼åº¦ã‚‚åŠ å‘³
            priority_score = priority_score * 0.8 + candidate.confidence * 0.2
            
            candidate.priority_score = min(1.0, priority_score)

    def select_primary_character(self, 
                               candidates: List[CharacterCandidate],
                               selection_strategy: str = "highest_score") -> Optional[CharacterCandidate]:
        """
        ä¸»è¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®é¸æŠ
        
        Args:
            candidates: å„ªå…ˆé †ä½ä»˜ã‘ã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å€™è£œ
            selection_strategy: é¸æŠæˆ¦ç•¥ ('highest_score', 'balanced', 'conservative')
            
        Returns:
            é¸æŠã•ã‚ŒãŸä¸»è¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼
        """
        if not candidates:
            return None
        
        if selection_strategy == "highest_score":
            return candidates[0]  # æ—¢ã«ã‚½ãƒ¼ãƒˆæ¸ˆã¿
        
        elif selection_strategy == "balanced":
            # é¡”ã€ä½ç½®ã€ã‚µã‚¤ã‚ºãŒãƒãƒ©ãƒ³ã‚¹è‰¯ãé«˜ã„ã‚‚ã®ã‚’é¸æŠ
            balanced_candidates = [
                c for c in candidates 
                if c.face_score > 0.3 and c.position_score > 0.4 and c.size_score > 0.3
            ]
            return balanced_candidates[0] if balanced_candidates else candidates[0]
        
        elif selection_strategy == "conservative":
            # ã‚ˆã‚Šä¿å®ˆçš„ãªé¸æŠï¼ˆé¡”ãŒç¢ºå®Ÿã«æ¤œå‡ºã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ï¼‰
            face_candidates = [c for c in candidates if c.face_score > 0.5]
            return face_candidates[0] if face_candidates else candidates[0]
        
        return candidates[0]

    def get_character_selection_reason(self, 
                                     selected: CharacterCandidate,
                                     all_candidates: List[CharacterCandidate]) -> str:
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é¸æŠç†ç”±ã®ç”Ÿæˆ"""
        reasons = []
        
        if selected.face_score > 0.5:
            reasons.append(f"é¡”æ¤œå‡ºã‚¹ã‚³ã‚¢é«˜({selected.face_score:.2f})")
        
        if selected.position_score > 0.6:
            reasons.append(f"ä¸­å¤®ä½ç½®({selected.position_score:.2f})")
        
        if selected.size_score > 0.7:
            reasons.append(f"é©åˆ‡ã‚µã‚¤ã‚º({selected.size_score:.2f})")
        
        if selected.confidence > 0.8:
            reasons.append(f"é«˜ä¿¡é ¼åº¦({selected.confidence:.2f})")
        
        if len(all_candidates) > 1:
            score_gap = selected.priority_score - all_candidates[1].priority_score
            if score_gap > 0.2:
                reasons.append(f"æ˜ç¢ºãªå„ªä½æ€§({score_gap:.2f}å·®)")
        
        return "ã€".join(reasons) if reasons else "ç·åˆåˆ¤å®š"


def test_character_priority_learning():
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å„ªå…ˆé †ä½å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    learning_system = CharacterPriorityLearning(
        enable_face_detection=True,
        enable_position_analysis=True,
        enable_size_priority=True
    )
    
    # ãƒ†ã‚¹ãƒˆç”»åƒ
    test_image_path = Path("/mnt/c/AItools/lora/train/yado/org/kana08/kana08_0002.jpg")
    if test_image_path.exists():
        image = cv2.imread(str(test_image_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        print(f"ãƒ†ã‚¹ãƒˆç”»åƒèª­ã¿è¾¼ã¿: {image.shape}")
        
        # ãƒ€ãƒŸãƒ¼ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å€™è£œä½œæˆ
        height, width = image.shape[:2]
        dummy_candidates = [
            {
                "bbox": (100, 100, 200, 300),
                "mask": np.ones((300, 200), dtype=np.uint8) * 255,
                "confidence": 0.85,
                "area": 60000,
                "center": (200, 250)
            },
            {
                "bbox": (400, 50, 150, 250),
                "mask": np.ones((250, 150), dtype=np.uint8) * 255,
                "confidence": 0.72,
                "area": 37500,
                "center": (475, 175)
            },
            {
                "bbox": (50, 400, 100, 150),
                "mask": np.ones((150, 100), dtype=np.uint8) * 255,
                "confidence": 0.68,
                "area": 15000,
                "center": (100, 475)
            }
        ]
        
        # å„ªå…ˆé †ä½ä»˜ã‘å®Ÿè¡Œ
        prioritized_candidates, analysis = learning_system.prioritize_characters(
            image, dummy_candidates
        )
        
        # åˆ†æçµæœè¡¨ç¤º
        print("\\nğŸ¯ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å„ªå…ˆé †ä½å­¦ç¿’çµæœ:")
        print(f"å€™è£œæ•°: {analysis['candidate_count']}")
        print(f"é¡”æ¤œå‡ºçµæœ: {len(analysis['face_detection_results'])}ä»¶")
        print(f"ä½ç½®åˆ†æ: {len(analysis['position_analysis'])}ä»¶")
        print(f"ã‚µã‚¤ã‚ºåˆ†æ: {len(analysis['size_analysis'])}ä»¶")
        
        # æœ€çµ‚ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
        print("\\nğŸ“Š æœ€çµ‚ãƒ©ãƒ³ã‚­ãƒ³ã‚°:")
        for i, ranking in enumerate(analysis['final_ranking'][:3]):
            print(f"  {i+1}ä½: ç·åˆã‚¹ã‚³ã‚¢{ranking['priority_score']:.3f} "
                  f"(ä½ç½®{ranking['position_score']:.2f}, "
                  f"ã‚µã‚¤ã‚º{ranking['size_score']:.2f}, "
                  f"é¡”{ranking['face_score']:.2f})")
        
        # ä¸»è¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é¸æŠ
        if analysis['primary_character']:
            primary = analysis['primary_character']
            print(f"\\nğŸ‘‘ ä¸»è¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: ã‚¹ã‚³ã‚¢{primary['priority_score']:.3f}")
            
            selected_candidate = learning_system.select_primary_character(prioritized_candidates)
            if selected_candidate:
                reason = learning_system.get_character_selection_reason(
                    selected_candidate, prioritized_candidates
                )
                print(f"é¸æŠç†ç”±: {reason}")
        
        print("\\nâœ… ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å„ªå…ˆé †ä½å­¦ç¿’ãƒ†ã‚¹ãƒˆå®Œäº†")
        
    else:
        print(f"ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_image_path}")


if __name__ == "__main__":
    test_character_priority_learning()