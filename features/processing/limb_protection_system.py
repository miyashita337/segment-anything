#!/usr/bin/env python3
"""
Limb Protection System - æ‰‹è¶³ä¿è­·ã‚·ã‚¹ãƒ†ãƒ 
äººä½“éª¨æ ¼æ¨å®šã¨éƒ¨åˆ†æ¬ æã®è‡ªå‹•æ¤œå‡ºãƒ»è£œå®Œã«ã‚ˆã‚‹æ‰‹è¶³åˆ‡æ–­å•é¡Œã®è§£æ±º
"""

import numpy as np
import cv2

import json
import logging
import math
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


class LimbProtectionSystem:
    """æ‰‹è¶³ä¿è­·ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self,
                 enable_pose_estimation: bool = True,
                 enable_limb_completion: bool = True,
                 protection_margin: int = 20):
        """
        Args:
            enable_pose_estimation: éª¨æ ¼æ¨å®šã®æœ‰åŠ¹åŒ–
            enable_limb_completion: æ‰‹è¶³è£œå®Œã®æœ‰åŠ¹åŒ–
            protection_margin: ä¿è­·ãƒãƒ¼ã‚¸ãƒ³ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
        """
        self.enable_pose_estimation = enable_pose_estimation
        self.enable_limb_completion = enable_limb_completion
        self.protection_margin = protection_margin
        
        # äººä½“ã®ä¸»è¦é–¢ç¯€ç‚¹ï¼ˆOpenPoseå½¢å¼ï¼‰
        self.pose_keypoints = {
            "nose": 0, "neck": 1, "r_shoulder": 2, "r_elbow": 3, "r_wrist": 4,
            "l_shoulder": 5, "l_elbow": 6, "l_wrist": 7, "r_hip": 8, "r_knee": 9,
            "r_ankle": 10, "l_hip": 11, "l_knee": 12, "l_ankle": 13,
            "r_eye": 14, "l_eye": 15, "r_ear": 16, "l_ear": 17
        }
        
        # æ‰‹è¶³ã®æ¥ç¶šé–¢ä¿‚
        self.limb_connections = [
            ("r_shoulder", "r_elbow"), ("r_elbow", "r_wrist"),  # å³è…•
            ("l_shoulder", "l_elbow"), ("l_elbow", "l_wrist"),  # å·¦è…•
            ("r_hip", "r_knee"), ("r_knee", "r_ankle"),        # å³è„š
            ("l_hip", "l_knee"), ("l_knee", "l_ankle")         # å·¦è„š
        ]
        
        logger.info(f"LimbProtectionSystemåˆæœŸåŒ–: pose={enable_pose_estimation}, "
                   f"completion={enable_limb_completion}, margin={protection_margin}")

    def protect_limbs_in_mask(self, 
                             image: np.ndarray,
                             mask: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        ãƒã‚¹ã‚¯ã§æ‰‹è¶³ä¿è­·å‡¦ç†ã‚’å®Ÿè¡Œ
        
        Args:
            image: å…¥åŠ›ç”»åƒ (H, W, 3)
            mask: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒã‚¹ã‚¯
            
        Returns:
            ä¿è­·ã•ã‚ŒãŸãƒã‚¹ã‚¯ã¨åˆ†æçµæœ
        """
        logger.debug(f"æ‰‹è¶³ä¿è­·å‡¦ç†é–‹å§‹: image={image.shape}, mask={mask.shape}")
        
        protection_result = {
            "pose_analysis": {},
            "limb_analysis": {},
            "protection_applied": False,
            "protection_quality": 0.0
        }
        
        protected_mask = mask.copy()
        
        # 1. äººä½“éª¨æ ¼æ¨å®š
        if self.enable_pose_estimation:
            pose_info = self._estimate_pose(image)
            protection_result["pose_analysis"] = pose_info
            
            if pose_info["keypoints_detected"] > 0:
                # 2. æ‰‹è¶³æ¬ ææ¤œå‡º
                limb_analysis = self._analyze_limb_completeness(mask, pose_info)
                protection_result["limb_analysis"] = limb_analysis
                
                # 3. ãƒã‚¹ã‚¯æ‹¡å¼µã«ã‚ˆã‚‹æ‰‹è¶³ä¿è­·
                if self.enable_limb_completion and limb_analysis["incomplete_limbs"]:
                    protected_mask = self._expand_mask_for_limbs(
                        image, mask, pose_info, limb_analysis
                    )
                    protection_result["protection_applied"] = True
        
        # 4. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: éª¨æ ¼æ¨å®šãªã—ã§ã®æ‰‹è¶³ä¿è­·
        if not protection_result["protection_applied"]:
            fallback_protection = self._fallback_limb_protection(image, mask)
            if fallback_protection["applied"]:
                protected_mask = fallback_protection["mask"]
                protection_result["protection_applied"] = True
                protection_result["fallback_used"] = True
        
        # 5. ä¿è­·å“è³ªè©•ä¾¡
        protection_result["protection_quality"] = self._evaluate_protection_quality(
            mask, protected_mask, protection_result
        )
        
        logger.debug("æ‰‹è¶³ä¿è­·å‡¦ç†å®Œäº†")
        return protected_mask, protection_result

    def _estimate_pose(self, image: np.ndarray) -> Dict[str, Any]:
        """ç°¡æ˜“äººä½“éª¨æ ¼æ¨å®šï¼ˆMediaPipeãªã—ã§ã®å®Ÿè£…ï¼‰"""
        # MediaPipeãŒåˆ©ç”¨ã§ããªã„ç’°å¢ƒã§ã®ä»£æ›¿å®Ÿè£…
        # è‰²ã¨å½¢çŠ¶ç‰¹å¾´ã«åŸºã¥ãç°¡æ˜“çš„ãªé–¢ç¯€æ¨å®š
        
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        height, width = image.shape[:2]
        
        # 1. é ­éƒ¨æ¨å®šï¼ˆæœ€ä¸Šéƒ¨ã®è‚Œè‰²é ˜åŸŸï¼‰
        head_candidates = self._find_head_region(image)
        
        # 2. èƒ´ä½“æ¨å®šï¼ˆé ­éƒ¨ã‹ã‚‰ä¸‹ã®ä¸­å¤®é ˜åŸŸï¼‰
        torso_region = self._find_torso_region(image, head_candidates)
        
        # 3. æ‰‹è¶³æœ«ç«¯æ¨å®šï¼ˆã‚¨ãƒƒã‚¸ãŒå¼·ã„å°é ˜åŸŸï¼‰
        limb_extremities = self._find_limb_extremities(image)
        
        # 4. ç°¡æ˜“é–¢ç¯€ç‚¹æ¨å®š
        estimated_keypoints = self._estimate_keypoints_simple(
            head_candidates, torso_region, limb_extremities, (width, height)
        )
        
        pose_info = {
            "keypoints_detected": len([kp for kp in estimated_keypoints if kp is not None]),
            "keypoints": estimated_keypoints,
            "head_region": head_candidates,
            "torso_region": torso_region,
            "limb_extremities": limb_extremities,
            "estimation_confidence": self._calculate_pose_confidence(estimated_keypoints)
        }
        
        logger.debug(f"éª¨æ ¼æ¨å®šçµæœ: {pose_info['keypoints_detected']}å€‹ã®é–¢ç¯€ç‚¹")
        return pose_info

    def _find_head_region(self, image: np.ndarray) -> List[Tuple[int, int]]:
        """é ­éƒ¨é ˜åŸŸã®æ¤œå‡º"""
        # è‚Œè‰²ã«ã‚ˆã‚‹é ­éƒ¨å€™è£œæ¤œå‡º
        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
        
        # è‚Œè‰²ç¯„å›²
        skin_lower = np.array([0, 20, 70])
        skin_upper = np.array([20, 255, 255])
        skin_mask = cv2.inRange(hsv, skin_lower, skin_upper)
        
        # ä¸Šéƒ¨1/3ã®é ˜åŸŸã§è‚Œè‰²é ˜åŸŸã‚’æ¤œç´¢
        height = image.shape[0]
        upper_region = skin_mask[:height//3, :]
        
        # é€£çµæˆåˆ†è§£æ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(upper_region)
        
        head_candidates = []
        for i in range(1, num_labels):
            area = stats[i, cv2.CC_STAT_AREA]
            if area > 500:  # ååˆ†ãªå¤§ãã•ã®é ˜åŸŸ
                center_x, center_y = centroids[i]
                head_candidates.append((int(center_x), int(center_y)))
        
        return head_candidates

    def _find_torso_region(self, 
                          image: np.ndarray, 
                          head_candidates: List[Tuple[int, int]]) -> Dict[str, Any]:
        """èƒ´ä½“é ˜åŸŸã®æ¨å®š"""
        height, width = image.shape[:2]
        
        if not head_candidates:
            # é ­éƒ¨ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ä¸­å¤®ä¸Šéƒ¨ã‚’ä»®å®š
            center_y = height // 4
            center_x = width // 2
        else:
            # æœ€ã‚‚ä¸Šéƒ¨ã®é ­éƒ¨å€™è£œã‚’ä½¿ç”¨
            center_x, center_y = min(head_candidates, key=lambda p: p[1])
        
        # èƒ´ä½“é ˜åŸŸï¼ˆé ­éƒ¨ã®ä¸‹ã€ç”»åƒã®ä¸­å¤®éƒ¨ï¼‰
        torso_top = max(0, center_y + 50)
        torso_bottom = min(height, center_y + height//2)
        torso_left = max(0, center_x - width//6)
        torso_right = min(width, center_x + width//6)
        
        return {
            "bbox": (torso_left, torso_top, torso_right - torso_left, torso_bottom - torso_top),
            "center": (center_x, (torso_top + torso_bottom) // 2)
        }

    def _find_limb_extremities(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """æ‰‹è¶³æœ«ç«¯ã®æ¤œå‡º"""
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        
        # ã‚¨ãƒƒã‚¸æ¤œå‡º
        edges = cv2.Canny(gray, 50, 150)
        
        # å½¢æ…‹å­¦çš„å‡¦ç†ã§æ‰‹è¶³ã®ã‚ˆã†ãªç´°ã„æ§‹é€ ã‚’å¼·èª¿
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        edges_dilated = cv2.dilate(edges, kernel, iterations=1)
        
        # é€£çµæˆåˆ†è§£æ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(edges_dilated)
        
        extremities = []
        height, width = image.shape[:2]
        
        for i in range(1, num_labels):
            area = stats[i, cv2.CC_STAT_AREA]
            if 50 < area < 2000:  # æ‰‹è¶³æœ«ç«¯ã®ã‚µã‚¤ã‚ºç¯„å›²
                x = stats[i, cv2.CC_STAT_LEFT]
                y = stats[i, cv2.CC_STAT_TOP]
                w = stats[i, cv2.CC_STAT_WIDTH]
                h = stats[i, cv2.CC_STAT_HEIGHT]
                
                center_x, center_y = centroids[i]
                
                # ç”»åƒç«¯ä»˜è¿‘ã®é ˜åŸŸã‚’æ‰‹è¶³æœ«ç«¯å€™è£œã¨ã™ã‚‹
                edge_distance = min(x, y, width - (x + w), height - (y + h))
                
                extremities.append({
                    "center": (int(center_x), int(center_y)),
                    "bbox": (x, y, w, h),
                    "area": area,
                    "edge_distance": edge_distance,
                    "aspect_ratio": w / h if h > 0 else 1.0
                })
        
        # ã‚¨ãƒƒã‚¸ã‹ã‚‰ã®è·é›¢ã§ã‚½ãƒ¼ãƒˆï¼ˆç«¯ã«è¿‘ã„ã»ã©æ‰‹è¶³æœ«ç«¯ã®å¯èƒ½æ€§ãŒé«˜ã„ï¼‰
        extremities.sort(key=lambda x: x["edge_distance"])
        
        return extremities[:8]  # ä¸Šä½8å€‹ã‚’è¿”ã™

    def _estimate_keypoints_simple(self,
                                 head_candidates: List[Tuple[int, int]],
                                 torso_region: Dict[str, Any],
                                 limb_extremities: List[Dict[str, Any]],
                                 image_size: Tuple[int, int]) -> List[Optional[Tuple[int, int]]]:
        """ç°¡æ˜“é–¢ç¯€ç‚¹æ¨å®š"""
        width, height = image_size
        keypoints = [None] * 18  # OpenPoseã®é–¢ç¯€ç‚¹æ•°
        
        # é ­éƒ¨ãƒ»é¦–ã®æ¨å®š
        if head_candidates:
            head_x, head_y = head_candidates[0]
            keypoints[self.pose_keypoints["nose"]] = (head_x, head_y)
            keypoints[self.pose_keypoints["neck"]] = (head_x, head_y + 30)
        
        # èƒ´ä½“ä¸­å¿ƒã®æ¨å®š
        torso_center = torso_region["center"]
        torso_x, torso_y = torso_center
        
        # è‚©ã®æ¨å®š
        shoulder_y = torso_y - 20
        keypoints[self.pose_keypoints["r_shoulder"]] = (torso_x + 40, shoulder_y)
        keypoints[self.pose_keypoints["l_shoulder"]] = (torso_x - 40, shoulder_y)
        
        # è…°ã®æ¨å®š
        hip_y = torso_y + 50
        keypoints[self.pose_keypoints["r_hip"]] = (torso_x + 20, hip_y)
        keypoints[self.pose_keypoints["l_hip"]] = (torso_x - 20, hip_y)
        
        # æ‰‹è¶³æœ«ç«¯ã‹ã‚‰é–¢ç¯€ã®æ¨å®š
        for extremity in limb_extremities[:4]:  # ä¸Šä½4å€‹ã‚’ä½¿ç”¨
            ex_x, ex_y = extremity["center"]
            
            # ä½ç½®ã«åŸºã¥ã„ã¦æ‰‹é¦–ãƒ»è¶³é¦–ã‚’æ¨å®š
            if ex_y < torso_y:  # ä¸ŠåŠèº«
                if ex_x > torso_x:  # å³å´
                    if keypoints[self.pose_keypoints["r_wrist"]] is None:
                        keypoints[self.pose_keypoints["r_wrist"]] = (ex_x, ex_y)
                        # è‚˜ã®æ¨å®š
                        if keypoints[self.pose_keypoints["r_shoulder"]]:
                            shoulder_x, shoulder_y = keypoints[self.pose_keypoints["r_shoulder"]]
                            elbow_x = (shoulder_x + ex_x) // 2
                            elbow_y = (shoulder_y + ex_y) // 2
                            keypoints[self.pose_keypoints["r_elbow"]] = (elbow_x, elbow_y)
                else:  # å·¦å´
                    if keypoints[self.pose_keypoints["l_wrist"]] is None:
                        keypoints[self.pose_keypoints["l_wrist"]] = (ex_x, ex_y)
                        # è‚˜ã®æ¨å®š
                        if keypoints[self.pose_keypoints["l_shoulder"]]:
                            shoulder_x, shoulder_y = keypoints[self.pose_keypoints["l_shoulder"]]
                            elbow_x = (shoulder_x + ex_x) // 2
                            elbow_y = (shoulder_y + ex_y) // 2
                            keypoints[self.pose_keypoints["l_elbow"]] = (elbow_x, elbow_y)
            else:  # ä¸‹åŠèº«
                if ex_x > torso_x:  # å³å´
                    if keypoints[self.pose_keypoints["r_ankle"]] is None:
                        keypoints[self.pose_keypoints["r_ankle"]] = (ex_x, ex_y)
                        # è†ã®æ¨å®š
                        if keypoints[self.pose_keypoints["r_hip"]]:
                            hip_x, hip_y = keypoints[self.pose_keypoints["r_hip"]]
                            knee_x = (hip_x + ex_x) // 2
                            knee_y = (hip_y + ex_y) // 2
                            keypoints[self.pose_keypoints["r_knee"]] = (knee_x, knee_y)
                else:  # å·¦å´
                    if keypoints[self.pose_keypoints["l_ankle"]] is None:
                        keypoints[self.pose_keypoints["l_ankle"]] = (ex_x, ex_y)
                        # è†ã®æ¨å®š
                        if keypoints[self.pose_keypoints["l_hip"]]:
                            hip_x, hip_y = keypoints[self.pose_keypoints["l_hip"]]
                            knee_x = (hip_x + ex_x) // 2
                            knee_y = (hip_y + ex_y) // 2
                            keypoints[self.pose_keypoints["l_knee"]] = (knee_x, knee_y)
        
        return keypoints

    def _calculate_pose_confidence(self, keypoints: List[Optional[Tuple[int, int]]]) -> float:
        """éª¨æ ¼æ¨å®šã®ä¿¡é ¼åº¦è¨ˆç®—"""
        detected_count = len([kp for kp in keypoints if kp is not None])
        total_count = len(keypoints)
        
        # ä¸»è¦é–¢ç¯€ç‚¹ã®é‡ã¿ä»˜ãè©•ä¾¡
        important_joints = ["neck", "r_shoulder", "l_shoulder", "r_hip", "l_hip"]
        important_detected = 0
        
        for joint_name in important_joints:
            joint_idx = self.pose_keypoints[joint_name]
            if joint_idx < len(keypoints) and keypoints[joint_idx] is not None:
                important_detected += 1
        
        # åŸºæœ¬ä¿¡é ¼åº¦ + é‡è¦é–¢ç¯€ãƒœãƒ¼ãƒŠã‚¹
        base_confidence = detected_count / total_count
        important_bonus = important_detected / len(important_joints) * 0.3
        
        return min(1.0, base_confidence + important_bonus)

    def _analyze_limb_completeness(self, 
                                 mask: np.ndarray, 
                                 pose_info: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰‹è¶³ã®å®Œå…¨æ€§åˆ†æ"""
        keypoints = pose_info["keypoints"]
        
        if len(mask.shape) == 3:
            mask_gray = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)
        else:
            mask_gray = mask.copy()
        
        incomplete_limbs = []
        limb_status = {}
        
        # å„æ‰‹è¶³ã®æ¥ç¶šã‚’ç¢ºèª
        for connection in self.limb_connections:
            joint1_name, joint2_name = connection
            joint1_idx = self.pose_keypoints[joint1_name]
            joint2_idx = self.pose_keypoints[joint2_name]
            
            limb_name = f"{joint1_name}_to_{joint2_name}"
            
            if (joint1_idx < len(keypoints) and joint2_idx < len(keypoints) and
                keypoints[joint1_idx] is not None and keypoints[joint2_idx] is not None):
                
                # é–¢ç¯€é–“ã®ç·šãŒãƒã‚¹ã‚¯ã§è¦†ã‚ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                pt1 = keypoints[joint1_idx]
                pt2 = keypoints[joint2_idx]
                
                coverage = self._check_limb_coverage(mask_gray, pt1, pt2)
                
                limb_status[limb_name] = {
                    "coverage": coverage,
                    "complete": coverage > 0.7,
                    "joint1": pt1,
                    "joint2": pt2
                }
                
                if coverage < 0.7:
                    incomplete_limbs.append({
                        "name": limb_name,
                        "coverage": coverage,
                        "joint1": pt1,
                        "joint2": pt2,
                        "missing_area": 1.0 - coverage
                    })
        
        return {
            "incomplete_limbs": incomplete_limbs,
            "limb_status": limb_status,
            "completion_rate": len([ls for ls in limb_status.values() if ls["complete"]]) / max(len(limb_status), 1)
        }

    def _check_limb_coverage(self, 
                           mask: np.ndarray, 
                           pt1: Tuple[int, int], 
                           pt2: Tuple[int, int]) -> float:
        """æ‰‹è¶³éƒ¨åˆ†ã®ãƒã‚¹ã‚¯è¢«è¦†ç‡ãƒã‚§ãƒƒã‚¯"""
        # 2ç‚¹é–“ã®ç·šä¸Šã§ãƒã‚¹ã‚¯ã®è¢«è¦†ç‡ã‚’è¨ˆç®—
        x1, y1 = pt1
        x2, y2 = pt2
        
        # ç·šã®é•·ã•
        length = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)
        if length < 1:
            return 1.0
        
        # ç·šä¸Šã®ç‚¹ã‚’æ¡å–
        num_samples = max(10, int(length))
        covered_count = 0
        
        for i in range(num_samples):
            t = i / (num_samples - 1) if num_samples > 1 else 0
            x = int(x1 + t * (x2 - x1))
            y = int(y1 + t * (y2 - y1))
            
            # å¢ƒç•Œãƒã‚§ãƒƒã‚¯
            if 0 <= x < mask.shape[1] and 0 <= y < mask.shape[0]:
                if mask[y, x] > 0:
                    covered_count += 1
        
        return covered_count / num_samples

    def _expand_mask_for_limbs(self,
                             image: np.ndarray,
                             mask: np.ndarray, 
                             pose_info: Dict[str, Any],
                             limb_analysis: Dict[str, Any]) -> np.ndarray:
        """æ‰‹è¶³ä¿è­·ã®ãŸã‚ã®ãƒã‚¹ã‚¯æ‹¡å¼µ"""
        expanded_mask = mask.copy()
        
        if len(expanded_mask.shape) == 3:
            expanded_mask = cv2.cvtColor(expanded_mask, cv2.COLOR_RGB2GRAY)
        
        # ä¸å®Œå…¨ãªæ‰‹è¶³ã‚’æ‹¡å¼µ
        for incomplete_limb in limb_analysis["incomplete_limbs"]:
            pt1 = incomplete_limb["joint1"]
            pt2 = incomplete_limb["joint2"]
            
            # é–¢ç¯€é–“ã®ç·šã‚’å¤ªãã—ã¦ãƒã‚¹ã‚¯ã«è¿½åŠ 
            expanded_mask = self._draw_limb_protection(expanded_mask, pt1, pt2)
        
        # æ‰‹è¶³æœ«ç«¯ã®ä¿è­·æ‹¡å¼µ
        keypoints = pose_info["keypoints"]
        extremity_joints = ["r_wrist", "l_wrist", "r_ankle", "l_ankle"]
        
        for joint_name in extremity_joints:
            joint_idx = self.pose_keypoints[joint_name]
            if joint_idx < len(keypoints) and keypoints[joint_idx] is not None:
                x, y = keypoints[joint_idx]
                # æœ«ç«¯å‘¨è¾ºã‚’å††å½¢ã«æ‹¡å¼µ
                cv2.circle(expanded_mask, (x, y), self.protection_margin, 255, -1)
        
        return expanded_mask

    def _draw_limb_protection(self, 
                            mask: np.ndarray, 
                            pt1: Tuple[int, int], 
                            pt2: Tuple[int, int]) -> np.ndarray:
        """æ‰‹è¶³ä¿è­·ç·šã®æç”»"""
        # å¤ªã„ç·šã§ãƒã‚¹ã‚¯ã‚’æ‹¡å¼µ
        cv2.line(mask, pt1, pt2, 255, thickness=self.protection_margin)
        
        # ä¸¡ç«¯ã‚‚å††å½¢ã«æ‹¡å¼µ
        cv2.circle(mask, pt1, self.protection_margin//2, 255, -1)
        cv2.circle(mask, pt2, self.protection_margin//2, 255, -1)
        
        return mask

    def _fallback_limb_protection(self, 
                                image: np.ndarray, 
                                mask: np.ndarray) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ‰‹è¶³ä¿è­·ï¼ˆéª¨æ ¼æ¨å®šãªã—ï¼‰- æ”¹å–„ç‰ˆ"""
        if len(mask.shape) == 3:
            mask_gray = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)
        else:
            mask_gray = mask.copy()
        
        # ãƒã‚¹ã‚¯ã®å¢ƒç•Œè¿‘è¾ºã§ç´°ã„éƒ¨åˆ†ã‚’æ¤œå‡ºãƒ»æ‹¡å¼µ
        # ç´°ã„éƒ¨åˆ†ã¯æ‰‹è¶³ã®å¯èƒ½æ€§ãŒé«˜ã„
        
        # 1. ãƒã‚¹ã‚¯ã®éª¨æ ¼åŒ–ï¼ˆcv2.ximgproc.thinning ã®ä»£æ›¿å®Ÿè£…ï¼‰
        skeleton = self._zhang_suen_thinning(mask_gray)
        
        # 2. æœ«ç«¯ç‚¹ã¨åˆ†å²ç‚¹ã®æ¤œå‡º
        endpoint_coords, branch_coords = self._find_skeleton_features(skeleton)
        
        # 3. è·é›¢å¤‰æ›ã«ã‚ˆã‚‹ç´°ã„éƒ¨åˆ†ã®æ¤œå‡º
        dist_transform = cv2.distanceTransform(mask_gray, cv2.DIST_L2, 5)
        thin_regions = (dist_transform > 0) & (dist_transform < 8)  # ç´°ã„éƒ¨åˆ†
        
        # 4. æ‹¡å¼µå‡¦ç†
        expanded_mask = mask_gray.copy()
        
        # æœ«ç«¯ç‚¹å‘¨è¾ºã‚’æ‹¡å¼µï¼ˆæ‰‹è¶³ã®æœ«ç«¯ä¿è­·ï¼‰
        for y, x in endpoint_coords:
            cv2.circle(expanded_mask, (x, y), self.protection_margin, 255, -1)
        
        # åˆ†å²ç‚¹å‘¨è¾ºã‚‚è»½ãæ‹¡å¼µï¼ˆé–¢ç¯€éƒ¨åˆ†ã®ä¿è­·ï¼‰
        for y, x in branch_coords:
            cv2.circle(expanded_mask, (x, y), self.protection_margin // 2, 255, -1)
        
        # ç´°ã„éƒ¨åˆ†ã®è†¨å¼µ
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        thin_expanded = cv2.dilate(thin_regions.astype(np.uint8) * 255, kernel, iterations=1)
        
        # 5. ç™½è‰²ç³»éƒ¨ä½ã®ç‰¹åˆ¥ä¿è­·ï¼ˆkana08è©•ä¾¡ã§å•é¡Œã¨ãªã£ãŸéƒ¨åˆ†ï¼‰
        expanded_mask = self._protect_white_regions(image, expanded_mask, mask_gray)
        
        # æœ€çµ‚ãƒã‚¹ã‚¯çµ±åˆ
        final_mask = cv2.bitwise_or(expanded_mask, thin_expanded)
        
        # ã•ã‚‰ã«æ‰‹è¶³ã‚‰ã—ã„å½¢çŠ¶ã®ä¿è­·
        final_mask = self._protect_limb_like_shapes(final_mask, image)
        
        # å¤‰åŒ–ãŒã‚ã£ãŸã‹ãƒã‚§ãƒƒã‚¯
        applied = not np.array_equal(mask_gray, final_mask)
        
        return {
            "applied": applied,
            "mask": final_mask,
            "endpoints_found": len(endpoint_coords),
            "branches_found": len(branch_coords),
            "method": "enhanced_fallback"
        }
    
    def _zhang_suen_thinning(self, mask: np.ndarray) -> np.ndarray:
        """Zhang-Suenç´°ç·šåŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆximgproc.thinningã®ä»£æ›¿ï¼‰"""
        # å…¥åŠ›ã‚’0/1ã®ãƒã‚¤ãƒŠãƒªã«å¤‰æ›
        binary = (mask > 0).astype(np.uint8)
        
        def neighbors(x, y, image):
            """8è¿‘å‚ã®å–å¾—"""
            return [image[x-1,y], image[x-1,y+1], image[x,y+1], image[x+1,y+1], 
                   image[x+1,y], image[x+1,y-1], image[x,y-1], image[x-1,y-1]]
        
        def transitions(neighbors):
            """0â†’1ã®é·ç§»æ•°ã‚’è¨ˆç®—"""
            n = neighbors + neighbors[0:1]  # å¾ªç’°
            return sum(n[i] == 0 and n[i+1] == 1 for i in range(8))
        
        changed = True
        height, width = binary.shape
        
        # å¢ƒç•Œã¯å‡¦ç†ã—ãªã„
        for _ in range(50):  # æœ€å¤§50å›ã®åå¾©
            if not changed:
                break
            changed = False
            
            # Phase 1
            to_remove = []
            for x in range(1, height-1):
                for y in range(1, width-1):
                    if binary[x,y] == 1:
                        n = neighbors(x, y, binary)
                        if (2 <= sum(n) <= 6 and transitions(n) == 1 and
                            n[0] * n[2] * n[4] == 0 and n[2] * n[4] * n[6] == 0):
                            to_remove.append((x, y))
            
            for x, y in to_remove:
                binary[x, y] = 0
                changed = True
            
            # Phase 2
            to_remove = []
            for x in range(1, height-1):
                for y in range(1, width-1):
                    if binary[x,y] == 1:
                        n = neighbors(x, y, binary)
                        if (2 <= sum(n) <= 6 and transitions(n) == 1 and
                            n[0] * n[2] * n[6] == 0 and n[0] * n[4] * n[6] == 0):
                            to_remove.append((x, y))
            
            for x, y in to_remove:
                binary[x, y] = 0
                changed = True
        
        return binary * 255
    
    def _find_skeleton_features(self, skeleton: np.ndarray) -> Tuple[List[Tuple[int, int]], List[Tuple[int, int]]]:
        """éª¨æ ¼ã®ç‰¹å¾´ç‚¹ï¼ˆæœ«ç«¯ç‚¹ãƒ»åˆ†å²ç‚¹ï¼‰ã‚’æ¤œå‡º"""
        # 8è¿‘å‚ã§ã®æ¥ç¶šæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        kernel = np.array([[1, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=np.uint8)
        neighbors = cv2.filter2D((skeleton > 0).astype(np.uint8), -1, kernel)
        
        # æœ«ç«¯ç‚¹ï¼ˆæ¥ç¶šãŒ1å€‹ï¼‰
        endpoints = np.where((skeleton > 0) & (neighbors == 1))
        endpoint_coords = list(zip(endpoints[0], endpoints[1]))
        
        # åˆ†å²ç‚¹ï¼ˆæ¥ç¶šãŒ3å€‹ä»¥ä¸Šï¼‰
        branches = np.where((skeleton > 0) & (neighbors >= 3))
        branch_coords = list(zip(branches[0], branches[1]))
        
        return endpoint_coords, branch_coords
    
    def _protect_white_regions(self, image: np.ndarray, mask: np.ndarray, original_mask: np.ndarray) -> np.ndarray:
        """ç™½è‰²ç³»éƒ¨ä½ã®ç‰¹åˆ¥ä¿è­·ï¼ˆã‚«ãƒãƒ¥ãƒ¼ã‚·ãƒ£ã€èƒ¸éƒ¨åˆ†ã€è¶³ãªã©ï¼‰"""
        # HSVè‰²ç©ºé–“ã§ã®ç™½è‰²ç³»æ¤œå‡º
        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
        h, s, v = cv2.split(hsv)
        
        # å¤šæ®µéšç™½è‰²æ¤œå‡º
        white_regions = (
            ((s < 30) & (v > 180)) |  # ç´”ç™½
            ((s < 40) & (v > 160)) |  # è–„ç™½
            ((s < 20) & (v > 140))    # ã‚°ãƒ¬ãƒ¼ç³»
        )
        
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒã‚¹ã‚¯ã¨ã®äº¤å·®é ˜åŸŸã‚’é‡è¦–
        original_white = cv2.bitwise_and(white_regions.astype(np.uint8) * 255, original_mask)
        
        # ç™½è‰²é ˜åŸŸã®å¢ƒç•Œã‚’æ¤œå‡º
        white_edges = cv2.Canny(original_white, 30, 100)
        
        # å¢ƒç•Œã‹ã‚‰å°‘ã—æ‹¡å¼µã—ã¦ä¿è­·
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        white_protected = cv2.dilate(white_edges, kernel, iterations=2)
        
        # å…ƒã®ãƒã‚¹ã‚¯ã¨çµ±åˆ
        return cv2.bitwise_or(mask, white_protected)
    
    def _protect_limb_like_shapes(self, mask: np.ndarray, image: np.ndarray) -> np.ndarray:
        """æ‰‹è¶³ã‚‰ã—ã„å½¢çŠ¶ã®ä¿è­·"""
        # è¼ªéƒ­æ¤œå‡º
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        protected_mask = mask.copy()
        
        for contour in contours:
            # è¼ªéƒ­ã®ç‰¹å¾´åˆ†æ
            area = cv2.contourArea(contour)
            if area < 100:  # å°ã•ã™ãã‚‹é ˜åŸŸã¯ç„¡è¦–
                continue
            
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = h / max(w, 1)
            
            # æ‰‹è¶³ã‚‰ã—ã„å½¢çŠ¶ï¼ˆç´°é•·ã„ï¼‰ã®ä¿è­·å¼·åŒ–
            if aspect_ratio > 2.0 or aspect_ratio < 0.5:  # ç¸¦é•·ã¾ãŸã¯æ¨ªé•·
                # è¼ªéƒ­ã‚’å°‘ã—æ‹¡å¼µ
                epsilon = 0.02 * cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, epsilon, True)
                
                # æ‹¡å¼µã—ãŸè¼ªéƒ­ã§å¡—ã‚Šã¤ã¶ã—
                expanded_contour = []
                center_x, center_y = x + w//2, y + h//2
                
                for point in approx:
                    px, py = point[0]
                    # ä¸­å¿ƒã‹ã‚‰å¤–å´ã«å‘ã‹ã£ã¦å°‘ã—æ‹¡å¼µ
                    direction_x = px - center_x
                    direction_y = py - center_y
                    length = math.sqrt(direction_x**2 + direction_y**2)
                    
                    if length > 0:
                        # 3ãƒ”ã‚¯ã‚»ãƒ«å¤–å´ã«æ‹¡å¼µ
                        expansion = 3.0
                        new_x = int(px + (direction_x / length) * expansion)
                        new_y = int(py + (direction_y / length) * expansion)
                        expanded_contour.append([new_x, new_y])
                
                if len(expanded_contour) >= 3:
                    expanded_contour = np.array(expanded_contour, dtype=np.int32)
                    cv2.fillPoly(protected_mask, [expanded_contour], 255)
        
        return protected_mask

    def _evaluate_protection_quality(self,
                                   original_mask: np.ndarray,
                                   protected_mask: np.ndarray, 
                                   protection_result: Dict[str, Any]) -> float:
        """ä¿è­·å“è³ªã®è©•ä¾¡"""
        # åŸºæœ¬å“è³ªã‚¹ã‚³ã‚¢
        base_score = 0.5
        
        # éª¨æ ¼æ¨å®šã®ä¿¡é ¼åº¦ãƒœãƒ¼ãƒŠã‚¹
        if "pose_analysis" in protection_result:
            pose_confidence = protection_result["pose_analysis"].get("estimation_confidence", 0)
            base_score += pose_confidence * 0.3
        
        # æ‰‹è¶³å®Œå…¨æ€§ã®æ”¹å–„åº¦
        if "limb_analysis" in protection_result:
            completion_rate = protection_result["limb_analysis"].get("completion_rate", 0)
            base_score += completion_rate * 0.2
        
        # ãƒã‚¹ã‚¯ã®å¤‰åŒ–é‡ï¼ˆé©åº¦ãªæ‹¡å¼µãŒè‰¯ã„ï¼‰
        if len(original_mask.shape) == 3:
            orig_area = np.sum(cv2.cvtColor(original_mask, cv2.COLOR_RGB2GRAY) > 0)
        else:
            orig_area = np.sum(original_mask > 0)
        
        if len(protected_mask.shape) == 3:
            prot_area = np.sum(cv2.cvtColor(protected_mask, cv2.COLOR_RGB2GRAY) > 0)
        else:
            prot_area = np.sum(protected_mask > 0)
        
        if orig_area > 0:
            expansion_ratio = prot_area / orig_area
            # é©åº¦ãªæ‹¡å¼µï¼ˆ1.05ï½1.3å€ï¼‰ãŒç†æƒ³
            if 1.05 <= expansion_ratio <= 1.3:
                base_score += 0.2
            elif expansion_ratio > 1.0:
                base_score += 0.1
        
        return min(1.0, base_score)


def test_limb_protection_system():
    """æ‰‹è¶³ä¿è­·ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    protector = LimbProtectionSystem(
        enable_pose_estimation=True,
        enable_limb_completion=True,
        protection_margin=15
    )
    
    # ãƒ†ã‚¹ãƒˆç”»åƒã¨ãƒã‚¹ã‚¯
    test_image_path = Path("/mnt/c/AItools/lora/train/yado/org/kana08/kana08_0009.jpg")
    test_mask_path = Path("/mnt/c/AItools/lora/train/yado/clipped_boundingbox/kana08_robust_system_final/kana08_0009.jpg")
    
    if test_image_path.exists():
        image = cv2.imread(str(test_image_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã«ã¯SAMã®çµæœã‚’ä½¿ç”¨ï¼‰
        # ãƒ†ã‚¹ãƒˆç”¨ã«ç°¡æ˜“ãƒã‚¹ã‚¯ã‚’ä½œæˆ
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        _, mask = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)
        
        print(f"ãƒ†ã‚¹ãƒˆç”»åƒèª­ã¿è¾¼ã¿: {image.shape}")
        print(f"ãƒ†ã‚¹ãƒˆãƒã‚¹ã‚¯ç”Ÿæˆ: {mask.shape}")
        
        # æ‰‹è¶³ä¿è­·å®Ÿè¡Œ
        protected_mask, analysis = protector.protect_limbs_in_mask(image, mask)
        
        # åˆ†æçµæœè¡¨ç¤º
        print("\\nğŸ¦´ æ‰‹è¶³ä¿è­·åˆ†æçµæœ:")
        print(f"éª¨æ ¼åˆ†æ: {analysis['pose_analysis']}")
        print(f"æ‰‹è¶³åˆ†æ: {analysis['limb_analysis']}")
        print(f"ä¿è­·é©ç”¨: {analysis['protection_applied']}")
        print(f"ä¿è­·å“è³ª: {analysis['protection_quality']:.3f}")
        
        # çµæœä¿å­˜
        output_path = Path("/tmp/limb_protection_test.jpg")
        cv2.imwrite(str(output_path), protected_mask)
        print(f"\\nğŸ’¾ çµæœä¿å­˜: {output_path}")
    else:
        print(f"ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_image_path}")


if __name__ == "__main__":
    test_limb_protection_system()