#!/usr/bin/env python3
"""
å¼·åŒ–SCIè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ (Phase A2)
æœ€é«˜å“è³ªã®é¡”ãƒ»ãƒãƒ¼ã‚ºæ¤œå‡ºã¨çµ±åˆã—ãŸSCIè¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ 

å“è³ªé‡è¦–ã®çµ±åˆè¨­è¨ˆ:
- EnhancedFaceDetectorçµ±åˆ
- EnhancedPoseDetectorçµ±åˆ
- OpenCVã‚¨ãƒ©ãƒ¼ä¿®æ­£
- å‡¦ç†æ™‚é–“: 10-12ç§’/ç”»åƒï¼ˆå“è³ªæœ€å„ªå…ˆï¼‰
"""

import numpy as np
import cv2

import logging
import os
import sys
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, NamedTuple, Optional, Tuple

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from features.evaluation.enhanced_detection_systems import (
    EnhancedFaceDetector,
    EnhancedPoseDetector,
    FaceDetection,
    PoseDetectionResult,
)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class EnhancedSCIResult:
    """å¼·åŒ–SCIè¨ˆç®—çµæœ"""
    sci_total: float
    face_score: float
    pose_score: float
    contour_score: float
    completeness_level: str
    quality_code: int
    
    # å¼·åŒ–æ¤œå‡ºçµæœè©³ç´°
    face_detections: List[FaceDetection]
    pose_result: PoseDetectionResult
    processing_time: float
    
    # è©³ç´°è©•ä¾¡æŒ‡æ¨™
    face_detection_rate: float
    pose_detection_rate: float
    structure_completeness: float


class EnhancedSCICalculationEngine:
    """å¼·åŒ–SCIè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.EnhancedSCICalculationEngine")
        
        # å¼·åŒ–æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self.face_detector = EnhancedFaceDetector()
        self.pose_detector = EnhancedPoseDetector()
        
        self.logger.info("å¼·åŒ–SCIè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
    
    def calculate_enhanced_sci(self, image: np.ndarray) -> EnhancedSCIResult:
        """å¼·åŒ–SCIè¨ˆç®—ï¼ˆé«˜å“è³ªæ¤œå‡ºçµ±åˆç‰ˆï¼‰"""
        start_time = datetime.now()
        
        try:
            # 1. å¼·åŒ–é¡”æ¤œå‡º (40% weight - é‡è¦æ€§å‘ä¸Š)
            face_detections = self.face_detector.detect_faces_comprehensive(image)
            face_score, face_detection_rate = self._calculate_enhanced_face_score(
                image, face_detections
            )
            
            # 2. å¼·åŒ–ãƒãƒ¼ã‚ºæ¤œå‡º (40% weight - é‡è¦æ€§å‘ä¸Š)
            pose_result = self.pose_detector.detect_pose_comprehensive(image)
            pose_score, pose_detection_rate = self._calculate_enhanced_pose_score(
                pose_result
            )
            
            # 3. æ§‹é€ å“è³ªã‚¹ã‚³ã‚¢ (20% weight - è£œå®Œçš„)
            contour_score, structure_completeness = self._calculate_enhanced_contour_score(
                image
            )
            
            # é‡ã¿ä»˜ãç·åˆã‚¹ã‚³ã‚¢ï¼ˆå¼·åŒ–ç‰ˆï¼‰
            sci_total = (face_score * 0.4 + pose_score * 0.4 + contour_score * 0.2)
            
            # å®Œå…¨æ€§ãƒ¬ãƒ™ãƒ«ã®åˆ¤å®šï¼ˆå¼·åŒ–ç‰ˆï¼‰
            completeness_level, quality_code = self._classify_enhanced_sci_quality(
                sci_total, face_detection_rate, pose_detection_rate
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            self.logger.info(f"å¼·åŒ–SCIè¨ˆç®—å®Œäº†: ç·åˆ={sci_total:.3f}, "
                           f"é¡”={face_score:.3f}, ãƒãƒ¼ã‚º={pose_score:.3f}, "
                           f"è¼ªéƒ­={contour_score:.3f} "
                           f"ï¼ˆå‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’ï¼‰")
            
            return EnhancedSCIResult(
                sci_total=sci_total,
                face_score=face_score,
                pose_score=pose_score,
                contour_score=contour_score,
                completeness_level=completeness_level,
                quality_code=quality_code,
                face_detections=face_detections,
                pose_result=pose_result,
                processing_time=processing_time,
                face_detection_rate=face_detection_rate,
                pose_detection_rate=pose_detection_rate,
                structure_completeness=structure_completeness
            )
            
        except Exception as e:
            self.logger.error(f"å¼·åŒ–SCIè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            processing_time = (datetime.now() - start_time).total_seconds()
            return EnhancedSCIResult(
                sci_total=0.0,
                face_score=0.0,
                pose_score=0.0,
                contour_score=0.0,
                completeness_level="ã‚¨ãƒ©ãƒ¼",
                quality_code=0,
                face_detections=[],
                pose_result=PoseDetectionResult(
                    detected=False, landmarks=None, visibility_score=0.0,
                    pose_category='unknown', completeness_score=0.0,
                    confidence=0.0, keypoints_detected=0
                ),
                processing_time=processing_time,
                face_detection_rate=0.0,
                pose_detection_rate=0.0,
                structure_completeness=0.0
            )
    
    def _calculate_enhanced_face_score(self, image: np.ndarray, 
                                     face_detections: List[FaceDetection]) -> Tuple[float, float]:
        """å¼·åŒ–é¡”æ¤œå‡ºã‚¹ã‚³ã‚¢è¨ˆç®—"""
        if not face_detections:
            return 0.0, 0.0  # (face_score, detection_rate)
        
        # æœ€é«˜ä¿¡é ¼åº¦ã®é¡”ã‚’é¸æŠ
        best_face = max(face_detections, key=lambda f: f.confidence)
        
        # åŸºæœ¬ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
        confidence_score = best_face.confidence
        
        # é¡”ã‚µã‚¤ã‚ºé©æ­£æ€§è©•ä¾¡
        x, y, w, h = best_face.bbox
        face_area = w * h
        image_area = image.shape[0] * image.shape[1]
        size_ratio = face_area / image_area
        
        # ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã«é©ã—ãŸé¡”ã‚µã‚¤ã‚ºè©•ä¾¡
        if 0.01 <= size_ratio <= 0.4:  # 1%-40%ãŒé©æ­£ç¯„å›²
            size_score = 1.0
        elif size_ratio < 0.01:
            size_score = size_ratio / 0.01  # å°ã•ã™ãã‚‹å ´åˆã®æ®µéšçš„æ¸›ç‚¹
        else:
            size_score = max(0.3, 1.0 - (size_ratio - 0.4) / 0.6)  # å¤§ãã™ãã‚‹å ´åˆ
        
        # é¡”ä½ç½®è©•ä¾¡ï¼ˆä¸­å¤®ä»˜è¿‘ãŒå¥½ã¾ã—ã„ï¼‰
        face_center_x = x + w // 2
        face_center_y = y + h // 2
        image_center_x = image.shape[1] // 2
        image_center_y = image.shape[0] // 2
        
        center_distance = np.sqrt(
            ((face_center_x - image_center_x) / image.shape[1]) ** 2 +
            ((face_center_y - image_center_y) / image.shape[0]) ** 2
        )
        position_score = max(0.5, 1.0 - center_distance)
        
        # è¤‡æ•°é¡”æ¤œå‡ºãƒœãƒ¼ãƒŠã‚¹ï¼ˆè¤‡æ•°æ‰‹æ³•ã§ç¢ºèªï¼‰
        multi_method_bonus = min(0.2, len(face_detections) * 0.05)
        
        # ç·åˆé¡”ã‚¹ã‚³ã‚¢è¨ˆç®—
        face_score = (confidence_score * 0.4 + 
                     size_score * 0.3 + 
                     position_score * 0.2 + 
                     multi_method_bonus + 0.1)
        
        face_score = min(1.0, face_score)
        detection_rate = 1.0  # é¡”ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã¯100%
        
        return face_score, detection_rate
    
    def _calculate_enhanced_pose_score(self, pose_result: PoseDetectionResult) -> Tuple[float, float]:
        """å¼·åŒ–ãƒãƒ¼ã‚ºæ¤œå‡ºã‚¹ã‚³ã‚¢è¨ˆç®—"""
        if not pose_result.detected:
            return 0.0, 0.0  # (pose_score, detection_rate)
        
        # åŸºæœ¬ãƒãƒ¼ã‚ºã‚¹ã‚³ã‚¢è¦ç´ 
        visibility_weight = 0.3
        completeness_weight = 0.4
        confidence_weight = 0.2
        category_weight = 0.1
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒœãƒ¼ãƒŠã‚¹
        category_bonuses = {
            'standing': 1.0,    # ç«‹ä½ã¯æ¨™æº–
            'sitting': 0.9,     # åº§ä½ã‚‚è‰¯å¥½
            'action': 1.1,      # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¯é«˜è©•ä¾¡
            'lying': 0.8,       # æ¨ªè‡¥ä½ã¯å°‘ã—ä½ã‚
            'profile': 0.85,    # æ¨ªå‘ãã¯å°‘ã—ä½ã‚
            'unknown': 0.6      # ä¸æ˜ã¯ä½è©•ä¾¡
        }
        
        category_bonus = category_bonuses.get(pose_result.pose_category, 0.6)
        
        # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå¯†åº¦ãƒœãƒ¼ãƒŠã‚¹
        keypoint_density = pose_result.keypoints_detected / 33.0
        density_bonus = keypoint_density * 0.2
        
        # ç·åˆãƒãƒ¼ã‚ºã‚¹ã‚³ã‚¢è¨ˆç®—
        pose_score = (
            pose_result.visibility_score * visibility_weight +
            pose_result.completeness_score * completeness_weight +
            pose_result.confidence * confidence_weight +
            category_bonus * category_weight +
            density_bonus
        )
        
        pose_score = min(1.0, pose_score)
        detection_rate = 1.0  # ãƒãƒ¼ã‚ºãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã¯100%
        
        return pose_score, detection_rate
    
    def _calculate_enhanced_contour_score(self, image: np.ndarray) -> Tuple[float, float]:
        """å¼·åŒ–è¼ªéƒ­å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆOpenCVã‚¨ãƒ©ãƒ¼ä¿®æ­£ç‰ˆï¼‰"""
        try:
            # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()
            
            # ã‚¨ãƒƒã‚¸æ¤œå‡ºï¼ˆé«˜å“è³ªè¨­å®šï¼‰
            # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ã§å‰å‡¦ç†
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            
            # Cannyã‚¨ãƒƒã‚¸æ¤œå‡ºï¼ˆã‚¢ãƒ‹ãƒ¡ç”»åƒã«é©ã—ãŸè¨­å®šï¼‰
            edges = cv2.Canny(blurred, 30, 100, apertureSize=3)
            
            # è¼ªéƒ­æ¤œå‡ºï¼ˆOpenCVã‚¨ãƒ©ãƒ¼ä¿®æ­£ï¼‰
            # edges ã‚’uint8å‹ã«ç¢ºå®Ÿã«å¤‰æ›
            edges_uint8 = edges.astype(np.uint8)
            
            contours, _ = cv2.findContours(
                edges_uint8, 
                cv2.RETR_EXTERNAL, 
                cv2.CHAIN_APPROX_SIMPLE
            )
            
            if not contours:
                return 0.2, 0.0  # è¼ªéƒ­ãªã—ã§ã‚‚æœ€ä½ã‚¹ã‚³ã‚¢
            
            # è¼ªéƒ­å“è³ªè©•ä¾¡
            total_contour_length = sum(cv2.arcLength(contour, True) for contour in contours)
            image_perimeter = 2 * (image.shape[0] + image.shape[1])
            
            # è¼ªéƒ­å¯†åº¦ã‚¹ã‚³ã‚¢
            contour_density = min(1.0, total_contour_length / image_perimeter)
            
            # ä¸»è¦è¼ªéƒ­åˆ†æ
            main_contours = [c for c in contours if cv2.contourArea(c) > 100]
            main_contour_ratio = len(main_contours) / max(1, len(contours))
            
            # è¼ªéƒ­ã®è¤‡é›‘åº¦è©•ä¾¡
            complexity_scores = []
            for contour in main_contours[:5]:  # ä¸Šä½5ã¤ã®è¼ªéƒ­
                epsilon = 0.02 * cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, epsilon, True)
                complexity = len(approx) / max(4, len(approx))  # æ­£è¦åŒ–è¤‡é›‘åº¦
                complexity_scores.append(min(1.0, complexity))
            
            avg_complexity = np.mean(complexity_scores) if complexity_scores else 0.3
            
            # ç·åˆè¼ªéƒ­ã‚¹ã‚³ã‚¢
            contour_score = (
                contour_density * 0.4 +
                main_contour_ratio * 0.3 +
                avg_complexity * 0.3
            )
            
            contour_score = min(1.0, contour_score)
            structure_completeness = contour_score
            
            return contour_score, structure_completeness
            
        except Exception as e:
            self.logger.warning(f"è¼ªéƒ­å“è³ªè¨ˆç®—ã‚¨ãƒ©ãƒ¼ï¼ˆä¿®æ­£ç‰ˆï¼‰: {e}")
            return 0.3, 0.0  # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚³ã‚¢
    
    def _classify_enhanced_sci_quality(self, sci_total: float, 
                                     face_detection_rate: float,
                                     pose_detection_rate: float) -> Tuple[str, int]:
        """å¼·åŒ–SCIå“è³ªåˆ†é¡"""
        # å“è³ªé–¾å€¤ï¼ˆå³æ ¼åŒ–ï¼‰
        if sci_total >= 0.85 and face_detection_rate > 0.9 and pose_detection_rate > 0.9:
            return "æœ€é«˜å“è³ª", 5
        elif sci_total >= 0.70 and face_detection_rate > 0.7 and pose_detection_rate > 0.7:
            return "é«˜å“è³ª", 4
        elif sci_total >= 0.55 and (face_detection_rate > 0.5 or pose_detection_rate > 0.5):
            return "è‰¯å¥½", 3
        elif sci_total >= 0.40:
            return "æ™®é€š", 2
        elif sci_total >= 0.25:
            return "ä½å“è³ª", 1
        else:
            return "å“è³ªä¸è¶³", 0


def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="å¼·åŒ–SCIè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆ")
    parser.add_argument("--image", "-i", required=True, help="ãƒ†ã‚¹ãƒˆç”»åƒãƒ‘ã‚¹")
    parser.add_argument("--verbose", "-v", action="store_true", help="è©³ç´°ãƒ­ã‚°å‡ºåŠ›")
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # ç”»åƒèª­ã¿è¾¼ã¿
    image = cv2.imread(args.image)
    if image is None:
        print(f"ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—: {args.image}")
        return 1
    
    print(f"ğŸ§® å¼·åŒ–SCIè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆ: {args.image}")
    print("=" * 70)
    
    # å¼·åŒ–SCIè¨ˆç®—å®Ÿè¡Œ
    sci_engine = EnhancedSCICalculationEngine()
    result = sci_engine.calculate_enhanced_sci(image)
    
    # çµæœè¡¨ç¤º
    print(f"ğŸ“Š å¼·åŒ–SCIè¨ˆç®—çµæœ:")
    print(f"  ç·åˆSCI: {result.sci_total:.3f}")
    print(f"  é¡”ã‚¹ã‚³ã‚¢: {result.face_score:.3f} (æ¤œå‡ºç‡: {result.face_detection_rate:.1%})")
    print(f"  ãƒãƒ¼ã‚ºã‚¹ã‚³ã‚¢: {result.pose_score:.3f} (æ¤œå‡ºç‡: {result.pose_detection_rate:.1%})")
    print(f"  è¼ªéƒ­ã‚¹ã‚³ã‚¢: {result.contour_score:.3f}")
    print(f"  å“è³ªãƒ¬ãƒ™ãƒ«: {result.completeness_level} (ã‚³ãƒ¼ãƒ‰: {result.quality_code})")
    print(f"  å‡¦ç†æ™‚é–“: {result.processing_time:.2f}ç§’")
    
    print(f"\nğŸ” è©³ç´°æ¤œå‡ºçµæœ:")
    print(f"  é¡”æ¤œå‡º: {len(result.face_detections)}ä»¶")
    if result.face_detections:
        for i, face in enumerate(result.face_detections):
            print(f"    é¡”{i+1}: {face.method}, ä¿¡é ¼åº¦={face.confidence:.3f}")
    
    print(f"  ãƒãƒ¼ã‚ºæ¤œå‡º: {'æˆåŠŸ' if result.pose_result.detected else 'å¤±æ•—'}")
    if result.pose_result.detected:
        print(f"    ã‚«ãƒ†ã‚´ãƒª: {result.pose_result.pose_category}")
        print(f"    å¯è¦–ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ: {result.pose_result.keypoints_detected}/33")
        print(f"    å®Œå…¨æ€§: {result.pose_result.completeness_score:.3f}")
    
    return 0


if __name__ == "__main__":
    exit(main())