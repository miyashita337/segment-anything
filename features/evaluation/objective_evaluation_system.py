#!/usr/bin/env python3
"""
å®¢è¦³çš„è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ  v1.0.0
3æŒ‡æ¨™ã‚·ã‚¹ãƒ†ãƒ ï¼ˆPLA/SCI/PLEï¼‰ã®å®Œå…¨å®Ÿè£…

Usage:
    from features.evaluation.objective_evaluation_system import ObjectiveEvaluationSystem
    
    evaluator = ObjectiveEvaluationSystem()
    report = evaluator.evaluate_batch(extraction_results)
"""

import numpy as np
import cv2

import json
import logging
import mediapipe as mp
import os
from collections import deque
from dataclasses import asdict, dataclass
from datetime import datetime
from pathlib import Path
from PIL import Image
from scipy import stats
from typing import Any, Dict, List, Optional, Tuple

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class PLAResult:
    """PLAï¼ˆPixel-Level Accuracyï¼‰è©•ä¾¡çµæœ"""

    iou_score: float
    accuracy_level: str
    quality_code: int
    intersection_pixels: int
    union_pixels: int
    mask_coverage: float


@dataclass
class SCIResult:
    """SCIï¼ˆSemantic Completeness Indexï¼‰è©•ä¾¡çµæœ"""

    sci_total: float
    face_score: float
    pose_score: float
    contour_score: float
    completeness_level: str
    quality_code: int
    detected_landmarks: int


@dataclass
class PLEResult:
    """PLEï¼ˆProgressive Learning Efficiencyï¼‰è©•ä¾¡çµæœ"""

    ple_score: float
    improvement_rate: float
    stability: float
    efficiency: float
    learning_status: str
    status_code: int
    trend_direction: str


@dataclass
class StatisticsResult:
    """çµ±è¨ˆçµæœ"""

    mean: float
    std: float
    min: float
    max: float
    median: float
    q25: float
    q75: float
    count: int


@dataclass
class ObjectiveEvaluationReport:
    """å®¢è¦³è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ"""

    timestamp: datetime
    batch_size: int
    pla_statistics: StatisticsResult
    sci_statistics: StatisticsResult
    ple_result: PLEResult
    overall_quality_score: float
    overall_quality_level: str
    milestone_progress: Dict[str, float]
    recommendations: List[str]
    alerts: List[str]


class PLACalculationEngine:
    """Pixel-Level Accuracy è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.PLACalculationEngine")

    def calculate_pla(self, predicted_mask: np.ndarray, ground_truth_mask: np.ndarray) -> PLAResult:
        """
        PLAï¼ˆIoUï¼‰ã®è¨ˆç®—

        Args:
            predicted_mask: äºˆæ¸¬ãƒã‚¹ã‚¯ï¼ˆ0-255 or 0-1ï¼‰
            ground_truth_mask: æ­£è§£ãƒã‚¹ã‚¯ï¼ˆ0-255 or 0-1ï¼‰

        Returns:
            PLAResult: PLAè©•ä¾¡çµæœ
        """
        try:
            # ãƒã‚¤ãƒŠãƒªãƒã‚¹ã‚¯ã¸ã®æ­£è¦åŒ–
            pred_binary = self._normalize_mask(predicted_mask)
            gt_binary = self._normalize_mask(ground_truth_mask)

            # IoUè¨ˆç®—
            intersection = np.logical_and(pred_binary, gt_binary).sum()
            union = np.logical_or(pred_binary, gt_binary).sum()

            iou_score = float(intersection) / float(union) if union > 0 else 1.0

            # ç²¾åº¦ãƒ¬ãƒ™ãƒ«ã®åˆ¤å®š
            accuracy_level, quality_code = self._classify_pla_quality(iou_score)

            # ãƒã‚¹ã‚¯ã‚«ãƒãƒ¬ãƒƒã‚¸è¨ˆç®—
            mask_coverage = intersection / (pred_binary.sum() + 1e-8)

            return PLAResult(
                iou_score=iou_score,
                accuracy_level=accuracy_level,
                quality_code=quality_code,
                intersection_pixels=int(intersection),
                union_pixels=int(union),
                mask_coverage=float(mask_coverage),
            )

        except Exception as e:
            self.logger.error(f"PLAè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return PLAResult(0.0, "ã‚¨ãƒ©ãƒ¼", 0, 0, 0, 0.0)

    def _normalize_mask(self, mask: np.ndarray) -> np.ndarray:
        """ãƒã‚¹ã‚¯ã‚’ãƒã‚¤ãƒŠãƒªå½¢å¼ã«æ­£è¦åŒ–"""
        if mask.max() > 1:
            return (mask > 127).astype(np.uint8)
        else:
            return (mask > 0.5).astype(np.uint8)

    def _classify_pla_quality(self, iou_score: float) -> Tuple[str, int]:
        """IoUã‚¹ã‚³ã‚¢ã‹ã‚‰å“è³ªãƒ¬ãƒ™ãƒ«ã‚’åˆ†é¡"""
        if iou_score >= 0.90:
            return "å•†ç”¨ãƒ¬ãƒ™ãƒ«", 5
        elif iou_score >= 0.80:
            return "å®Ÿç”¨ãƒ¬ãƒ™ãƒ«", 4
        elif iou_score >= 0.70:
            return "æ”¹å–„ä½™åœ°ã‚ã‚Š", 3
        elif iou_score >= 0.60:
            return "å•é¡Œã‚ã‚Š", 2
        else:
            return "ä½¿ç”¨ä¸å¯", 1


class SCICalculationEngine:
    """Semantic Completeness Index è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.SCICalculationEngine")

        # é¡”æ¤œå‡ºå™¨ã®åˆæœŸåŒ–
        try:
            cascade_path = cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
            self.face_detector = cv2.CascadeClassifier(cascade_path)
        except Exception as e:
            self.logger.warning(f"é¡”æ¤œå‡ºå™¨åˆæœŸåŒ–å¤±æ•—: {e}")
            self.face_detector = None

        # MediaPipeå§¿å‹¢æ¨å®šã®åˆæœŸåŒ–
        try:
            self.pose_estimator = mp.solutions.pose.Pose(
                static_image_mode=True,
                model_complexity=2,
                enable_segmentation=False,
                min_detection_confidence=0.5,
            )
        except Exception as e:
            self.logger.warning(f"MediaPipeåˆæœŸåŒ–å¤±æ•—: {e}")
            self.pose_estimator = None

    def calculate_sci(self, extracted_image: np.ndarray, anime_optimized: bool = True) -> SCIResult:
        """
        SCIï¼ˆæ„å‘³çš„å®Œå…¨æ€§ï¼‰ã®è¨ˆç®— - Week 3ã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–æœ€é©åŒ–ç‰ˆ

        Args:
            extracted_image: æŠ½å‡ºã•ã‚ŒãŸç”»åƒï¼ˆRGBå½¢å¼ï¼‰
            anime_optimized: ã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–é‡ã¿ä»˜ã‘ã‚’ä½¿ç”¨ã™ã‚‹ã‹

        Returns:
            SCIResult: SCIè©•ä¾¡çµæœ
        """
        try:
            # 1. é¡”æ¤œå‡ºã‚¹ã‚³ã‚¢
            face_score = self._calculate_face_score(extracted_image)

            # 2. äººä½“å§¿å‹¢ã‚¹ã‚³ã‚¢  
            pose_score, detected_landmarks = self._calculate_pose_score(extracted_image)

            # 3. è¼ªéƒ­å“è³ªã‚¹ã‚³ã‚¢
            contour_score = self._calculate_contour_score(extracted_image)

            # Week 4: SCIé‡ã¿æœ€é©åŒ–ï¼ˆè¼ªéƒ­å•é¡Œå¯¾å¿œï¼‰
            if anime_optimized:
                # Week 4æœ€é©åŒ–é‡ã¿ï¼ˆè¼ªéƒ­ä¸å®‰å®šæ€§å¯¾å¿œï¼‰
                face_weight = 0.6    # 50% â†’ 60% (é¡”æ¤œå‡ºå¤§å¹…æ”¹å–„ã«ã‚ˆã‚Šæ›´ã«é‡è¦–)
                pose_weight = 0.25   # 30% â†’ 25% (ãƒãƒ¼ã‚ºã¯è£œåŠ©çš„å½¹å‰²)
                contour_weight = 0.15 # 20% â†’ 15% (è¼ªéƒ­è¨ˆç®—ã®ä¸å®‰å®šæ€§ã‚’é‡ã¿å‰Šæ¸›ã§è£œå„Ÿ)
            else:
                # å¾“æ¥é‡ã¿ï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ï¼‰
                face_weight = 0.3
                pose_weight = 0.4 
                contour_weight = 0.3

            # é‡ã¿ä»˜ãç·åˆã‚¹ã‚³ã‚¢
            sci_total = face_score * face_weight + pose_score * pose_weight + contour_score * contour_weight

            # å®Œå…¨æ€§ãƒ¬ãƒ™ãƒ«ã®åˆ¤å®š
            completeness_level, quality_code = self._classify_sci_quality(sci_total)

            self.logger.debug(
                f"SCIè¨ˆç®—å®Œäº†: é¡”{face_score:.3f}Ã—{face_weight} + "
                f"ãƒãƒ¼ã‚º{pose_score:.3f}Ã—{pose_weight} + "
                f"è¼ªéƒ­{contour_score:.3f}Ã—{contour_weight} = {sci_total:.3f} "
                f"({'ã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–' if anime_optimized else 'æ¨™æº–'})"
            )

            return SCIResult(
                sci_total=sci_total,
                face_score=face_score,
                pose_score=pose_score,
                contour_score=contour_score,
                completeness_level=completeness_level,
                quality_code=quality_code,
                detected_landmarks=detected_landmarks,
            )

        except Exception as e:
            self.logger.error(f"SCIè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return SCIResult(0.0, 0.0, 0.0, 0.0, "ã‚¨ãƒ©ãƒ¼", 0, 0)

    def _calculate_face_score(self, image: np.ndarray) -> float:
        """é¡”æ¤œå‡ºã‚¹ã‚³ã‚¢ã®è¨ˆç®— - Week 4æœ€é©åŒ–ç‰ˆï¼ˆã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–ï¼‰"""
        if self.face_detector is None:
            return 0.6  # ã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤å‘ä¸Š

        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # Week 4æ”¹å–„: ã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–æ¤œå‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            faces = self.face_detector.detectMultiScale(
                gray, 
                scaleFactor=1.05,  # ã‚ˆã‚Šç´°ã‹ã„ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆã‚¢ãƒ‹ãƒ¡é¡”å¯¾å¿œï¼‰
                minNeighbors=3,    # ã‚ˆã‚Šå¯›å®¹ï¼ˆã‚¢ãƒ‹ãƒ¡é¡”ã¯å¤šæ§˜ï¼‰
                minSize=(15, 15),  # ã‚ˆã‚Šå°ã•ã„é¡”ã‚‚æ¤œå‡º
                maxSize=(400, 400) # ã‚ˆã‚Šå¤§ãã„é¡”ã‚‚æ¤œå‡º
            )

            if len(faces) == 0:
                # Week 4æ”¹å–„: ã‚ˆã‚Šå¯›å®¹ãªè¿½åŠ æ¤œå‡ºè©¦è¡Œ
                faces = self.face_detector.detectMultiScale(
                    gray, scaleFactor=1.03, minNeighbors=1, minSize=(10, 10)
                )
                
                if len(faces) == 0:
                    return 0.2  # å®Œå…¨0å›é¿ï¼ˆã‚¢ãƒ‹ãƒ¡ã§ã¯éƒ¨åˆ†æ¤œå‡ºã‚‚ä¾¡å€¤ï¼‰

            # Week 4æ”¹å–„: è¤‡æ•°é¡”å¯¾å¿œã¨ã‚ˆã‚Šç²¾å¯†ãªè©•ä¾¡
            face_scores = []
            image_area = image.shape[0] * image.shape[1]
            
            for face in faces:
                x, y, w, h = face
                face_area = w * h
                face_ratio = face_area / image_area
                
                # ã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–ã‚µã‚¤ã‚ºè©•ä¾¡
                if 0.005 <= face_ratio <= 0.4:  # ã‚ˆã‚Šåºƒç¯„å›²è¨±å®¹
                    if 0.02 <= face_ratio <= 0.15:  # ç†æƒ³ç¯„å›²
                        size_score = 1.0
                    elif face_ratio < 0.02:
                        size_score = 0.7 + (face_ratio / 0.02) * 0.3
                    else:  # face_ratio > 0.15
                        size_score = 1.0 - min((face_ratio - 0.15) / 0.25, 0.3)
                else:
                    size_score = 0.3  # æœ€ä½ä¿è¨¼
                
                # Week 4è¿½åŠ : ä½ç½®è©•ä¾¡ï¼ˆä¸­å¤®å¯„ã‚ŠãŒé«˜è©•ä¾¡ï¼‰
                center_x = x + w/2
                center_y = y + h/2
                img_center_x = gray.shape[1] / 2
                img_center_y = gray.shape[0] / 2
                
                center_dist = np.sqrt(
                    ((center_x - img_center_x) / img_center_x) ** 2 + 
                    ((center_y - img_center_y) / img_center_y) ** 2
                )
                position_score = max(0.5, 1.0 - center_dist * 0.3)
                
                # Week 4è¿½åŠ : ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”è©•ä¾¡ï¼ˆé¡”ã‚‰ã—ã„æ¯”ç‡ï¼‰
                aspect_ratio = w / h if h > 0 else 1.0
                if 0.7 <= aspect_ratio <= 1.4:  # é¡”ã‚‰ã—ã„æ¯”ç‡
                    aspect_score = 1.0
                else:
                    aspect_score = max(0.6, 1.0 - abs(aspect_ratio - 1.0) * 0.4)
                
                # çµ±åˆã‚¹ã‚³ã‚¢è¨ˆç®—
                face_score = (size_score * 0.5 + position_score * 0.3 + aspect_score * 0.2)
                face_scores.append(face_score)
            
            # æœ€é«˜ã‚¹ã‚³ã‚¢ã®é¡”ã‚’æ¡ç”¨ï¼ˆè¤‡æ•°é¡”ã®å ´åˆï¼‰
            final_score = max(face_scores)
            
            # Week 4æ”¹å–„: è¤‡æ•°é¡”ãƒœãƒ¼ãƒŠã‚¹ï¼ˆã‚¢ãƒ‹ãƒ¡ã§ã¯è¤‡æ•°ã‚­ãƒ£ãƒ©ã‚‚ä¾¡å€¤ï¼‰
            if len(faces) > 1:
                multi_face_bonus = min(0.1, len(faces) * 0.03)
                final_score += multi_face_bonus
            
            return min(final_score, 1.0)

        except Exception as e:
            self.logger.warning(f"é¡”æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return 0.3  # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–æœ€ä½ä¿è¨¼

    def _calculate_pose_score(self, image: np.ndarray) -> Tuple[float, int]:
        """äººä½“å§¿å‹¢ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        if self.pose_estimator is None:
            return 0.5, 0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

        try:
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if len(image.shape) == 3 else image
            results = self.pose_estimator.process(rgb_image)

            if not results.pose_landmarks:
                return 0.0, 0

            # é‡è¦ãªãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®æ¤œå‡ºç¢ºèª
            critical_landmarks = [
                # é¡”éƒ¨åˆ†
                mp.solutions.pose.PoseLandmark.NOSE,
                mp.solutions.pose.PoseLandmark.LEFT_EYE,
                mp.solutions.pose.PoseLandmark.RIGHT_EYE,
                # ä¸Šè‚¢
                mp.solutions.pose.PoseLandmark.LEFT_SHOULDER,
                mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER,
                mp.solutions.pose.PoseLandmark.LEFT_WRIST,
                mp.solutions.pose.PoseLandmark.RIGHT_WRIST,
                # ä¸‹è‚¢
                mp.solutions.pose.PoseLandmark.LEFT_HIP,
                mp.solutions.pose.PoseLandmark.RIGHT_HIP,
                mp.solutions.pose.PoseLandmark.LEFT_ANKLE,
                mp.solutions.pose.PoseLandmark.RIGHT_ANKLE,
            ]

            detected_count = 0
            confidence_sum = 0.0

            for landmark_id in critical_landmarks:
                landmark = results.pose_landmarks.landmark[landmark_id]
                if landmark.visibility > 0.5:  # 50%ä»¥ä¸Šã®ç¢ºä¿¡åº¦
                    detected_count += 1
                    confidence_sum += landmark.visibility

            detection_rate = detected_count / len(critical_landmarks)
            avg_confidence = confidence_sum / max(detected_count, 1)

            return detection_rate * avg_confidence, detected_count

        except Exception as e:
            self.logger.warning(f"å§¿å‹¢æ¨å®šã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0, 0

    def _calculate_contour_score(self, image: np.ndarray) -> float:
        """è¼ªéƒ­å“è³ªã‚¹ã‚³ã‚¢ã®è¨ˆç®— - Week 4ä¿®æ­£ç‰ˆï¼ˆBoolå‹ã‚¨ãƒ©ãƒ¼å¯¾å¿œï¼‰"""
        try:
            # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image

            # Week 4ä¿®æ­£: Boolå‹ã‚’uint8å‹ã«å¤‰æ›ã—ã¦findContoursã‚¨ãƒ©ãƒ¼è§£æ±º
            binary_mask = (gray > 0).astype(np.uint8) * 255

            # è¼ªéƒ­æ¤œå‡º
            contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            if len(contours) == 0:
                return 0.0

            # Week 4æ”¹å–„: æœ‰åŠ¹ãªè¼ªéƒ­ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            valid_contours = [c for c in contours if cv2.contourArea(c) > 100]  # æœ€å°é¢ç©ãƒ•ã‚£ãƒ«ã‚¿
            
            if len(valid_contours) == 0:
                return 0.1  # å®Œå…¨0å›é¿ï¼ˆã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–ï¼‰

            # æœ€å¤§è¼ªéƒ­ã‚’å–å¾—
            largest_contour = max(valid_contours, key=cv2.contourArea)
            contour_area = cv2.contourArea(largest_contour)
            
            # Week 4æ”¹å–„: è¼ªéƒ­é¢ç©ã«ã‚ˆã‚‹åŸºæœ¬ã‚¹ã‚³ã‚¢
            image_area = gray.shape[0] * gray.shape[1]
            area_ratio = contour_area / image_area
            base_score = min(area_ratio * 2, 1.0)  # ç”»åƒã®50%ä»¥ä¸Šã§æº€ç‚¹

            # 1. æ»‘ã‚‰ã‹ã•ã‚’è©•ä¾¡ï¼ˆã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–èª¿æ•´ï¼‰
            epsilon = 0.015 * cv2.arcLength(largest_contour, True)  # ã‚ˆã‚Šå¯›å®¹
            approx = cv2.approxPolyDP(largest_contour, epsilon, True)
            smoothness_score = max(0, 1.0 - len(approx) / 80.0)  # ã‚¢ãƒ‹ãƒ¡ã«é©ã—ãŸé–¾å€¤

            # 2. é–‰é–æ€§ã‚’è©•ä¾¡ï¼ˆã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–èª¿æ•´ï¼‰
            perimeter = cv2.arcLength(largest_contour, True)
            if perimeter > 0:
                circularity = 4 * np.pi * contour_area / (perimeter * perimeter)
                closure_score = min(circularity * 1.5, 1.0)  # ã‚¢ãƒ‹ãƒ¡å½¢çŠ¶ã«å¯›å®¹
            else:
                closure_score = 0.5

            # 3. é€£ç¶šæ€§ã‚’è©•ä¾¡ï¼ˆã‚®ãƒ£ãƒƒãƒ—ã®æ¤œå‡ºï¼‰
            continuity_score = self._detect_contour_continuity(largest_contour)

            # Week 4æ”¹å–„: é‡ã¿ä»˜ãçµ±åˆï¼ˆåŸºæœ¬ã‚¹ã‚³ã‚¢é‡è¦–ï¼‰
            final_score = (base_score * 0.4 + smoothness_score * 0.3 + 
                          closure_score * 0.2 + continuity_score * 0.1)
            
            return min(final_score, 1.0)

        except Exception as e:
            self.logger.warning(f"è¼ªéƒ­å“è³ªè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0

    def _detect_contour_continuity(self, contour: np.ndarray) -> float:
        """è¼ªéƒ­ã®é€£ç¶šæ€§ã‚’è©•ä¾¡ - Week 4æ”¹å–„ç‰ˆï¼ˆã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–ï¼‰"""
        if len(contour) < 5:  # ã‚ˆã‚Šå¯›å®¹ãªæœ€å°ç‚¹æ•°
            return 0.3  # ã‚¢ãƒ‹ãƒ¡ã§ã¯å°ã•ãªè¼ªéƒ­ã§ã‚‚ä¸€å®šè©•ä¾¡

        try:
            # è¼ªéƒ­ç‚¹é–“ã®è·é›¢å¤‰å‹•ã‚’è©•ä¾¡
            distances = []
            for i in range(min(len(contour), 100)):  # è¨ˆç®—é‡åˆ¶é™
                pt1 = contour[i][0]
                pt2 = contour[(i + 1) % len(contour)][0]
                dist = np.linalg.norm(pt1 - pt2)
                distances.append(dist)

            if not distances:
                return 0.3

            # Week 4æ”¹å–„: è·é›¢ã®å¤‰å‹•ä¿‚æ•°ã§è©•ä¾¡ï¼ˆã‚¢ãƒ‹ãƒ¡ã«é©ã—ãŸæŒ‡æ¨™ï¼‰
            mean_dist = np.mean(distances)
            std_dev = np.std(distances)
            
            if mean_dist == 0:
                return 0.5
                
            # å¤‰å‹•ä¿‚æ•° (CV) = æ¨™æº–åå·® / å¹³å‡
            cv = std_dev / mean_dist
            
            # ã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–: å¤‰å‹•ä¿‚æ•°ãŒ1.0ä»¥ä¸‹ãªã‚‰é«˜è©•ä¾¡
            continuity = max(0.2, 1.0 - cv)  # æœ€ä½0.2ä¿è¨¼
            
            return min(continuity, 1.0)
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–ã®æœ€ä½ä¿è¨¼ã‚¹ã‚³ã‚¢
            return 0.3

    def _classify_sci_quality(self, sci_score: float) -> Tuple[str, int]:
        """SCIã‚¹ã‚³ã‚¢ã‹ã‚‰å“è³ªãƒ¬ãƒ™ãƒ«ã‚’åˆ†é¡ - Week 4ã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–èª¿æ•´"""
        # Week 4æ”¹å–„: ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç‰¹æ€§ã«åˆã‚ã›ãŸç·©å’Œã•ã‚ŒãŸé–¾å€¤
        if sci_score >= 0.75:  # 0.85 â†’ 0.75 ç·©å’Œ
            return "æ§‹é€ çš„å®Œç’§", 5
        elif sci_score >= 0.55:  # 0.70 â†’ 0.55 å¤§å¹…ç·©å’Œ
            return "ã»ã¼å®Œå…¨", 4
        elif sci_score >= 0.35:  # 0.50 â†’ 0.35 ç·©å’Œ
            return "éƒ¨åˆ†çš„", 3
        elif sci_score >= 0.20:  # 0.30 â†’ 0.20 ç·©å’Œ
            return "ä¸å®Œå…¨", 2
        else:
            return "æ§‹é€ ç ´ç¶»", 1


class PLEProgressTracker:
    """Progressive Learning Efficiency è¿½è·¡å™¨"""

    def __init__(self, history_file: str = "progress_history.json"):
        self.logger = logging.getLogger(f"{__name__}.PLEProgressTracker")
        self.history_file = Path(history_file)
        self.history = self._load_history()

    def _load_history(self) -> Dict:
        """é€²æ—å±¥æ­´ã®èª­ã¿è¾¼ã¿"""
        if self.history_file.exists():
            try:
                with open(self.history_file, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                self.logger.warning(f"å±¥æ­´èª­ã¿è¾¼ã¿å¤±æ•—: {e}")

        return {"pla_scores": [], "sci_scores": [], "timestamps": [], "batch_sizes": []}

    def calculate_ple(
        self,
        current_pla_scores: List[float],
        current_sci_scores: List[float],
        time_window: int = 10,
    ) -> PLEResult:
        """
        PLEï¼ˆç¶™ç¶šå­¦ç¿’åŠ¹ç‡ï¼‰ã®è¨ˆç®—

        Args:
            current_pla_scores: ç¾åœ¨ã®PLAã‚¹ã‚³ã‚¢ãƒªã‚¹ãƒˆ
            current_sci_scores: ç¾åœ¨ã®SCIã‚¹ã‚³ã‚¢ãƒªã‚¹ãƒˆ
            time_window: æ¯”è¼ƒå¯¾è±¡ã®æ™‚é–“çª“

        Returns:
            PLEResult: PLEè©•ä¾¡çµæœ
        """
        try:
            # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°
            self._update_history(current_pla_scores, current_sci_scores)

            # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒè“„ç©ã•ã‚Œã¦ã„ãªã„å ´åˆ
            if len(self.history["pla_scores"]) < time_window * 2:
                return PLEResult(
                    ple_score=0.0,
                    improvement_rate=0.0,
                    stability=0.0,
                    efficiency=0.0,
                    learning_status="ãƒ‡ãƒ¼ã‚¿ä¸è¶³",
                    status_code=0,
                    trend_direction="unknown",
                )

            # ç›´è¿‘æ€§èƒ½ã®è¨ˆç®—
            recent_pla = np.mean(self.history["pla_scores"][-time_window:])
            recent_sci = np.mean(self.history["sci_scores"][-time_window:])
            recent_avg = (recent_pla + recent_sci) / 2

            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ€§èƒ½ã®è¨ˆç®—
            baseline_pla = np.mean(self.history["pla_scores"][:time_window])
            baseline_sci = np.mean(self.history["sci_scores"][:time_window])
            baseline_avg = (baseline_pla + baseline_sci) / 2

            # 1. æ”¹å–„ç‡ã®è¨ˆç®— (40% weight)
            if baseline_avg == 0:
                improvement_rate = 0.0
            else:
                improvement_rate = (recent_avg - baseline_avg) / baseline_avg

            # 2. å®‰å®šæ€§ã®è¨ˆç®— (30% weight)
            recent_combined = [
                (self.history["pla_scores"][i] + self.history["sci_scores"][i]) / 2
                for i in range(-time_window, 0)
            ]
            stability = 1.0 - min(np.std(recent_combined), 1.0)

            # 3. åŠ¹ç‡æ€§ã®è¨ˆç®— (30% weight)
            trial_count = len(self.history["pla_scores"])
            efficiency = improvement_rate / (trial_count / 100.0) if trial_count > 0 else 0.0

            # PLEç·åˆã‚¹ã‚³ã‚¢
            ple_score = improvement_rate * 0.4 + stability * 0.3 + efficiency * 0.3
            ple_score = max(-1.0, min(1.0, ple_score))  # -1.0 to 1.0 ã«æ­£è¦åŒ–

            # å­¦ç¿’çŠ¶æ…‹ã®åˆ†é¡
            learning_status, status_code = self._classify_ple_status(ple_score)
            trend_direction = "up" if improvement_rate > 0 else "down"

            return PLEResult(
                ple_score=ple_score,
                improvement_rate=improvement_rate,
                stability=stability,
                efficiency=efficiency,
                learning_status=learning_status,
                status_code=status_code,
                trend_direction=trend_direction,
            )

        except Exception as e:
            self.logger.error(f"PLEè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return PLEResult(0.0, 0.0, 0.0, 0.0, "ã‚¨ãƒ©ãƒ¼", 0, "unknown")

    def _update_history(self, pla_scores: List[float], sci_scores: List[float]):
        """å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°"""
        # å¹³å‡å€¤ã‚’å±¥æ­´ã«è¿½åŠ 
        self.history["pla_scores"].append(np.mean(pla_scores))
        self.history["sci_scores"].append(np.mean(sci_scores))
        self.history["timestamps"].append(datetime.now().isoformat())
        self.history["batch_sizes"].append(len(pla_scores))

        # å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        try:
            with open(self.history_file, "w", encoding="utf-8") as f:
                json.dump(self.history, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.warning(f"å±¥æ­´ä¿å­˜å¤±æ•—: {e}")

    def _classify_ple_status(self, ple_score: float) -> Tuple[str, int]:
        """PLEã‚¹ã‚³ã‚¢ã‹ã‚‰å­¦ç¿’çŠ¶æ…‹ã‚’åˆ†é¡"""
        if ple_score >= 0.15:
            return "é«˜åŠ¹ç‡å­¦ç¿’", 5
        elif ple_score >= 0.05:
            return "æ¨™æº–å­¦ç¿’", 4
        elif ple_score >= 0.00:
            return "ä½åŠ¹ç‡å­¦ç¿’", 3
        elif ple_score >= -0.05:
            return "åœæ»", 2
        else:
            return "é€€è¡Œ", 1


class ObjectiveEvaluationSystem:
    """å®¢è¦³çš„è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ  ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config_path: Optional[str] = None):
        """
        åˆæœŸåŒ–

        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        self.logger = logging.getLogger(f"{__name__}.ObjectiveEvaluationSystem")

        # å„è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
        self.pla_engine = PLACalculationEngine()
        self.sci_engine = SCICalculationEngine()
        self.ple_tracker = PLEProgressTracker()

        # è¨­å®šã®èª­ã¿è¾¼ã¿
        self.config = self._load_config(config_path)

        # ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³å®šç¾©
        self.milestones = {
            "phase_a1": {"pla_target": 0.75, "weight": 0.5},
            "phase_a2": {"sci_target": 0.70, "weight": 0.5},
            "phase_b1": {"pla_target": 0.80, "sci_target": 0.75, "weight": 0.7},
            "phase_c1": {"pla_target": 0.85, "sci_target": 0.80, "ple_target": 0.15, "weight": 1.0},
        }

        self.logger.info("å®¢è¦³çš„è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

    def _load_config(self, config_path: Optional[str]) -> Dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        default_config = {
            "quality_thresholds": {"pla_minimum": 0.75, "sci_minimum": 0.70, "ple_minimum": 0.05},
            "alert_thresholds": {"regression_ple": -0.05, "critical_drop": 0.10},
        }

        if config_path and Path(config_path).exists():
            try:
                with open(config_path, "r", encoding="utf-8") as f:
                    user_config = json.load(f)
                    default_config.update(user_config)
            except Exception as e:
                self.logger.warning(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {e}")

        return default_config

    def evaluate_batch(self, extraction_results: List[Dict]) -> ObjectiveEvaluationReport:
        """
        ãƒãƒƒãƒã®å®¢è¦³çš„è©•ä¾¡å®Ÿè¡Œ

        Args:
            extraction_results: æŠ½å‡ºçµæœã®ãƒªã‚¹ãƒˆ
                å„è¦ç´ ã¯ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’å«ã‚€è¾æ›¸:
                - 'extracted_image': æŠ½å‡ºç”»åƒï¼ˆnumpy arrayï¼‰
                - 'predicted_mask': äºˆæ¸¬ãƒã‚¹ã‚¯ï¼ˆnumpy arrayï¼‰
                - 'ground_truth_mask': æ­£è§£ãƒã‚¹ã‚¯ï¼ˆnumpy array, ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            ObjectiveEvaluationReport: å®¢è¦³è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ
        """
        self.logger.info(f"ãƒãƒƒãƒè©•ä¾¡é–‹å§‹: {len(extraction_results)} ç”»åƒ")

        try:
            pla_scores = []
            sci_scores = []
            pla_details = []
            sci_details = []

            # å„ç”»åƒã®è©•ä¾¡å®Ÿè¡Œ
            for i, result in enumerate(extraction_results):
                # PLAè¨ˆç®—
                if "ground_truth_mask" in result and result["ground_truth_mask"] is not None:
                    pla_result = self.pla_engine.calculate_pla(
                        result["predicted_mask"], result["ground_truth_mask"]
                    )
                    pla_scores.append(pla_result.iou_score)
                    pla_details.append(pla_result)
                else:
                    # æ­£è§£ãƒã‚¹ã‚¯ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    self.logger.warning(f"ç”»åƒ {i}: æ­£è§£ãƒã‚¹ã‚¯ãªã— - PLAè¨ˆç®—ã‚¹ã‚­ãƒƒãƒ—")

                # SCIè¨ˆç®—
                if "extracted_image" in result:
                    sci_result = self.sci_engine.calculate_sci(result["extracted_image"])
                    sci_scores.append(sci_result.sci_total)
                    sci_details.append(sci_result)

            # PLEè¨ˆç®—
            ple_result = self.ple_tracker.calculate_ple(pla_scores, sci_scores)

            # çµ±è¨ˆå‡¦ç†
            pla_statistics = self._calculate_statistics(pla_scores) if pla_scores else None
            sci_statistics = self._calculate_statistics(sci_scores) if sci_scores else None

            # ç·åˆå“è³ªè©•ä¾¡
            overall_quality_score, overall_quality_level = self._calculate_overall_quality(
                pla_statistics, sci_statistics
            )

            # ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³é€²æ—è¨ˆç®—
            milestone_progress = self._calculate_milestone_progress(
                pla_statistics, sci_statistics, ple_result
            )

            # æ¨å¥¨äº‹é …ç”Ÿæˆ
            recommendations = self._generate_recommendations(
                pla_statistics, sci_statistics, ple_result
            )

            # ã‚¢ãƒ©ãƒ¼ãƒˆæ¤œå‡º
            alerts = self._detect_alerts(pla_statistics, sci_statistics, ple_result)

            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = ObjectiveEvaluationReport(
                timestamp=datetime.now(),
                batch_size=len(extraction_results),
                pla_statistics=pla_statistics,
                sci_statistics=sci_statistics,
                ple_result=ple_result,
                overall_quality_score=overall_quality_score,
                overall_quality_level=overall_quality_level,
                milestone_progress=milestone_progress,
                recommendations=recommendations,
                alerts=alerts,
            )

            self.logger.info(f"ãƒãƒƒãƒè©•ä¾¡å®Œäº†: ç·åˆå“è³ª={overall_quality_score:.3f}")
            return report

        except Exception as e:
            self.logger.error(f"ãƒãƒƒãƒè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def evaluate_single_extraction(self, extracted_image: np.ndarray, anime_optimized: bool = True) -> SCIResult:
        """
        å˜ä¸€æŠ½å‡ºç”»åƒã®SCIè©•ä¾¡
        
        Args:
            extracted_image: æŠ½å‡ºã•ã‚ŒãŸç”»åƒï¼ˆRGBå½¢å¼ï¼‰
            anime_optimized: ã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–é‡ã¿ä»˜ã‘ã‚’ä½¿ç”¨ã™ã‚‹ã‹
            
        Returns:
            SCIResult: SCIè©•ä¾¡çµæœ
        """
        try:
            return self.sci_engine.calculate_sci(extracted_image, anime_optimized=anime_optimized)
        except Exception as e:
            self.logger.error(f"å˜ä¸€ç”»åƒSCIè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            return SCIResult(0.0, 0.0, 0.0, 0.0, "ã‚¨ãƒ©ãƒ¼", 0, 0)

    def _calculate_statistics(self, scores: List[float]) -> StatisticsResult:
        """çµ±è¨ˆå€¤ã®è¨ˆç®—"""
        if not scores:
            return StatisticsResult(0, 0, 0, 0, 0, 0, 0, 0)

        scores_array = np.array(scores)
        return StatisticsResult(
            mean=float(np.mean(scores_array)),
            std=float(np.std(scores_array)),
            min=float(np.min(scores_array)),
            max=float(np.max(scores_array)),
            median=float(np.median(scores_array)),
            q25=float(np.percentile(scores_array, 25)),
            q75=float(np.percentile(scores_array, 75)),
            count=len(scores),
        )

    def _calculate_overall_quality(
        self, pla_stats: Optional[StatisticsResult], sci_stats: Optional[StatisticsResult]
    ) -> Tuple[float, str]:
        """ç·åˆå“è³ªã®è¨ˆç®—"""
        if pla_stats is None and sci_stats is None:
            return 0.0, "ãƒ‡ãƒ¼ã‚¿ä¸è¶³"

        # é‡ã¿ä»˜ãå¹³å‡ï¼ˆPLA 60%, SCI 40%ï¼‰
        pla_score = pla_stats.mean if pla_stats else 0.0
        sci_score = sci_stats.mean if sci_stats else 0.0

        if pla_stats and sci_stats:
            overall_score = pla_score * 0.6 + sci_score * 0.4
        elif pla_stats:
            overall_score = pla_score
        else:
            overall_score = sci_score

        # å“è³ªãƒ¬ãƒ™ãƒ«ã®æ±ºå®š
        if overall_score >= 0.85:
            quality_level = "æœ€é«˜å“è³ª"
        elif overall_score >= 0.75:
            quality_level = "é«˜å“è³ª"
        elif overall_score >= 0.65:
            quality_level = "æ¨™æº–å“è³ª"
        elif overall_score >= 0.55:
            quality_level = "è¦æ”¹å–„"
        else:
            quality_level = "å“è³ªä¸è¶³"

        return overall_score, quality_level

    def _calculate_milestone_progress(
        self,
        pla_stats: Optional[StatisticsResult],
        sci_stats: Optional[StatisticsResult],
        ple_result: PLEResult,
    ) -> Dict[str, float]:
        """ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³é”æˆåº¦ã®è¨ˆç®—"""
        progress = {}

        for milestone_id, milestone in self.milestones.items():
            achievement_rate = 0.0
            total_weight = 0.0

            # PLAç›®æ¨™ã®é”æˆåº¦
            if "pla_target" in milestone and pla_stats:
                pla_achievement = min(pla_stats.mean / milestone["pla_target"], 1.0)
                achievement_rate += pla_achievement * 0.5
                total_weight += 0.5

            # SCIç›®æ¨™ã®é”æˆåº¦
            if "sci_target" in milestone and sci_stats:
                sci_achievement = min(sci_stats.mean / milestone["sci_target"], 1.0)
                achievement_rate += sci_achievement * 0.4
                total_weight += 0.4

            # PLEç›®æ¨™ã®é”æˆåº¦
            if "ple_target" in milestone:
                ple_achievement = (
                    min(ple_result.ple_score / milestone["ple_target"], 1.0)
                    if ple_result.ple_score > 0
                    else 0.0
                )
                achievement_rate += ple_achievement * 0.1
                total_weight += 0.1

            # æ­£è¦åŒ–
            if total_weight > 0:
                progress[milestone_id] = achievement_rate / total_weight
            else:
                progress[milestone_id] = 0.0

        return progress

    def _generate_recommendations(
        self,
        pla_stats: Optional[StatisticsResult],
        sci_stats: Optional[StatisticsResult],
        ple_result: PLEResult,
    ) -> List[str]:
        """æ¨å¥¨äº‹é …ã®ç”Ÿæˆ"""
        recommendations = []

        # PLAé–¢é€£æ¨å¥¨
        if pla_stats:
            if pla_stats.mean >= self.config["quality_thresholds"]["pla_minimum"]:
                recommendations.append(
                    f"PLAç›®æ¨™ï¼ˆ{self.config['quality_thresholds']['pla_minimum']:.2f}ï¼‰é”æˆæ¸ˆã¿ - ç¶™ç¶šæ”¹å–„æ¨å¥¨"
                )
            else:
                recommendations.append(
                    f"PLAå¹³å‡å€¤å‘ä¸ŠãŒå¿…è¦: {pla_stats.mean:.3f} â†’ {self.config['quality_thresholds']['pla_minimum']:.2f}"
                )

        # SCIé–¢é€£æ¨å¥¨
        if sci_stats:
            if sci_stats.mean >= self.config["quality_thresholds"]["sci_minimum"]:
                recommendations.append(
                    f"SCIç›®æ¨™ï¼ˆ{self.config['quality_thresholds']['sci_minimum']:.2f}ï¼‰é”æˆæ¸ˆã¿ - å®‰å®šç¶­æŒ"
                )
            else:
                recommendations.append(
                    f"SCIå¹³å‡å€¤å‘ä¸ŠãŒå¿…è¦: {sci_stats.mean:.3f} â†’ {self.config['quality_thresholds']['sci_minimum']:.2f}"
                )

        # PLEé–¢é€£æ¨å¥¨
        if ple_result.ple_score >= self.config["quality_thresholds"]["ple_minimum"]:
            recommendations.append(f"PLEå€¤è‰¯å¥½ï¼ˆ{ple_result.ple_score:.3f}ï¼‰- ç¾æ‰‹æ³•ç¶™ç¶š")
        else:
            recommendations.append(f"å­¦ç¿’åŠ¹ç‡æ”¹å–„ãŒå¿…è¦: æ‰‹æ³•è¦‹ç›´ã—ã¾ãŸã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´æ¨å¥¨")

        return recommendations

    def _detect_alerts(
        self,
        pla_stats: Optional[StatisticsResult],
        sci_stats: Optional[StatisticsResult],
        ple_result: PLEResult,
    ) -> List[str]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆã®æ¤œå‡º"""
        alerts = []

        # PLAé€€è¡Œãƒã‚§ãƒƒã‚¯
        if pla_stats and pla_stats.mean < self.config["quality_thresholds"]["pla_minimum"]:
            alerts.append(
                f"PLAè­¦å‘Š: å¹³å‡å€¤ãŒç›®æ¨™ã‚’ä¸‹å›ã‚‹ ({pla_stats.mean:.3f} < {self.config['quality_thresholds']['pla_minimum']:.2f})"
            )

        # SCIé€€è¡Œãƒã‚§ãƒƒã‚¯
        if sci_stats and sci_stats.mean < self.config["quality_thresholds"]["sci_minimum"]:
            alerts.append(
                f"SCIè­¦å‘Š: å¹³å‡å€¤ãŒç›®æ¨™ã‚’ä¸‹å›ã‚‹ ({sci_stats.mean:.3f} < {self.config['quality_thresholds']['sci_minimum']:.2f})"
            )

        # PLEé€€è¡Œãƒã‚§ãƒƒã‚¯
        if ple_result.ple_score < self.config["alert_thresholds"]["regression_ple"]:
            alerts.append(
                f"å­¦ç¿’åŠ¹ç‡é€€è¡Œæ¤œå‡º: PLE={ple_result.ple_score:.3f} < {self.config['alert_thresholds']['regression_ple']:.2f}"
            )

        return alerts

    def generate_detailed_report(self, report: ObjectiveEvaluationReport) -> str:
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        report_lines = [
            "=" * 60,
            f"ğŸ“Š å®¢è¦³çš„è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ - {report.timestamp.strftime('%Y-%m-%d %H:%M:%S')}",
            "=" * 60,
            "",
            f"ğŸ“ˆ ãƒãƒƒãƒæƒ…å ±:",
            f"  å‡¦ç†ç”»åƒæ•°: {report.batch_size}",
            "",
            f"ğŸ¯ æ ¸å¿ƒæŒ‡æ¨™:",
        ]

        if report.pla_statistics:
            report_lines.extend(
                [
                    f"  PLA (Pixel Accuracy): {report.pla_statistics.mean:.3f} Â± {report.pla_statistics.std:.3f}",
                    f"    ç¯„å›²: {report.pla_statistics.min:.3f} - {report.pla_statistics.max:.3f}",
                ]
            )

        if report.sci_statistics:
            report_lines.extend(
                [
                    f"  SCI (Completeness): {report.sci_statistics.mean:.3f} Â± {report.sci_statistics.std:.3f}",
                    f"    ç¯„å›²: {report.sci_statistics.min:.3f} - {report.sci_statistics.max:.3f}",
                ]
            )

        report_lines.extend(
            [
                f"  PLE (Learning Eff.): {report.ple_result.ple_score:.3f} ({report.ple_result.learning_status})",
                "",
                f"ğŸ† ç·åˆå“è³ª:",
                f"  ã‚¹ã‚³ã‚¢: {report.overall_quality_score:.3f}",
                f"  ãƒ¬ãƒ™ãƒ«: {report.overall_quality_level}",
                "",
                f"ğŸ¯ ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³é€²æ—:",
            ]
        )

        for milestone_id, progress in report.milestone_progress.items():
            report_lines.append(f"  {milestone_id}: {progress:.1%}")

        if report.alerts:
            report_lines.extend(["", "âš ï¸ ã‚¢ãƒ©ãƒ¼ãƒˆ:"])
            for alert in report.alerts:
                report_lines.append(f"  - {alert}")
        else:
            report_lines.append("\nâœ… ã‚¢ãƒ©ãƒ¼ãƒˆ: ãªã—")

        if report.recommendations:
            report_lines.extend(["", "ğŸ’¡ æ¨å¥¨äº‹é …:"])
            for rec in report.recommendations:
                report_lines.append(f"  - {rec}")

        report_lines.append("")
        return "\n".join(report_lines)

    def save_report(self, report: ObjectiveEvaluationReport, output_path: str):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            # JSONå½¢å¼ã§ä¿å­˜
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(asdict(report), f, indent=2, ensure_ascii=False, default=str)

            # ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ã‚‚ä¿å­˜
            text_path = output_path.replace(".json", ".txt")
            with open(text_path, "w", encoding="utf-8") as f:
                f.write(self.generate_detailed_report(report))

            self.logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†: {output_path}")

        except Exception as e:
            self.logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œä¾‹"""
    import argparse

    parser = argparse.ArgumentParser(description="å®¢è¦³çš„è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("--test", action="store_true", help="ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    parser.add_argument("--config", type=str, help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    args = parser.parse_args()

    if args.test:
        # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        print("ğŸ§ª ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")

        evaluator = ObjectiveEvaluationSystem(args.config)

        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        test_results = []
        for i in range(5):
            dummy_image = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
            dummy_mask = np.random.randint(0, 2, (512, 512), dtype=np.uint8) * 255
            dummy_gt = np.random.randint(0, 2, (512, 512), dtype=np.uint8) * 255

            test_results.append(
                {
                    "extracted_image": dummy_image,
                    "predicted_mask": dummy_mask,
                    "ground_truth_mask": dummy_gt,
                }
            )

        # è©•ä¾¡å®Ÿè¡Œ
        report = evaluator.evaluate_batch(test_results)

        # çµæœè¡¨ç¤º
        print(evaluator.generate_detailed_report(report))

        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        evaluator.save_report(report, "test_evaluation_report.json")
        print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")


if __name__ == "__main__":
    main()
