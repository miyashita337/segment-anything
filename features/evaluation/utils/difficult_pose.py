"""
è¤‡é›‘ãƒãƒ¼ã‚ºãƒ»ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯æ§‹å›³å°‚ç”¨å‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
å¤±æ•—ã—ã‚„ã™ã„ç”»åƒã«å¯¾ã™ã‚‹ç‰¹åˆ¥ãªå‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯
Phase 2: ã‚¨ãƒ•ã‚§ã‚¯ãƒˆç·šé™¤å»ãƒ»ãƒãƒ«ãƒã‚³ãƒåˆ†å‰²å¯¾å¿œ
"""

import numpy as np
from typing import Dict, Any, Optional, Tuple, List
from pathlib import Path
import cv2
from PIL import Image
from features.processing.preprocessing.manga_preprocessing import MangaPreprocessor


class DifficultPoseProcessor:
    """è¤‡é›‘ãƒãƒ¼ã‚ºå°‚ç”¨å‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.retry_configs = self._generate_retry_configs()
        self.manga_processor = MangaPreprocessor()
    
    def _generate_retry_configs(self) -> List[Dict[str, Any]]:
        """æ®µéšçš„ãƒªãƒˆãƒ©ã‚¤ç”¨ã®è¨­å®šã‚’ç”Ÿæˆ (Phase 2å¯¾å¿œç‰ˆ)"""
        return [
            # Stage 1: æ¨™æº–ã‚ˆã‚Šå°‘ã—ç·©ã„è¨­å®š
            {
                'min_yolo_score': 0.08,
                'sam_points_per_side': 32,
                'sam_pred_iou_thresh': 0.86,
                'sam_stability_score_thresh': 0.90,
                'enable_enhanced_processing': False,
                'enable_manga_preprocessing': False,
                'description': 'Stage 1: è»½åº¦ç·©å’Œ'
            },
            # Stage 2: ä½é–¾å€¤è¨­å®š + æ¼«ç”»å‰å‡¦ç†
            {
                'min_yolo_score': 0.05,
                'sam_points_per_side': 48,
                'sam_pred_iou_thresh': 0.82,
                'sam_stability_score_thresh': 0.88,
                'enable_enhanced_processing': True,
                'enable_manga_preprocessing': True,
                'enable_effect_removal': True,
                'enable_panel_split': False,
                'description': 'Stage 2: ä½é–¾å€¤ + ã‚¨ãƒ•ã‚§ã‚¯ãƒˆç·šé™¤å»'
            },
            # Stage 3: æ¥µä½é–¾å€¤ + é«˜å¯†åº¦å‡¦ç† + ãƒãƒ«ãƒã‚³ãƒåˆ†å‰²
            {
                'min_yolo_score': 0.02,
                'sam_points_per_side': 64,
                'sam_pred_iou_thresh': 0.78,
                'sam_stability_score_thresh': 0.85,
                'enable_enhanced_processing': True,
                'enable_manga_preprocessing': True,
                'enable_effect_removal': True,
                'enable_panel_split': True,
                'description': 'Stage 3: æ¥µä½é–¾å€¤ + ãƒãƒ«ãƒã‚³ãƒåˆ†å‰²'
            },
            # Stage 4: æœ€çµ‚æ‰‹æ®µ - æœ€ã‚‚ç·©ã„è¨­å®š + å…¨æ©Ÿèƒ½
            {
                'min_yolo_score': 0.01,
                'sam_points_per_side': 96,
                'sam_pred_iou_thresh': 0.75,
                'sam_stability_score_thresh': 0.80,
                'enable_enhanced_processing': True,
                'enable_manga_preprocessing': True,
                'enable_effect_removal': True,
                'enable_panel_split': True,
                'crop_before_processing': True,
                'description': 'Stage 4: æœ€çµ‚æ‰‹æ®µ + å…¨æ©Ÿèƒ½'
            }
        ]
    
    def detect_pose_complexity(self, image_path: str) -> Dict[str, Any]:
        """
        ãƒãƒ¼ã‚ºã®è¤‡é›‘åº¦ã‚’åˆ¤å®š (Phase 2å¯¾å¿œç‰ˆ: ã‚¨ãƒ•ã‚§ã‚¯ãƒˆç·šãƒ»ãƒãƒ«ãƒã‚³ãƒæ¤œå‡ºå¼·åŒ–)
        
        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            Dict: è¤‡é›‘åº¦åˆ¤å®šçµæœ
        """
        try:
            # ç”»åƒèª­ã¿è¾¼ã¿
            image = cv2.imread(image_path)
            if image is None:
                return {'complexity': 'unknown', 'score': 0.0, 'factors': []}
            
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            h, w = gray.shape
            
            # è¤‡é›‘åº¦åˆ¤å®šè¦ç´ 
            factors = []
            complexity_score = 0.0
            
            # 1. ã‚¨ãƒƒã‚¸å¯†åº¦ï¼ˆé›†ä¸­ç·šã€ã‚¨ãƒ•ã‚§ã‚¯ãƒˆç·šæ¤œå‡ºï¼‰
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / (h * w)
            if edge_density > 0.15:
                factors.append('high_edge_density')
                complexity_score += 2.0
            elif edge_density > 0.10:
                factors.append('medium_edge_density')
                complexity_score += 1.0
            
            # 2. å¯¾æ¯”ã®æ¿€ã—ã•ï¼ˆæ˜æš—ã®å¤‰åŒ–ï¼‰
            contrast = np.std(gray)
            if contrast > 80:
                factors.append('high_contrast')
                complexity_score += 1.5
            elif contrast > 60:
                factors.append('medium_contrast')
                complexity_score += 0.5
            
            # 3. ç·šã®æ–¹å‘æ€§ï¼ˆæ”¾å°„çŠ¶ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º - é›†ä¸­ç·šã®ç‰¹å¾´ï¼‰
            # ãƒãƒ•å¤‰æ›ã§ç›´ç·šæ¤œå‡º
            lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)
            if lines is not None and len(lines) > 50:
                factors.append('many_lines')
                complexity_score += 1.5
                
                # æ”¾å°„çŠ¶ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
                angles = []
                for line in lines[:100]:  # æœ€å¤§100æœ¬ã¾ã§
                    rho, theta = line[0]
                    angles.append(theta)
                
                # è§’åº¦ã®åˆ†æ•£ã‚’è¨ˆç®—ï¼ˆæ”¾å°„çŠ¶ãªã‚‰åˆ†æ•£ãŒå¤§ãã„ï¼‰
                if len(angles) > 10:
                    angle_std = np.std(angles)
                    if angle_std > 0.8:
                        factors.append('radial_pattern')
                        complexity_score += 2.0
            
            # 4. ã‚¨ãƒ•ã‚§ã‚¯ãƒˆç·šå¯†åº¦æ¤œå‡º (Phase 2æ–°æ©Ÿèƒ½)
            effect_lines, effect_density = self.manga_processor.effect_remover.detect_effect_lines(image)
            if effect_density > 0.02:
                factors.append('high_effect_lines')
                complexity_score += 2.5
            elif effect_density > 0.01:
                factors.append('medium_effect_lines')
                complexity_score += 1.0
            
            # 5. ãƒãƒ«ãƒã‚³ãƒæ§‹æˆæ¤œå‡º (Phase 2æ–°æ©Ÿèƒ½)
            panel_borders = self.manga_processor.panel_splitter.detect_panel_borders(image)
            if len(panel_borders) > 3:
                factors.append('multi_panel_layout')
                complexity_score += 2.0
            elif len(panel_borders) > 1:
                factors.append('partial_panel_borders')
                complexity_score += 1.0
            
            # 6. ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸå¯†åº¦
            # æ–‡å­—ã‚‰ã—ãé ˜åŸŸã‚’æ¤œå‡ºï¼ˆå°ã•ãªçŸ©å½¢ã®å¯†é›†ï¼‰
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            small_contours = 0
            for contour in contours:
                area = cv2.contourArea(contour)
                if 50 < area < 500:  # æ–‡å­—ã‚µã‚¤ã‚ºç¨‹åº¦
                    small_contours += 1
            
            text_density = small_contours / (h * w / 10000)  # 10000ãƒ”ã‚¯ã‚»ãƒ«ã‚ãŸã‚Šã®å°é ˜åŸŸæ•°
            if text_density > 5:
                factors.append('high_text_density')
                complexity_score += 1.0
            
            # 7. ç”»åƒã®ç¸¦æ¨ªæ¯”ï¼ˆæ¥µç«¯ãªæ¯”ç‡ã¯è¤‡é›‘ãªæ§‹å›³ã®å¯èƒ½æ€§ï¼‰
            aspect_ratio = max(w/h, h/w)
            if aspect_ratio > 2.0:
                factors.append('extreme_aspect_ratio')
                complexity_score += 0.5
            
            # è¤‡é›‘åº¦ãƒ¬ãƒ™ãƒ«åˆ¤å®š (Phase 2å¯¾å¿œã§é–¾å€¤èª¿æ•´)
            if complexity_score >= 6.0:
                complexity_level = 'very_high'
            elif complexity_score >= 4.0:
                complexity_level = 'high'
            elif complexity_score >= 2.5:
                complexity_level = 'medium'
            else:
                complexity_level = 'low'
            
            return {
                'complexity': complexity_level,
                'score': complexity_score,
                'factors': factors,
                'edge_density': edge_density,
                'contrast': contrast,
                'line_count': len(lines) if lines is not None else 0,
                'text_density': text_density,
                'effect_line_density': effect_density,
                'panel_borders_count': len(panel_borders)
            }
            
        except Exception as e:
            print(f"âš ï¸ ãƒãƒ¼ã‚ºè¤‡é›‘åº¦åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
            return {'complexity': 'unknown', 'score': 0.0, 'factors': []}
    
    def get_recommended_config(self, complexity_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¤‡é›‘åº¦ã«åŸºã¥ã„ã¦æ¨å¥¨è¨­å®šã‚’è¿”ã™
        
        Args:
            complexity_info: detect_pose_complexity ã®çµæœ
            
        Returns:
            Dict: æ¨å¥¨è¨­å®š
        """
        complexity = complexity_info.get('complexity', 'medium')
        score = complexity_info.get('score', 0.0)
        
        if complexity == 'very_high' or score >= 5.0:
            return self.retry_configs[3]  # Stage 4: æœ€çµ‚æ‰‹æ®µ
        elif complexity == 'high' or score >= 3.5:
            return self.retry_configs[2]  # Stage 3: æ¥µä½é–¾å€¤
        elif complexity == 'medium' or score >= 2.0:
            return self.retry_configs[1]  # Stage 2: ä½é–¾å€¤
        else:
            return self.retry_configs[0]  # Stage 1: è»½åº¦ç·©å’Œ
    
    def preprocess_for_difficult_pose(self, image_path: str, output_path: Optional[str] = None, 
                                      enable_manga_preprocessing: bool = False,
                                      enable_effect_removal: bool = False,
                                      enable_panel_split: bool = False) -> str:
        """
        è¤‡é›‘ãƒãƒ¼ã‚ºç”¨ã®å‰å‡¦ç† (Phase 2å¯¾å¿œç‰ˆ)
        
        Args:
            image_path: å…¥åŠ›ç”»åƒãƒ‘ã‚¹
            output_path: å‡ºåŠ›ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
            enable_manga_preprocessing: æ¼«ç”»å‰å‡¦ç†ã‚’æœ‰åŠ¹åŒ–
            enable_effect_removal: ã‚¨ãƒ•ã‚§ã‚¯ãƒˆç·šé™¤å»ã‚’æœ‰åŠ¹åŒ–
            enable_panel_split: ãƒãƒ«ãƒã‚³ãƒåˆ†å‰²ã‚’æœ‰åŠ¹åŒ–
            
        Returns:
            str: å‰å‡¦ç†æ¸ˆã¿ç”»åƒãƒ‘ã‚¹
        """
        try:
            # ç”»åƒèª­ã¿è¾¼ã¿
            image = cv2.imread(image_path)
            if image is None:
                return image_path
            
            # å‰å‡¦ç†ã®é©ç”¨
            processed = image.copy()
            
            # Phase 2: æ¼«ç”»å‰å‡¦ç†
            if enable_manga_preprocessing:
                print(f"ğŸ¨ æ¼«ç”»å‰å‡¦ç†é©ç”¨ä¸­...")
                manga_result = self.manga_processor.preprocess_manga_image(
                    processed,
                    enable_effect_removal=enable_effect_removal,
                    enable_panel_split=enable_panel_split
                )
                
                print(f"   ã‚¨ãƒ•ã‚§ã‚¯ãƒˆç·šæ¤œå‡º: {'âœ…' if manga_result['effect_lines_detected'] else 'âŒ'}")
                print(f"   ãƒ‘ãƒãƒ«æ•°: {len(manga_result['panels'])}")
                print(f"   å‡¦ç†æ®µéš: {', '.join(manga_result['processing_stages'])}")
                
                # ãƒãƒ«ãƒãƒ‘ãƒãƒ«ã®å ´åˆã¯æœ€å¤§ãƒ‘ãƒãƒ«ã‚’ä½¿ç”¨
                if enable_panel_split and len(manga_result['panels']) > 1:
                    # æœ€å¤§é¢ç©ã®ãƒ‘ãƒãƒ«ã‚’é¸æŠ
                    best_panel = max(manga_result['panels'], 
                                   key=lambda p: p[1][2] * p[1][3])  # width * height
                    processed = best_panel[0]
                    print(f"   æœ€å¤§ãƒ‘ãƒãƒ«é¸æŠ: {best_panel[1]}")
                else:
                    processed = manga_result['processed_image']
            
            # å¾“æ¥ã®å‰å‡¦ç†
            # 1. ãƒã‚¤ã‚ºé™¤å»ï¼ˆãƒˆãƒ¼ãƒ³ãƒ»ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒˆãƒ¼ãƒ³å¯¾ç­–ï¼‰
            processed = cv2.bilateralFilter(processed, 9, 75, 75)
            
            # 2. ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´ï¼ˆé©åº¦ãªå¼·èª¿ï¼‰
            lab = cv2.cvtColor(processed, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            l = clahe.apply(l)
            processed = cv2.merge([l, a, b])
            processed = cv2.cvtColor(processed, cv2.COLOR_LAB2BGR)
            
            # 3. ã‚¨ãƒƒã‚¸ä¿è­·ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿
            processed = cv2.edgePreservingFilter(processed, flags=1, sigma_s=50, sigma_r=0.4)
            
            # å‡ºåŠ›ãƒ‘ã‚¹æ±ºå®š
            if output_path is None:
                input_path = Path(image_path)
                suffix = "_manga" if enable_manga_preprocessing else ""
                output_path = str(input_path.parent / f"preprocessed{suffix}_{input_path.name}")
            
            # ä¿å­˜
            cv2.imwrite(output_path, processed)
            return output_path
            
        except Exception as e:
            print(f"âš ï¸ å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return image_path
    
    def enhance_mask_for_complex_pose(self, mask: np.ndarray, original_image: np.ndarray) -> np.ndarray:
        """
        è¤‡é›‘ãƒãƒ¼ã‚ºç”¨ã®ãƒã‚¹ã‚¯å¾Œå‡¦ç†å¼·åŒ–
        
        Args:
            mask: å…ƒã®ãƒã‚¹ã‚¯
            original_image: å…ƒç”»åƒ
            
        Returns:
            np.ndarray: å¼·åŒ–ã•ã‚ŒãŸãƒã‚¹ã‚¯
        """
        try:
            # ãƒã‚¹ã‚¯ã®ã‚³ãƒ”ãƒ¼
            enhanced_mask = mask.copy()
            
            # 1. ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼æ¼”ç®—ã«ã‚ˆã‚‹ç©´åŸ‹ã‚
            kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            kernel_medium = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
            
            # å°ã•ãªç©´ã‚’åŸ‹ã‚ã‚‹
            enhanced_mask = cv2.morphologyEx(enhanced_mask, cv2.MORPH_CLOSE, kernel_small)
            
            # 2. é€£çµæˆåˆ†åˆ†æã«ã‚ˆã‚‹æœ€å¤§é ˜åŸŸæŠ½å‡º
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(enhanced_mask)
            
            if num_labels > 1:
                # æœ€å¤§ã®é€£çµæˆåˆ†ã‚’é¸æŠï¼ˆèƒŒæ™¯ã‚’é™¤ãï¼‰
                largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])
                enhanced_mask = (labels == largest_label).astype(np.uint8) * 255
            
            # 3. è¼ªéƒ­ã®å¹³æ»‘åŒ–
            contours, _ = cv2.findContours(enhanced_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if contours:
                # æœ€å¤§ã®è¼ªéƒ­ã‚’å–å¾—
                largest_contour = max(contours, key=cv2.contourArea)
                
                # è¼ªéƒ­ã‚’å¹³æ»‘åŒ–
                epsilon = 0.001 * cv2.arcLength(largest_contour, True)
                smoothed_contour = cv2.approxPolyDP(largest_contour, epsilon, True)
                
                # æ–°ã—ã„ãƒã‚¹ã‚¯ã‚’ä½œæˆ
                enhanced_mask = np.zeros_like(enhanced_mask)
                cv2.fillPoly(enhanced_mask, [smoothed_contour], 255)
            
            # 4. æœ€çµ‚çš„ãªå½¢çŠ¶è£œæ­£
            enhanced_mask = cv2.morphologyEx(enhanced_mask, cv2.MORPH_OPEN, kernel_small)
            enhanced_mask = cv2.morphologyEx(enhanced_mask, cv2.MORPH_CLOSE, kernel_medium)
            
            return enhanced_mask
            
        except Exception as e:
            print(f"âš ï¸ ãƒã‚¹ã‚¯å¼·åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return mask


def detect_difficult_pose(image_path: str) -> bool:
    """
    ç”»åƒãŒè¤‡é›‘ãƒãƒ¼ã‚ºã‹ã©ã†ã‹ã‚’ç°¡æ˜“åˆ¤å®š
    
    Args:
        image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
    Returns:
        bool: è¤‡é›‘ãƒãƒ¼ã‚ºã®å ´åˆTrue
    """
    processor = DifficultPoseProcessor()
    complexity_info = processor.detect_pose_complexity(image_path)
    
    complexity = complexity_info.get('complexity', 'low')
    return complexity in ['high', 'very_high']


def get_difficult_pose_config(image_path: str) -> Dict[str, Any]:
    """
    ç”»åƒã«é©ã—ãŸè¤‡é›‘ãƒãƒ¼ã‚ºå‡¦ç†è¨­å®šã‚’å–å¾—
    
    Args:
        image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
    Returns:
        Dict: å‡¦ç†è¨­å®š
    """
    processor = DifficultPoseProcessor()
    complexity_info = processor.detect_pose_complexity(image_path)
    config = processor.get_recommended_config(complexity_info)
    
    # è¤‡é›‘åº¦æƒ…å ±ã‚‚å«ã‚ã‚‹
    config['complexity_info'] = complexity_info
    
    return config


def process_with_retry(image_path: str, extract_function, max_retries: int = 4) -> Dict[str, Any]:
    """
    æ®µéšçš„ãƒªãƒˆãƒ©ã‚¤ã§ç”»åƒå‡¦ç†ã‚’å®Ÿè¡Œ
    
    Args:
        image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        extract_function: æŠ½å‡ºå‡¦ç†é–¢æ•°
        max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
        
    Returns:
        Dict: å‡¦ç†çµæœ
    """
    processor = DifficultPoseProcessor()
    
    # è¤‡é›‘åº¦ã‚’äº‹å‰åˆ¤å®š
    complexity_info = processor.detect_pose_complexity(image_path)
    print(f"ğŸ” ãƒãƒ¼ã‚ºè¤‡é›‘åº¦åˆ¤å®š: {complexity_info['complexity']} (ã‚¹ã‚³ã‚¢: {complexity_info['score']:.1f})")
    print(f"ğŸ“Š æ¤œå‡ºè¦ç´ : {', '.join(complexity_info['factors'])}")
    
    # å„æ®µéšã§è©¦è¡Œ
    for i, config in enumerate(processor.retry_configs[:max_retries]):
        stage = i + 1
        print(f"\nğŸ”„ {config['description']} å®Ÿè¡Œä¸­...")
        print(f"   YOLOé–¾å€¤: {config['min_yolo_score']}")
        print(f"   SAMãƒã‚¤ãƒ³ãƒˆå¯†åº¦: {config['sam_points_per_side']}")
        
        try:
            # å‰å‡¦ç†é©ç”¨ï¼ˆStage 2ä»¥é™ï¼‰
            if config.get('enable_enhanced_processing', False):
                processed_image_path = processor.preprocess_for_difficult_pose(
                    image_path,
                    enable_manga_preprocessing=config.get('enable_manga_preprocessing', False),
                    enable_effect_removal=config.get('enable_effect_removal', False),
                    enable_panel_split=config.get('enable_panel_split', False)
                )
                print(f"   å‰å‡¦ç†é©ç”¨: {processed_image_path}")
            else:
                processed_image_path = image_path
            
            # æŠ½å‡ºå®Ÿè¡Œ
            result = extract_function(processed_image_path, **config)
            
            if result.get('success', False):
                print(f"âœ… {config['description']} ã§æˆåŠŸ!")
                result['retry_stage'] = stage
                result['config_used'] = config['description']
                result['complexity_info'] = complexity_info
                return result
            else:
                print(f"âŒ {config['description']} ã§å¤±æ•—: {result.get('error', 'Unknown error')}")
        
        except Exception as e:
            print(f"âŒ {config['description']} ã§ä¾‹å¤–: {e}")
    
    # å…¨æ®µéšå¤±æ•—
    print(f"ğŸ’” å…¨{max_retries}æ®µéšã®ãƒªãƒˆãƒ©ã‚¤ãŒå¤±æ•—ã—ã¾ã—ãŸ")
    return {
        'success': False,
        'error': f'All {max_retries} retry stages failed',
        'retry_stage': max_retries,
        'complexity_info': complexity_info
    }


# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆé–¢æ•°
if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨
    test_image = "/mnt/c/AItools/lora/train/yadokugaeru/org/kaname03/25_kaname03_0024.jpg"
    
    processor = DifficultPoseProcessor()
    complexity_info = processor.detect_pose_complexity(test_image)
    
    print("=== è¤‡é›‘ãƒãƒ¼ã‚ºåˆ¤å®šãƒ†ã‚¹ãƒˆ ===")
    print(f"ç”»åƒ: {test_image}")
    print(f"è¤‡é›‘åº¦: {complexity_info['complexity']}")
    print(f"ã‚¹ã‚³ã‚¢: {complexity_info['score']:.2f}")
    print(f"è¦ç´ : {complexity_info['factors']}")
    
    config = processor.get_recommended_config(complexity_info)
    print(f"\næ¨å¥¨è¨­å®š: {config['description']}")
    print(f"YOLOé–¾å€¤: {config['min_yolo_score']}")