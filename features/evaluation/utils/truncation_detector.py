#!/usr/bin/env python3
"""
P1-020: åˆ‡æ–­æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
äººä½“ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡ºã«ãŠã‘ã‚‹æ‰‹è¶³ãƒ»èº«ä½“éƒ¨ä½ã®åˆ‡æ–­ã‚’æ¤œå‡ºãƒ»é˜²æ­¢ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 

Features:
- Edge-based truncation detection
- Body part completeness analysis
- Anatomical structure validation
- Truncation severity assessment
- Recovery suggestion generation
"""

import numpy as np
import cv2
from typing import Dict, List, Tuple, Optional, Any
import json
from pathlib import Path
from datetime import datetime

# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…ç”¨
HAS_SCIPY = True
HAS_SKLEARN = True

try:
    from scipy import ndimage, morphology
    from scipy.spatial.distance import cdist
except ImportError:
    HAS_SCIPY = False

try:
    from sklearn.cluster import DBSCAN
except ImportError:
    HAS_SKLEARN = False


class TruncationDetector:
    """æ‰‹è¶³åˆ‡æ–­æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.name = "TruncationDetector"
        self.version = "1.0.0"
        
        # åˆ‡æ–­æ¤œå‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.detection_params = {
            'edge_threshold': 0.05,      # ã‚¨ãƒƒã‚¸ã§ã®åˆ‡æ–­åˆ¤å®šé–¾å€¤
            'completeness_threshold': 0.7, # éƒ¨ä½å®Œå…¨æ€§ã®æœ€ä½åŸºæº–
            'aspect_ratio_bounds': (0.3, 3.0), # æ­£å¸¸ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ç¯„å›²
            'edge_proximity_threshold': 10,  # ã‚¨ãƒƒã‚¸è¿‘æ¥åˆ¤å®šè·é›¢
            'limb_width_ratio': 0.15,    # æ‰‹è¶³å¹…æ¯”ç‡
            'torso_minimum_ratio': 0.4   # èƒ´ä½“æœ€å°æ¯”ç‡
        }
        
        # éƒ¨ä½åˆ¥åˆ‡æ–­é‡è¦åº¦
        self.truncation_severity = {
            'head': 0.9,      # é ­éƒ¨åˆ‡æ–­ã¯é‡å¤§
            'torso': 0.8,     # èƒ´ä½“åˆ‡æ–­ã‚‚é‡è¦
            'upper_limb': 0.6, # ä¸Šè‚¢ï¼ˆè…•ï¼‰
            'lower_limb': 0.7, # ä¸‹è‚¢ï¼ˆè„šï¼‰
            'hands': 0.4,     # æ‰‹éƒ¨
            'feet': 0.5       # è¶³éƒ¨
        }
        
        # ã‚°ãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°åŸºæº–
        self.severity_grades = {
            'A': (0.0, 0.1),   # No truncation
            'B': (0.1, 0.3),   # Minor truncation
            'C': (0.3, 0.5),   # Moderate truncation
            'D': (0.5, 0.7),   # Significant truncation
            'F': (0.7, 1.0)    # Severe truncation
        }
    
    def detect_truncation(self, mask: np.ndarray, image_bounds: Optional[Tuple] = None) -> Dict[str, Any]:
        """
        åŒ…æ‹¬çš„åˆ‡æ–­æ¤œå‡ºåˆ†æ
        
        Args:
            mask: ãƒã‚¤ãƒŠãƒªãƒã‚¹ã‚¯ç”»åƒ
            image_bounds: ç”»åƒå¢ƒç•Œæƒ…å ± (height, width)
            
        Returns:
            Dict: åˆ‡æ–­æ¤œå‡ºçµæœ
        """
        if mask is None or mask.size == 0:
            return self._generate_error_result("Empty or invalid mask")
        
        try:
            # ç”»åƒå¢ƒç•Œæƒ…å ±è¨­å®š
            if image_bounds is None:
                image_bounds = mask.shape
            
            # ã‚¨ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹åˆ‡æ–­æ¤œå‡º
            edge_analysis = self._detect_edge_truncation(mask, image_bounds)
            
            # èº«ä½“éƒ¨ä½å®Œå…¨æ€§åˆ†æ
            completeness_analysis = self._analyze_body_completeness(mask)
            
            # è§£å‰–å­¦çš„æ§‹é€ æ¤œè¨¼
            anatomical_analysis = self._validate_anatomical_structure(mask)
            
            # ã‚¨ãƒƒã‚¸è¿‘æ¥åˆ†æ
            proximity_analysis = self._analyze_edge_proximity(mask, image_bounds)
            
            # ç·åˆåˆ‡æ–­è©•ä¾¡
            overall_assessment = self._calculate_overall_truncation_assessment(
                edge_analysis, completeness_analysis, anatomical_analysis, proximity_analysis
            )
            
            # å›å¾©ææ¡ˆç”Ÿæˆ
            recovery_suggestions = self._generate_recovery_suggestions(
                edge_analysis, completeness_analysis, anatomical_analysis
            )
            
            return {
                'analysis_type': 'truncation_detection',
                'mask_info': {
                    'mask_shape': mask.shape,
                    'mask_area': int(np.sum(mask > 0)),
                    'image_bounds': image_bounds
                },
                'edge_truncation': edge_analysis,
                'body_completeness': completeness_analysis,
                'anatomical_validation': anatomical_analysis,
                'edge_proximity': proximity_analysis,
                'overall_assessment': overall_assessment,
                'recovery_suggestions': recovery_suggestions,
                'processing_info': {
                    'timestamp': datetime.now().isoformat(),
                    'version': self.version
                }
            }
            
        except Exception as e:
            return self._generate_error_result(f"Truncation detection failed: {str(e)}")
    
    def _detect_edge_truncation(self, mask: np.ndarray, image_bounds: Tuple) -> Dict[str, Any]:
        """ã‚¨ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹åˆ‡æ–­æ¤œå‡º"""
        try:
            height, width = image_bounds[:2]
            edge_threshold = int(min(height, width) * self.detection_params['edge_threshold'])
            
            # ãƒã‚¹ã‚¯ã®å¢ƒç•Œæ¤œå‡º
            if mask.dtype != np.uint8:
                mask_uint8 = (mask > 0).astype(np.uint8) * 255
            else:
                mask_uint8 = mask
            
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if not contours:
                return {'error': 'No contours found for edge analysis'}
            
            # æœ€å¤§è¼ªéƒ­é¸æŠ
            main_contour = max(contours, key=cv2.contourArea)
            
            # å„ã‚¨ãƒƒã‚¸ã§ã®åˆ‡æ–­æ¤œå‡º
            edge_truncations = {
                'top': self._check_edge_truncation(main_contour, 'top', edge_threshold, width, height),
                'bottom': self._check_edge_truncation(main_contour, 'bottom', edge_threshold, width, height),
                'left': self._check_edge_truncation(main_contour, 'left', edge_threshold, width, height),
                'right': self._check_edge_truncation(main_contour, 'right', edge_threshold, width, height)
            }
            
            # åˆ‡æ–­ã‚¹ã‚³ã‚¢è¨ˆç®—
            truncation_scores = {edge: info['truncation_score'] for edge, info in edge_truncations.items()}
            overall_edge_score = max(truncation_scores.values()) if truncation_scores else 0.0
            
            return {
                'edge_truncations': edge_truncations,
                'truncation_scores': truncation_scores,
                'overall_edge_truncation_score': overall_edge_score,
                'edge_truncation_grade': self._score_to_grade(overall_edge_score)
            }
            
        except Exception as e:
            return {'error': f'Edge truncation detection failed: {str(e)}'}
    
    def _check_edge_truncation(self, contour: np.ndarray, edge: str, threshold: int, 
                              width: int, height: int) -> Dict[str, Any]:
        """ç‰¹å®šã‚¨ãƒƒã‚¸ã§ã®åˆ‡æ–­ãƒã‚§ãƒƒã‚¯"""
        points = contour.reshape(-1, 2)
        
        # ã‚¨ãƒƒã‚¸è¿‘æ¥ç‚¹æ¤œå‡º
        if edge == 'top':
            near_edge = points[points[:, 1] <= threshold]
            edge_length = width
        elif edge == 'bottom':
            near_edge = points[points[:, 1] >= height - threshold]
            edge_length = width
        elif edge == 'left':
            near_edge = points[points[:, 0] <= threshold]
            edge_length = height
        elif edge == 'right':
            near_edge = points[points[:, 0] >= width - threshold]
            edge_length = height
        else:
            return {'error': f'Unknown edge: {edge}'}
        
        if len(near_edge) == 0:
            return {
                'truncation_detected': False,
                'truncation_score': 0.0,
                'affected_length': 0,
                'severity': 'none'
            }
        
        # åˆ‡æ–­é•·ã•è¨ˆç®—
        if edge in ['top', 'bottom']:
            affected_length = np.ptp(near_edge[:, 0]) if len(near_edge) > 1 else 0
        else:
            affected_length = np.ptp(near_edge[:, 1]) if len(near_edge) > 1 else 0
        
        # åˆ‡æ–­ã‚¹ã‚³ã‚¢è¨ˆç®—
        truncation_ratio = affected_length / edge_length if edge_length > 0 else 0
        truncation_score = min(truncation_ratio * 2, 1.0)  # æ­£è¦åŒ–
        
        # é‡è¦åº¦åˆ¤å®š
        severity = self._determine_truncation_severity(edge, truncation_score)
        
        return {
            'truncation_detected': truncation_score > 0.1,
            'truncation_score': truncation_score,
            'affected_length': int(affected_length),
            'edge_length': edge_length,
            'truncation_ratio': truncation_ratio,
            'severity': severity,
            'near_edge_points': len(near_edge)
        }
    
    def _analyze_body_completeness(self, mask: np.ndarray) -> Dict[str, Any]:
        """èº«ä½“éƒ¨ä½å®Œå…¨æ€§åˆ†æ"""
        try:
            # ãƒã‚¹ã‚¯ã®åŸºæœ¬æƒ…å ±
            mask_binary = mask > 0
            total_area = np.sum(mask_binary)
            
            if total_area == 0:
                return {'error': 'Empty mask for completeness analysis'}
            
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
            coords = np.column_stack(np.where(mask_binary))
            if len(coords) == 0:
                return {'error': 'No valid coordinates found'}
            
            min_y, min_x = coords.min(axis=0)
            max_y, max_x = coords.max(axis=0)
            
            height = max_y - min_y + 1
            width = max_x - min_x + 1
            aspect_ratio = height / width if width > 0 else 0
            
            # èº«ä½“éƒ¨ä½æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
            body_regions = self._estimate_body_regions(mask_binary, min_y, max_y, min_x, max_x)
            
            # å„éƒ¨ä½ã®å®Œå…¨æ€§è©•ä¾¡
            completeness_scores = {}
            for region_name, region_info in body_regions.items():
                completeness_scores[region_name] = self._evaluate_region_completeness(
                    mask_binary, region_info
                )
            
            # å…¨ä½“å®Œå…¨æ€§ã‚¹ã‚³ã‚¢
            if completeness_scores:
                overall_completeness = np.mean(list(completeness_scores.values()))
            else:
                overall_completeness = 0.0
            
            return {
                'mask_dimensions': {'height': height, 'width': width},
                'aspect_ratio': aspect_ratio,
                'body_regions': body_regions,
                'completeness_scores': completeness_scores,
                'overall_completeness': overall_completeness,
                'completeness_grade': self._score_to_grade(1.0 - overall_completeness)  # ä½ã„æ–¹ãŒè‰¯ã„
            }
            
        except Exception as e:
            return {'error': f'Body completeness analysis failed: {str(e)}'}
    
    def _estimate_body_regions(self, mask: np.ndarray, min_y: int, max_y: int, 
                              min_x: int, max_x: int) -> Dict[str, Dict]:
        """èº«ä½“éƒ¨ä½æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        height = max_y - min_y + 1
        width = max_x - min_x + 1
        
        # åŸºæœ¬çš„ãªèº«ä½“éƒ¨ä½åˆ†å‰²
        regions = {
            'head': {
                'y_range': (min_y, min_y + int(height * 0.25)),
                'x_range': (min_x, max_x),
                'expected_ratio': 0.15
            },
            'torso': {
                'y_range': (min_y + int(height * 0.25), min_y + int(height * 0.7)),
                'x_range': (min_x, max_x),
                'expected_ratio': 0.45
            },
            'lower_body': {
                'y_range': (min_y + int(height * 0.7), max_y),
                'x_range': (min_x, max_x),
                'expected_ratio': 0.4
            }
        }
        
        return regions
    
    def _evaluate_region_completeness(self, mask: np.ndarray, region_info: Dict) -> float:
        """éƒ¨ä½å®Œå…¨æ€§è©•ä¾¡"""
        try:
            y_min, y_max = region_info['y_range']
            x_min, x_max = region_info['x_range']
            
            # é ˜åŸŸå†…ã®ãƒã‚¹ã‚¯é¢ç©
            region_mask = mask[y_min:y_max, x_min:x_max]
            region_area = np.sum(region_mask)
            
            # æœŸå¾…ã•ã‚Œã‚‹é¢ç©
            region_total = (y_max - y_min) * (x_max - x_min)
            expected_area = region_total * region_info.get('expected_ratio', 0.3)
            
            # å®Œå…¨æ€§ã‚¹ã‚³ã‚¢ï¼ˆæœŸå¾…é¢ç©ã«å¯¾ã™ã‚‹å®Ÿéš›é¢ç©ã®æ¯”ç‡ï¼‰
            if expected_area > 0:
                completeness = min(region_area / expected_area, 1.0)
            else:
                completeness = 0.0
            
            return 1.0 - completeness  # ä¸å®Œå…¨æ€§ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©åˆ‡æ–­å¯èƒ½æ€§å¤§ï¼‰
            
        except Exception:
            return 1.0  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯æœ€å¤§ä¸å®Œå…¨æ€§
    
    def _validate_anatomical_structure(self, mask: np.ndarray) -> Dict[str, Any]:
        """è§£å‰–å­¦çš„æ§‹é€ æ¤œè¨¼"""
        try:
            mask_binary = mask > 0
            
            # é€£çµæˆåˆ†åˆ†æ
            if HAS_SCIPY:
                labeled_mask, num_components = ndimage.label(mask_binary)
                component_sizes = [np.sum(labeled_mask == i) for i in range(1, num_components + 1)]
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šOpenCVãƒ™ãƒ¼ã‚¹
                contours, _ = cv2.findContours(
                    mask_binary.astype(np.uint8) * 255, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
                )
                num_components = len(contours)
                component_sizes = [cv2.contourArea(c) for c in contours] if contours else []
            
            # æ§‹é€ åˆ†æ
            structure_analysis = {
                'component_count': num_components,
                'component_sizes': component_sizes,
                'main_component_ratio': max(component_sizes) / sum(component_sizes) if component_sizes else 0,
                'fragmentation_score': self._calculate_fragmentation_score(component_sizes)
            }
            
            # è§£å‰–å­¦çš„å¦¥å½“æ€§è©•ä¾¡
            anatomical_validity = self._assess_anatomical_validity(structure_analysis, mask_binary)
            
            return {
                'structure_analysis': structure_analysis,
                'anatomical_validity': anatomical_validity,
                'structure_grade': self._score_to_grade(1.0 - structure_analysis['fragmentation_score'])
            }
            
        except Exception as e:
            return {'error': f'Anatomical structure validation failed: {str(e)}'}
    
    def _calculate_fragmentation_score(self, component_sizes: List[int]) -> float:
        """æ–­ç‰‡åŒ–ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        if not component_sizes:
            return 1.0
        
        if len(component_sizes) == 1:
            return 0.0  # å˜ä¸€æˆåˆ†ãªã‚‰æ–­ç‰‡åŒ–ãªã—
        
        total_area = sum(component_sizes)
        main_ratio = max(component_sizes) / total_area if total_area > 0 else 0
        
        # æ–­ç‰‡åŒ–ã‚¹ã‚³ã‚¢ï¼ˆä¸»æˆåˆ†æ¯”ç‡ãŒä½ã„ã»ã©æ–­ç‰‡åŒ–å¤§ï¼‰
        fragmentation = 1.0 - main_ratio
        
        # è¤‡æ•°æˆåˆ†ã®ãƒšãƒŠãƒ«ãƒ†ã‚£
        component_penalty = min((len(component_sizes) - 1) * 0.2, 0.8)
        
        return min(fragmentation + component_penalty, 1.0)
    
    def _assess_anatomical_validity(self, structure_analysis: Dict, mask: np.ndarray) -> Dict[str, Any]:
        """è§£å‰–å­¦çš„å¦¥å½“æ€§è©•ä¾¡"""
        validity_score = 1.0
        issues = []
        
        # éåº¦ãªæ–­ç‰‡åŒ–ãƒã‚§ãƒƒã‚¯
        if structure_analysis['component_count'] > 3:
            validity_score -= 0.3
            issues.append('excessive_fragmentation')
        
        # ä¸»æˆåˆ†æ¯”ç‡ãƒã‚§ãƒƒã‚¯
        if structure_analysis['main_component_ratio'] < 0.7:
            validity_score -= 0.2
            issues.append('weak_main_component')
        
        # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ãƒã‚§ãƒƒã‚¯
        coords = np.column_stack(np.where(mask))
        if len(coords) > 0:
            height = coords[:, 0].ptp() + 1
            width = coords[:, 1].ptp() + 1
            aspect_ratio = height / width if width > 0 else 0
            
            if not (self.detection_params['aspect_ratio_bounds'][0] <= 
                   aspect_ratio <= self.detection_params['aspect_ratio_bounds'][1]):
                validity_score -= 0.2
                issues.append('unusual_aspect_ratio')
        
        validity_score = max(validity_score, 0.0)
        
        return {
            'validity_score': validity_score,
            'validity_issues': issues,
            'is_anatomically_valid': validity_score > 0.6
        }
    
    def _analyze_edge_proximity(self, mask: np.ndarray, image_bounds: Tuple) -> Dict[str, Any]:
        """ã‚¨ãƒƒã‚¸è¿‘æ¥åˆ†æ"""
        try:
            height, width = image_bounds[:2]
            threshold = self.detection_params['edge_proximity_threshold']
            
            mask_binary = mask > 0
            coords = np.column_stack(np.where(mask_binary))
            
            if len(coords) == 0:
                return {'error': 'No coordinates for proximity analysis'}
            
            # å„ã‚¨ãƒƒã‚¸ã¸ã®è¿‘æ¥åº¦è¨ˆç®—
            edge_proximities = {
                'top': np.sum(coords[:, 0] < threshold),
                'bottom': np.sum(coords[:, 0] > height - threshold),
                'left': np.sum(coords[:, 1] < threshold),
                'right': np.sum(coords[:, 1] > width - threshold)
            }
            
            total_points = len(coords)
            proximity_ratios = {edge: count / total_points for edge, count in edge_proximities.items()}
            
            # æœ€å¤§è¿‘æ¥åº¦ï¼ˆæœ€ã‚‚å•é¡Œã®ã‚ã‚‹ã‚¨ãƒƒã‚¸ï¼‰
            max_proximity = max(proximity_ratios.values()) if proximity_ratios else 0
            
            return {
                'edge_proximities': edge_proximities,
                'proximity_ratios': proximity_ratios,
                'max_proximity_ratio': max_proximity,
                'proximity_grade': self._score_to_grade(1.0 - max_proximity)
            }
            
        except Exception as e:
            return {'error': f'Edge proximity analysis failed: {str(e)}'}
    
    def _calculate_overall_truncation_assessment(self, edge_analysis: Dict, completeness_analysis: Dict,
                                               anatomical_analysis: Dict, proximity_analysis: Dict) -> Dict[str, Any]:
        """ç·åˆåˆ‡æ–­è©•ä¾¡è¨ˆç®—"""
        scores = []
        weights = []
        
        # ã‚¨ãƒƒã‚¸åˆ‡æ–­ã‚¹ã‚³ã‚¢
        if 'overall_edge_truncation_score' in edge_analysis:
            scores.append(edge_analysis['overall_edge_truncation_score'])
            weights.append(0.4)
        
        # å®Œå…¨æ€§ã‚¹ã‚³ã‚¢
        if 'overall_completeness' in completeness_analysis:
            scores.append(completeness_analysis['overall_completeness'])
            weights.append(0.3)
        
        # è§£å‰–å­¦çš„æ§‹é€ ã‚¹ã‚³ã‚¢
        if 'structure_analysis' in anatomical_analysis:
            fragmentation = anatomical_analysis['structure_analysis'].get('fragmentation_score', 0)
            scores.append(fragmentation)
            weights.append(0.2)
        
        # è¿‘æ¥ã‚¹ã‚³ã‚¢
        if 'max_proximity_ratio' in proximity_analysis:
            scores.append(proximity_analysis['max_proximity_ratio'])
            weights.append(0.1)
        
        # é‡ã¿ä»˜ãå¹³å‡
        if scores and weights:
            overall_score = np.average(scores, weights=weights)
        else:
            overall_score = 0.0
        
        # é‡è¦åº¦åˆ†æ
        severity_assessment = self._assess_truncation_severity(overall_score, edge_analysis, completeness_analysis)
        
        return {
            'overall_truncation_score': overall_score,
            'truncation_grade': self._score_to_grade(overall_score),
            'severity_assessment': severity_assessment,
            'component_scores': {
                'edge_truncation': edge_analysis.get('overall_edge_truncation_score', 0),
                'incompleteness': completeness_analysis.get('overall_completeness', 0),
                'fragmentation': anatomical_analysis.get('structure_analysis', {}).get('fragmentation_score', 0),
                'edge_proximity': proximity_analysis.get('max_proximity_ratio', 0)
            }
        }
    
    def _assess_truncation_severity(self, overall_score: float, edge_analysis: Dict, 
                                  completeness_analysis: Dict) -> str:
        """åˆ‡æ–­é‡è¦åº¦è©•ä¾¡"""
        if overall_score <= 0.1:
            return "no_truncation"
        elif overall_score <= 0.3:
            return "minor_truncation"
        elif overall_score <= 0.5:
            return "moderate_truncation"
        elif overall_score <= 0.7:
            return "significant_truncation"
        else:
            return "severe_truncation"
    
    def _generate_recovery_suggestions(self, edge_analysis: Dict, completeness_analysis: Dict,
                                     anatomical_analysis: Dict) -> List[str]:
        """å›å¾©ææ¡ˆç”Ÿæˆ"""
        suggestions = []
        
        # ã‚¨ãƒƒã‚¸åˆ‡æ–­ã¸ã®å¯¾å¿œ
        if edge_analysis.get('overall_edge_truncation_score', 0) > 0.3:
            suggestions.append("expand_extraction_area")
            suggestions.append("adjust_bounding_box")
        
        # ä¸å®Œå…¨æ€§ã¸ã®å¯¾å¿œ
        if completeness_analysis.get('overall_completeness', 0) > 0.4:
            suggestions.append("improve_segmentation_parameters")
            suggestions.append("use_larger_input_resolution")
        
        # æ–­ç‰‡åŒ–ã¸ã®å¯¾å¿œ
        fragmentation = anatomical_analysis.get('structure_analysis', {}).get('fragmentation_score', 0)
        if fragmentation > 0.3:
            suggestions.append("merge_disconnected_components")
            suggestions.append("apply_morphological_closing")
        
        return suggestions
    
    def _determine_truncation_severity(self, edge: str, score: float) -> str:
        """ã‚¨ãƒƒã‚¸åˆ¥åˆ‡æ–­é‡è¦åº¦åˆ¤å®š"""
        if score <= 0.1:
            return "none"
        elif score <= 0.3:
            return "minor"
        elif score <= 0.5:
            return "moderate"
        else:
            return "severe"
    
    def _score_to_grade(self, score: float) -> str:
        """ã‚¹ã‚³ã‚¢ã‹ã‚‰ã‚°ãƒ¬ãƒ¼ãƒ‰ã¸ã®å¤‰æ›"""
        for grade, (min_val, max_val) in self.severity_grades.items():
            if min_val <= score < max_val:
                return grade
        return 'F'
    
    def _generate_error_result(self, error_message: str) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼çµæœç”Ÿæˆ"""
        return {
            'error': error_message,
            'overall_assessment': {
                'overall_truncation_score': 1.0,
                'truncation_grade': 'F',
                'severity_assessment': 'analysis_failed'
            }
        }


def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ P1-020: åˆ‡æ–­æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ãƒ†ã‚¹ãƒˆç”¨äººä½“å½¢çŠ¶ãƒã‚¹ã‚¯ä½œæˆ
    test_mask = np.zeros((200, 150), dtype=np.uint8)
    
    # é ­éƒ¨
    cv2.circle(test_mask, (75, 40), 25, 255, -1)
    # èƒ´ä½“
    cv2.rectangle(test_mask, (50, 65), (100, 120), 255, -1)
    # è„šéƒ¨ï¼ˆä¸€éƒ¨ã‚’æ„å›³çš„ã«åˆ‡æ–­ï¼‰
    cv2.rectangle(test_mask, (55, 120), (95, 190), 255, -1)  # ç”»åƒä¸‹ç«¯è¿‘ãã§åˆ‡æ–­
    
    # åˆ‡æ–­æ¤œå‡ºå®Ÿè¡Œ
    detector = TruncationDetector()
    result = detector.detect_truncation(test_mask, (200, 150))
    
    print("\nğŸ“Š åˆ‡æ–­æ¤œå‡ºçµæœ:")
    if 'error' not in result:
        overall = result.get('overall_assessment', {})
        print(f"  ç·åˆåˆ‡æ–­ã‚¹ã‚³ã‚¢: {overall.get('overall_truncation_score', 0):.3f}")
        print(f"  åˆ‡æ–­ã‚°ãƒ¬ãƒ¼ãƒ‰: {overall.get('truncation_grade', 'N/A')}")
        print(f"  é‡è¦åº¦è©•ä¾¡: {overall.get('severity_assessment', 'N/A')}")
        
        # ã‚¨ãƒƒã‚¸åˆ‡æ–­è©³ç´°
        edge_analysis = result.get('edge_truncation', {})
        if 'truncation_scores' in edge_analysis:
            print(f"\nğŸ” ã‚¨ãƒƒã‚¸åˆ‡æ–­ã‚¹ã‚³ã‚¢:")
            for edge, score in edge_analysis['truncation_scores'].items():
                print(f"    {edge}: {score:.3f}")
        
        # å›å¾©ææ¡ˆ
        suggestions = result.get('recovery_suggestions', [])
        if suggestions:
            print(f"\nğŸ’¡ å›å¾©ææ¡ˆ: {', '.join(suggestions)}")
    else:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
    
    print(f"\nâœ… [P1-020] åˆ‡æ–­æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å®Œäº†")


if __name__ == "__main__":
    main()