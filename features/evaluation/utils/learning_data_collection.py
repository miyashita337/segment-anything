#!/usr/bin/env python3
"""
Learning Data Collection Plan - P1-009
å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åé›†è¨ˆç”»ç­–å®šã‚·ã‚¹ãƒ†ãƒ 

æ—¢å­˜ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’æ‹¡å¼µã—ã€åŠ¹ç‡çš„ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿åé›†æˆ¦ç•¥ã‚’ç¢ºç«‹
"""

import os
import json
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime
import numpy as np
from collections import defaultdict, Counter


class LearningDataCollectionPlanner:
    """
    å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åé›†è¨ˆç”»ç­–å®šã‚·ã‚¹ãƒ†ãƒ 
    
    æ—¢å­˜ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€åŠ¹ç‡çš„ãªè¿½åŠ ãƒ‡ãƒ¼ã‚¿åé›†æˆ¦ç•¥ã‚’ç­–å®š
    """
    
    def __init__(self, evaluation_data_path: str = None):
        """
        åˆæœŸåŒ–
        
        Args:
            evaluation_data_path: æ—¢å­˜è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹
        """
        self.evaluation_data_path = evaluation_data_path or self._find_evaluation_data()
        self.evaluation_data = []
        self.analysis_results = {}
        
        if self.evaluation_data_path and os.path.exists(self.evaluation_data_path):
            self.load_evaluation_data()
    
    def _find_evaluation_data(self) -> Optional[str]:
        """æ—¢å­˜ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        possible_paths = [
            "features/evaluation/logs/kaname07_user_evaluation.jsonl",
            "logs/user_evaluation.jsonl",
            "evaluation_data.jsonl"
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                return path
        return None
    
    def load_evaluation_data(self) -> bool:
        """è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        try:
            with open(self.evaluation_data_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        self.evaluation_data.append(json.loads(line))
            
            print(f"âœ… è©•ä¾¡ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(self.evaluation_data)}ä»¶")
            return True
            
        except Exception as e:
            print(f"âŒ è©•ä¾¡ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def analyze_existing_data(self) -> Dict[str, Any]:
        """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ"""
        if not self.evaluation_data:
            return {"error": "è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        
        # åŸºæœ¬çµ±è¨ˆ
        total_count = len(self.evaluation_data)
        success_count = sum(1 for item in self.evaluation_data if item.get('extraction_success', False))
        success_rate = success_count / total_count if total_count > 0 else 0
        
        # è©•ä¾¡åˆ†å¸ƒ
        rating_distribution = Counter()
        problem_distribution = Counter()
        region_distribution = Counter()
        
        for item in self.evaluation_data:
            # è©•ä¾¡åˆ†å¸ƒ
            rating = item.get('user_rating')
            if rating:
                rating_distribution[rating] += 1
            
            # å•é¡Œåˆ†å¸ƒ
            problem = item.get('actual_problem', 'unknown')
            problem_distribution[problem] += 1
            
            # åœ°åŸŸè¦æ±‚åˆ†å¸ƒ
            region = item.get('desired_region', 'unknown')
            if region != 'unknown' and region != 'success':
                region_distribution[region] += 1
        
        # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        success_patterns = []
        failure_patterns = []
        
        for item in self.evaluation_data:
            pattern = {
                'user_rating': item.get('user_rating'),
                'desired_region': item.get('desired_region'),
                'actual_problem': item.get('actual_problem'),
                'extraction_success': item.get('extraction_success', False)
            }
            
            if item.get('extraction_success', False) and item.get('user_rating') in ['A', 'B']:
                success_patterns.append(pattern)
            else:
                failure_patterns.append(pattern)
        
        self.analysis_results = {
            'basic_stats': {
                'total_count': total_count,
                'success_count': success_count,
                'success_rate': success_rate,
                'failure_count': total_count - success_count
            },
            'distributions': {
                'rating': dict(rating_distribution),
                'problems': dict(problem_distribution),
                'regions': dict(region_distribution)
            },
            'patterns': {
                'success_patterns': success_patterns,
                'failure_patterns': failure_patterns,
                'success_pattern_count': len(success_patterns),
                'failure_pattern_count': len(failure_patterns)
            }
        }
        
        return self.analysis_results
    
    def identify_data_gaps(self) -> Dict[str, List[str]]:
        """ãƒ‡ãƒ¼ã‚¿ã‚®ãƒ£ãƒƒãƒ—ã®ç‰¹å®š"""
        if not self.analysis_results:
            self.analyze_existing_data()
        
        gaps = {
            'underrepresented_problems': [],
            'missing_regions': [],
            'rating_imbalance': [],
            'success_case_shortage': []
        }
        
        # å•é¡Œåˆ†å¸ƒã®åã‚Š
        problem_dist = self.analysis_results['distributions']['problems']
        total_problems = sum(problem_dist.values())
        
        for problem, count in problem_dist.items():
            ratio = count / total_problems if total_problems > 0 else 0
            if ratio < 0.1:  # 10%æœªæº€ã¯ä¸è¶³
                gaps['underrepresented_problems'].append(f"{problem} ({count}ä»¶, {ratio:.1%})")
        
        # åœ°åŸŸè¦æ±‚ã®ä¸è¶³
        region_dist = self.analysis_results['distributions']['regions']
        expected_regions = ['ç”»é¢å·¦å´', 'ç”»é¢å³å´', 'ç”»é¢ä¸Šéƒ¨', 'ç”»é¢ä¸‹éƒ¨', 'ç”»é¢ä¸­å¤®', 'ç”»é¢å³ä¸Š', 'ç”»é¢å·¦ä¸‹']
        
        for region in expected_regions:
            if region not in region_dist:
                gaps['missing_regions'].append(region)
        
        # è©•ä¾¡åˆ†å¸ƒã®åã‚Š
        rating_dist = self.analysis_results['distributions']['rating']
        total_ratings = sum(rating_dist.values())
        
        for rating in ['A', 'B', 'C', 'D', 'E', 'F']:
            count = rating_dist.get(rating, 0)
            ratio = count / total_ratings if total_ratings > 0 else 0
            if rating in ['A', 'B'] and ratio < 0.2:  # æˆåŠŸä¾‹ãŒ20%æœªæº€
                gaps['success_case_shortage'].append(f"{rating}è©•ä¾¡ ({count}ä»¶, {ratio:.1%})")
            elif rating in ['D', 'E', 'F'] and ratio > 0.4:  # å¤±æ•—ä¾‹ãŒ40%è¶…
                gaps['rating_imbalance'].append(f"{rating}è©•ä¾¡ãŒéå¤š ({count}ä»¶, {ratio:.1%})")
        
        return gaps
    
    def generate_collection_strategy(self) -> Dict[str, Any]:
        """åŠ¹ç‡çš„ãƒ‡ãƒ¼ã‚¿åé›†æˆ¦ç•¥ã®ç”Ÿæˆ"""
        gaps = self.identify_data_gaps()
        
        # å„ªå…ˆåº¦ä»˜ããƒ‡ãƒ¼ã‚¿åé›†è¨ˆç”»
        strategy = {
            'high_priority': [],
            'medium_priority': [],
            'low_priority': [],
            'sampling_strategy': {},
            'target_metrics': {}
        }
        
        # é«˜å„ªå…ˆåº¦: æˆåŠŸäº‹ä¾‹ä¸è¶³
        if gaps['success_case_shortage']:
            strategy['high_priority'].extend([
                "Aãƒ»Bè©•ä¾¡ç²å¾—äº‹ä¾‹ã®åé›†å¼·åŒ–",
                "æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°åˆ†æ",
                "é«˜å“è³ªæŠ½å‡ºã®å†ç¾æ¡ä»¶ç‰¹å®š"
            ])
        
        # ä¸­å„ªå…ˆåº¦: åœ°åŸŸãƒ»å•é¡Œã®åã‚Š
        if gaps['missing_regions']:
            strategy['medium_priority'].extend([
                f"ä¸è¶³åœ°åŸŸã®åé›†: {', '.join(gaps['missing_regions'])}",
                "åœ°åŸŸåˆ¥ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é…ç½®ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åé›†"
            ])
        
        if gaps['underrepresented_problems']:
            strategy['medium_priority'].extend([
                "å°‘æ•°å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã®é›†ä¸­åé›†",
                "å¢ƒç•Œä¾‹ãƒ»é›£ã—ã„ã‚±ãƒ¼ã‚¹ã®ç‰¹å®š"
            ])
        
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥
        current_success_rate = self.analysis_results['basic_stats']['success_rate']
        target_samples = max(100, len(self.evaluation_data) * 2)  # ç¾åœ¨ã®2å€ã¾ãŸã¯100ä»¶
        
        strategy['sampling_strategy'] = {
            'target_total_samples': target_samples,
            'success_case_ratio': 0.4,  # 40%ã¯æˆåŠŸä¾‹
            'failure_case_ratio': 0.6,  # 60%ã¯æ”¹å–„å¯¾è±¡
            'regional_balance': True,
            'problem_type_balance': True
        }
        
        # ç›®æ¨™ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        strategy['target_metrics'] = {
            'success_rate_improvement': min(0.8, current_success_rate + 0.15),  # +15%æ”¹å–„
            'A_rating_ratio': 0.25,  # Aè©•ä¾¡25%
            'regional_coverage': 1.0,  # å…¨åœ°åŸŸã‚«ãƒãƒ¼
            'problem_type_coverage': 0.9  # å•é¡Œã‚¿ã‚¤ãƒ—90%ã‚«ãƒãƒ¼
        }
        
        return strategy
    
    def create_collection_plan(self, dataset_name: str = None) -> Dict[str, Any]:
        """å…·ä½“çš„ãªåé›†è¨ˆç”»ã®ä½œæˆ"""
        strategy = self.generate_collection_strategy()
        
        plan = {
            'dataset_name': dataset_name or f"learning_data_{datetime.now().strftime('%Y%m%d')}",
            'collection_phases': [],
            'execution_steps': [],
            'success_criteria': {},
            'timeline': {}
        }
        
        # Phase 1: æˆåŠŸäº‹ä¾‹åé›†
        plan['collection_phases'].append({
            'phase': 1,
            'name': "æˆåŠŸäº‹ä¾‹åé›†å¼·åŒ–",
            'target_samples': strategy['sampling_strategy']['target_total_samples'] // 3,
            'focus': "Aãƒ»Bè©•ä¾¡ç²å¾—å¯èƒ½ãªç”»åƒã®ç‰¹å®šã¨åé›†",
            'methods': [
                "æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®é¡ä¼¼ç”»åƒæ¤œç´¢",
                "é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã®é¸åˆ¥åé›†",
                "è¤‡æ•°å“è³ªæ‰‹æ³•ã§ã®äº‹å‰ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"
            ]
        })
        
        # Phase 2: åœ°åŸŸãƒãƒ©ãƒ³ã‚¹æ”¹å–„
        plan['collection_phases'].append({
            'phase': 2,
            'name': "åœ°åŸŸãƒãƒ©ãƒ³ã‚¹æ”¹å–„",
            'target_samples': strategy['sampling_strategy']['target_total_samples'] // 3,
            'focus': "ä¸è¶³åœ°åŸŸã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é…ç½®ãƒ‘ã‚¿ãƒ¼ãƒ³åé›†",
            'methods': [
                "åœ°åŸŸåˆ¥ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é…ç½®ã®æ„å›³çš„åé›†",
                "è¤‡æ•°ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚·ãƒ¼ãƒ³ã§ã®ä¸»äººå…¬ç‰¹å®š",
                "èƒŒæ™¯ãƒ»å‰æ™¯é–¢ä¿‚ã®å¤šæ§˜åŒ–"
            ]
        })
        
        # Phase 3: å›°é›£äº‹ä¾‹åé›†
        plan['collection_phases'].append({
            'phase': 3,
            'name': "å›°é›£äº‹ä¾‹ãƒ»å¢ƒç•Œä¾‹åé›†",
            'target_samples': strategy['sampling_strategy']['target_total_samples'] // 3,
            'focus': "æ”¹å–„å¯¾è±¡ã¨ãªã‚‹é›£ã—ã„ã‚±ãƒ¼ã‚¹ã®åé›†",
            'methods': [
                "è¤‡é›‘ãªå§¿å‹¢ãƒ»æ§‹å›³ã®åé›†",
                "éƒ¨åˆ†éš è”½ãƒ»é‡è¤‡ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®åé›†",
                "ã‚¨ãƒ•ã‚§ã‚¯ãƒˆãƒ»èƒŒæ™¯ãŒè¤‡é›‘ãªç”»åƒã®åé›†"
            ]
        })
        
        # å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—
        plan['execution_steps'] = [
            "1. å€™è£œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç‰¹å®šï¼ˆkaname08, kaname09ç­‰ï¼‰",
            "2. äº‹å‰å“è³ªè©•ä¾¡ã«ã‚ˆã‚‹å„ªå…ˆåº¦ä»˜ã‘",
            "3. Phaseåˆ¥ãƒ‡ãƒ¼ã‚¿åé›†ã®å®Ÿè¡Œ",
            "4. åé›†ãƒ‡ãƒ¼ã‚¿ã®å“è³ªæ¤œè¨¼",
            "5. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®çµ±åˆ",
            "6. åŠ¹æœæ¸¬å®šã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"
        ]
        
        # æˆåŠŸåŸºæº–
        plan['success_criteria'] = {
            'minimum_sample_count': strategy['sampling_strategy']['target_total_samples'],
            'target_success_rate': strategy['target_metrics']['success_rate_improvement'],
            'regional_coverage_ratio': strategy['target_metrics']['regional_coverage'],
            'quality_distribution_balance': "A:B:C = 25:25:25, D:E:F = 8:8:9"
        }
        
        return plan
    
    def save_analysis_report(self, output_path: str = None) -> str:
        """åˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ä¿å­˜"""
        if not output_path:
            output_path = f"learning_data_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'analysis_results': self.analysis_results,
            'data_gaps': self.identify_data_gaps(),
            'collection_strategy': self.generate_collection_strategy(),
            'collection_plan': self.create_collection_plan()
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… åˆ†æãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {output_path}")
        return output_path
    
    def print_summary(self):
        """ã‚µãƒãƒªãƒ¼ã®å‡ºåŠ›"""
        if not self.analysis_results:
            self.analyze_existing_data()
        
        stats = self.analysis_results['basic_stats']
        gaps = self.identify_data_gaps()
        strategy = self.generate_collection_strategy()
        
        print("\n" + "="*60)
        print("ğŸ“Š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åé›†è¨ˆç”» - åˆ†æã‚µãƒãƒªãƒ¼")
        print("="*60)
        
        print(f"\nğŸ“ˆ ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ³:")
        print(f"  ç·ä»¶æ•°: {stats['total_count']}ä»¶")
        print(f"  æˆåŠŸç‡: {stats['success_rate']:.1%} ({stats['success_count']}/{stats['total_count']})")
        print(f"  å¤±æ•—ä»¶æ•°: {stats['failure_count']}ä»¶")
        
        print(f"\nğŸ¯ ç‰¹å®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚®ãƒ£ãƒƒãƒ—:")
        if gaps['success_case_shortage']:
            print(f"  æˆåŠŸäº‹ä¾‹ä¸è¶³: {', '.join(gaps['success_case_shortage'])}")
        if gaps['missing_regions']:
            print(f"  ä¸è¶³åœ°åŸŸ: {', '.join(gaps['missing_regions'])}")
        if gaps['underrepresented_problems']:
            print(f"  å°‘æ•°å•é¡Œ: {', '.join(gaps['underrepresented_problems'])}")
        
        print(f"\nğŸš€ æ¨å¥¨åé›†æˆ¦ç•¥:")
        target = strategy['sampling_strategy']['target_total_samples']
        current = stats['total_count']
        additional = target - current
        
        print(f"  è¿½åŠ åé›†ç›®æ¨™: {additional}ä»¶ (ç¾åœ¨{current}ä»¶ â†’ ç›®æ¨™{target}ä»¶)")
        print(f"  æˆåŠŸç‡æ”¹å–„ç›®æ¨™: {stats['success_rate']:.1%} â†’ {strategy['target_metrics']['success_rate_improvement']:.1%}")
        print(f"  Aè©•ä¾¡ç›®æ¨™æ¯”ç‡: {strategy['target_metrics']['A_rating_ratio']:.1%}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åé›†è¨ˆç”»ç­–å®šã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
    
    # åˆæœŸåŒ–
    planner = LearningDataCollectionPlanner()
    
    if not planner.evaluation_data:
        print("âŒ è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    # åˆ†æå®Ÿè¡Œ
    print("\nğŸ“Š æ—¢å­˜ãƒ‡ãƒ¼ã‚¿åˆ†æä¸­...")
    planner.analyze_existing_data()
    
    # ã‚µãƒãƒªãƒ¼å‡ºåŠ›
    planner.print_summary()
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    print("\nğŸ’¾ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ä¸­...")
    report_path = planner.save_analysis_report()
    
    print(f"\nâœ… [P1-009] å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åé›†è¨ˆç”»ç­–å®šå®Œäº†")
    print(f"ğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")


if __name__ == "__main__":
    main()