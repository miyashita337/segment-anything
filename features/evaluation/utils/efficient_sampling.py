#!/usr/bin/env python3
"""
P1-010: åŠ¹ç‡çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åé›†ã®åŠ¹ç‡æ€§ã‚’æœ€å¤§åŒ–ã™ã‚‹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥ã‚·ã‚¹ãƒ†ãƒ 

Features:
- Multi-criteria sampling strategies
- Uncertainty-based sampling
- Diversity-maximizing sampling
- Stratified sampling by quality metrics
- Active learning integration
- Cost-effectiveness optimization
"""

import numpy as np
import json
from typing import Dict, List, Tuple, Optional, Any, Union
from pathlib import Path
from datetime import datetime
import random

# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…ç”¨
HAS_SCIPY = True
HAS_SKLEARN = True

try:
    from scipy.spatial.distance import pdist, squareform
    from scipy.stats import entropy
except ImportError:
    HAS_SCIPY = False

try:
    from sklearn.cluster import KMeans
    from sklearn.metrics.pairwise import pairwise_distances
    from sklearn.preprocessing import StandardScaler
except ImportError:
    HAS_SKLEARN = False


class EfficientSampling:
    """åŠ¹ç‡çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.name = "EfficientSampling"
        self.version = "1.0.0"
        
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.sampling_params = {
            'uncertainty_weight': 0.3,      # ä¸ç¢ºå®Ÿæ€§é‡ã¿
            'diversity_weight': 0.3,        # å¤šæ§˜æ€§é‡ã¿
            'quality_weight': 0.2,          # å“è³ªé‡ã¿
            'cost_weight': 0.2,             # ã‚³ã‚¹ãƒˆé‡ã¿
            'min_samples_per_stratum': 2,   # å±¤åˆ¥æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°
            'max_samples_per_stratum': 10,  # å±¤åˆ¥æœ€å¤§ã‚µãƒ³ãƒ—ãƒ«æ•°
            'similarity_threshold': 0.8,    # é¡ä¼¼åº¦é–¾å€¤
            'exploration_ratio': 0.3        # æ¢ç´¢ç‡
        }
        
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥
        self.strategies = {
            'uncertainty_based': self._uncertainty_based_sampling,
            'diversity_maximizing': self._diversity_maximizing_sampling,
            'stratified_quality': self._stratified_quality_sampling,
            'active_learning': self._active_learning_sampling,
            'cost_effective': self._cost_effective_sampling,
            'hybrid': self._hybrid_sampling
        }
    
    def generate_sampling_strategy(self, candidate_data: List[Dict], 
                                 target_samples: int,
                                 strategy: str = 'hybrid',
                                 constraints: Optional[Dict] = None) -> Dict[str, Any]:
        """
        åŠ¹ç‡çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥ç”Ÿæˆ
        
        Args:
            candidate_data: å€™è£œãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
            target_samples: ç›®æ¨™ã‚µãƒ³ãƒ—ãƒ«æ•°
            strategy: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥
            constraints: åˆ¶ç´„æ¡ä»¶
            
        Returns:
            Dict: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥çµæœ
        """
        if not candidate_data:
            return self._generate_error_result("No candidate data provided")
        
        if target_samples <= 0:
            return self._generate_error_result("Invalid target sample count")
        
        try:
            # å€™è£œãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
            processed_candidates = self._preprocess_candidates(candidate_data)
            
            # åˆ¶ç´„æ¡ä»¶é©ç”¨
            if constraints:
                processed_candidates = self._apply_constraints(processed_candidates, constraints)
            
            # ç‰¹å¾´é‡æŠ½å‡º
            features = self._extract_features(processed_candidates)
            
            # æŒ‡å®šæˆ¦ç•¥ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Ÿè¡Œ
            if strategy in self.strategies:
                sampling_result = self.strategies[strategy](
                    processed_candidates, features, target_samples
                )
            else:
                return self._generate_error_result(f"Unknown strategy: {strategy}")
            
            # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°åŠ¹æœåˆ†æ
            effectiveness_analysis = self._analyze_sampling_effectiveness(
                sampling_result, processed_candidates, features
            )
            
            # æ¨å¥¨ã‚µãƒ³ãƒ—ãƒ«æœ€é©åŒ–
            optimization_suggestions = self._generate_optimization_suggestions(
                sampling_result, effectiveness_analysis
            )
            
            return {
                'sampling_strategy': strategy,
                'target_samples': target_samples,
                'actual_samples': len(sampling_result['selected_samples']),
                'candidate_pool_size': len(processed_candidates),
                'selected_samples': sampling_result['selected_samples'],
                'sampling_rationale': sampling_result.get('rationale', {}),
                'effectiveness_analysis': effectiveness_analysis,
                'optimization_suggestions': optimization_suggestions,
                'processing_info': {
                    'timestamp': datetime.now().isoformat(),
                    'version': self.version
                }
            }
            
        except Exception as e:
            return self._generate_error_result(f"Sampling strategy generation failed: {str(e)}")
    
    def _preprocess_candidates(self, candidate_data: List[Dict]) -> List[Dict]:
        """å€™è£œãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†"""
        processed = []
        
        for i, candidate in enumerate(candidate_data):
            processed_candidate = {
                'id': candidate.get('id', f'candidate_{i}'),
                'image_path': candidate.get('image_path', ''),
                'quality_score': candidate.get('quality_score', 0.0),
                'confidence_score': candidate.get('confidence_score', 0.0),
                'processing_time': candidate.get('processing_time', 1.0),
                'complexity_score': candidate.get('complexity_score', 0.5),
                'previous_evaluation': candidate.get('previous_evaluation'),
                'characteristics': candidate.get('characteristics', {}),
                'metadata': candidate.get('metadata', {})
            }
            
            # ä¸ç¢ºå®Ÿæ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
            processed_candidate['uncertainty_score'] = self._calculate_uncertainty(processed_candidate)
            
            # ã‚³ã‚¹ãƒˆã‚¹ã‚³ã‚¢è¨ˆç®—
            processed_candidate['cost_score'] = self._calculate_cost_score(processed_candidate)
            
            processed.append(processed_candidate)
        
        return processed
    
    def _calculate_uncertainty(self, candidate: Dict) -> float:
        """ä¸ç¢ºå®Ÿæ€§ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        quality_score = candidate['quality_score']
        confidence_score = candidate['confidence_score']
        
        # å“è³ªã‚¹ã‚³ã‚¢ã®æ›–æ˜§æ€§ï¼ˆ0.5ä»˜è¿‘ãŒæœ€ã‚‚ä¸ç¢ºå®Ÿï¼‰
        quality_uncertainty = 1.0 - 2 * abs(quality_score - 0.5)
        
        # ä¿¡é ¼åº¦ã®ä½ã•
        confidence_uncertainty = 1.0 - confidence_score
        
        # çµ±åˆä¸ç¢ºå®Ÿæ€§
        uncertainty = (quality_uncertainty + confidence_uncertainty) / 2
        
        return min(max(uncertainty, 0.0), 1.0)
    
    def _calculate_cost_score(self, candidate: Dict) -> float:
        """ã‚³ã‚¹ãƒˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆä½ã„æ–¹ãŒè‰¯ã„ï¼‰"""
        processing_time = candidate['processing_time']
        complexity = candidate['complexity_score']
        
        # å‡¦ç†æ™‚é–“æ­£è¦åŒ–ï¼ˆä»®å®šï¼šæœ€å¤§10ç§’ï¼‰
        time_cost = min(processing_time / 10.0, 1.0)
        
        # è¤‡é›‘æ€§ã‚³ã‚¹ãƒˆ
        complexity_cost = complexity
        
        # çµ±åˆã‚³ã‚¹ãƒˆ
        cost = (time_cost + complexity_cost) / 2
        
        return min(max(cost, 0.0), 1.0)
    
    def _apply_constraints(self, candidates: List[Dict], constraints: Dict) -> List[Dict]:
        """åˆ¶ç´„æ¡ä»¶é©ç”¨"""
        filtered = candidates.copy()
        
        # å“è³ªã‚¹ã‚³ã‚¢åˆ¶ç´„
        if 'min_quality' in constraints:
            min_quality = constraints['min_quality']
            filtered = [c for c in filtered if c['quality_score'] >= min_quality]
        
        if 'max_quality' in constraints:
            max_quality = constraints['max_quality']
            filtered = [c for c in filtered if c['quality_score'] <= max_quality]
        
        # å‡¦ç†æ™‚é–“åˆ¶ç´„
        if 'max_processing_time' in constraints:
            max_time = constraints['max_processing_time']
            filtered = [c for c in filtered if c['processing_time'] <= max_time]
        
        # ç‰¹æ€§åˆ¶ç´„
        if 'required_characteristics' in constraints:
            required = constraints['required_characteristics']
            filtered = [c for c in filtered 
                       if all(c['characteristics'].get(key) == value 
                             for key, value in required.items())]
        
        return filtered
    
    def _extract_features(self, candidates: List[Dict]) -> np.ndarray:
        """ç‰¹å¾´é‡æŠ½å‡º"""
        features = []
        
        for candidate in candidates:
            feature_vector = [
                candidate['quality_score'],
                candidate['confidence_score'],
                candidate['uncertainty_score'],
                candidate['cost_score'],
                candidate['complexity_score'],
                candidate['processing_time'] / 10.0  # æ­£è¦åŒ–
            ]
            features.append(feature_vector)
        
        return np.array(features)
    
    def _uncertainty_based_sampling(self, candidates: List[Dict], 
                                   features: np.ndarray, 
                                   target_samples: int) -> Dict[str, Any]:
        """ä¸ç¢ºå®Ÿæ€§ãƒ™ãƒ¼ã‚¹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        # ä¸ç¢ºå®Ÿæ€§ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        sorted_indices = sorted(range(len(candidates)), 
                              key=lambda i: candidates[i]['uncertainty_score'], 
                              reverse=True)
        
        # ä¸Šä½ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒ«é¸æŠ
        selected_indices = sorted_indices[:target_samples]
        selected_samples = [candidates[i] for i in selected_indices]
        
        return {
            'selected_samples': selected_samples,
            'rationale': {
                'strategy': 'uncertainty_based',
                'avg_uncertainty': np.mean([candidates[i]['uncertainty_score'] for i in selected_indices]),
                'selection_criterion': 'highest_uncertainty'
            }
        }
    
    def _diversity_maximizing_sampling(self, candidates: List[Dict],
                                     features: np.ndarray,
                                     target_samples: int) -> Dict[str, Any]:
        """å¤šæ§˜æ€§æœ€å¤§åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        try:
            if HAS_SKLEARN and len(features) > target_samples:
                # K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                n_clusters = min(target_samples, len(features))
                kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                cluster_labels = kmeans.fit_predict(features)
                
                # å„ã‚¯ãƒ©ã‚¹ã‚¿ã‹ã‚‰ä»£è¡¨ã‚µãƒ³ãƒ—ãƒ«é¸æŠ
                selected_indices = []
                for cluster_id in range(n_clusters):
                    cluster_indices = np.where(cluster_labels == cluster_id)[0]
                    if len(cluster_indices) > 0:
                        # ã‚¯ãƒ©ã‚¹ã‚¿ä¸­å¿ƒã«æœ€ã‚‚è¿‘ã„ã‚µãƒ³ãƒ—ãƒ«é¸æŠ
                        cluster_center = kmeans.cluster_centers_[cluster_id]
                        distances = [np.linalg.norm(features[i] - cluster_center) 
                                   for i in cluster_indices]
                        best_idx = cluster_indices[np.argmin(distances)]
                        selected_indices.append(best_idx)
                
                # ç›®æ¨™æ•°ã«æº€ãŸãªã„å ´åˆã¯è¿½åŠ é¸æŠ
                while len(selected_indices) < target_samples and len(selected_indices) < len(candidates):
                    remaining_indices = [i for i in range(len(candidates)) if i not in selected_indices]
                    if not remaining_indices:
                        break
                    
                    # æœ€ã‚‚é›¢ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ã‚’è¿½åŠ 
                    if selected_indices:
                        selected_features = features[selected_indices]
                        distances = []
                        for idx in remaining_indices:
                            min_dist = min(np.linalg.norm(features[idx] - selected_features[j]) 
                                         for j in range(len(selected_features)))
                            distances.append(min_dist)
                        best_remaining = remaining_indices[np.argmax(distances)]
                        selected_indices.append(best_remaining)
                    else:
                        selected_indices.append(remaining_indices[0])
                
                rationale = {
                    'strategy': 'diversity_maximizing',
                    'method': 'kmeans_clustering',
                    'n_clusters': n_clusters
                }
                
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç°¡æ˜“å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                selected_indices = self._simple_diversity_sampling(features, target_samples)
                rationale = {
                    'strategy': 'diversity_maximizing',
                    'method': 'simple_diversity',
                    'fallback': True
                }
            
            selected_samples = [candidates[i] for i in selected_indices]
            
            return {
                'selected_samples': selected_samples,
                'rationale': rationale
            }
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            selected_indices = random.sample(range(len(candidates)), 
                                           min(target_samples, len(candidates)))
            selected_samples = [candidates[i] for i in selected_indices]
            
            return {
                'selected_samples': selected_samples,
                'rationale': {
                    'strategy': 'diversity_maximizing',
                    'method': 'random_fallback',
                    'error': str(e)
                }
            }
    
    def _simple_diversity_sampling(self, features: np.ndarray, target_samples: int) -> List[int]:
        """ç°¡æ˜“å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        if len(features) <= target_samples:
            return list(range(len(features)))
        
        selected_indices = []
        
        # æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ã¯ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
        first_idx = random.randint(0, len(features) - 1)
        selected_indices.append(first_idx)
        
        # æ®‹ã‚Šã¯æœ€ã‚‚é›¢ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ã‚’é †æ¬¡é¸æŠ
        for _ in range(target_samples - 1):
            remaining_indices = [i for i in range(len(features)) if i not in selected_indices]
            if not remaining_indices:
                break
            
            max_min_distance = -1
            best_idx = remaining_indices[0]
            
            for candidate_idx in remaining_indices:
                min_distance = min(np.linalg.norm(features[candidate_idx] - features[selected_idx])
                                 for selected_idx in selected_indices)
                if min_distance > max_min_distance:
                    max_min_distance = min_distance
                    best_idx = candidate_idx
            
            selected_indices.append(best_idx)
        
        return selected_indices
    
    def _stratified_quality_sampling(self, candidates: List[Dict],
                                   features: np.ndarray,
                                   target_samples: int) -> Dict[str, Any]:
        """å“è³ªå±¤åˆ¥ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        # å“è³ªã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹å±¤åˆ†ã‘
        quality_scores = [c['quality_score'] for c in candidates]
        
        # å“è³ªãƒ¬ãƒ³ã‚¸ã”ã¨ã®å±¤å®šç¾©
        strata = {
            'high_quality': [i for i, score in enumerate(quality_scores) if score >= 0.7],
            'medium_quality': [i for i, score in enumerate(quality_scores) if 0.3 <= score < 0.7],
            'low_quality': [i for i, score in enumerate(quality_scores) if score < 0.3]
        }
        
        # å„å±¤ã‹ã‚‰ã®ã‚µãƒ³ãƒ—ãƒ«æ•°æ±ºå®š
        total_candidates = sum(len(stratum) for stratum in strata.values())
        selected_indices = []
        
        for stratum_name, stratum_indices in strata.items():
            if not stratum_indices:
                continue
                
            # å±¤ã‚µã‚¤ã‚ºã«æ¯”ä¾‹ã—ãŸé…åˆ†
            stratum_ratio = len(stratum_indices) / total_candidates
            stratum_samples = max(
                self.sampling_params['min_samples_per_stratum'],
                min(
                    int(target_samples * stratum_ratio),
                    self.sampling_params['max_samples_per_stratum'],
                    len(stratum_indices)
                )
            )
            
            # å±¤å†…ã§ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            if stratum_samples < len(stratum_indices):
                sampled = random.sample(stratum_indices, stratum_samples)
            else:
                sampled = stratum_indices
            
            selected_indices.extend(sampled)
        
        # ç›®æ¨™æ•°èª¿æ•´
        if len(selected_indices) > target_samples:
            selected_indices = random.sample(selected_indices, target_samples)
        elif len(selected_indices) < target_samples:
            # ä¸è¶³åˆ†ã‚’ãƒ©ãƒ³ãƒ€ãƒ è£œå®Œ
            remaining = [i for i in range(len(candidates)) if i not in selected_indices]
            additional_needed = target_samples - len(selected_indices)
            if remaining and additional_needed > 0:
                additional = random.sample(remaining, min(additional_needed, len(remaining)))
                selected_indices.extend(additional)
        
        selected_samples = [candidates[i] for i in selected_indices]
        
        # å±¤åˆ¥çµ±è¨ˆ
        stratum_stats = {}
        for stratum_name, stratum_indices in strata.items():
            selected_in_stratum = [i for i in selected_indices if i in stratum_indices]
            stratum_stats[stratum_name] = {
                'total_candidates': len(stratum_indices),
                'selected_samples': len(selected_in_stratum),
                'selection_ratio': len(selected_in_stratum) / len(stratum_indices) if stratum_indices else 0
            }
        
        return {
            'selected_samples': selected_samples,
            'rationale': {
                'strategy': 'stratified_quality',
                'strata_definition': {name: len(indices) for name, indices in strata.items()},
                'stratum_statistics': stratum_stats
            }
        }
    
    def _active_learning_sampling(self, candidates: List[Dict],
                                features: np.ndarray,
                                target_samples: int) -> Dict[str, Any]:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        # ä¸ç¢ºå®Ÿæ€§ã¨å¤šæ§˜æ€§ã®çµ„ã¿åˆã‚ã›
        uncertainty_scores = [c['uncertainty_score'] for c in candidates]
        
        # å„å€™è£œã®ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        composite_scores = []
        for i, candidate in enumerate(candidates):
            uncertainty = uncertainty_scores[i]
            
            # å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆä»–ã‚µãƒ³ãƒ—ãƒ«ã¨ã®å¹³å‡è·é›¢ï¼‰
            if len(features) > 1:
                distances = [np.linalg.norm(features[i] - features[j]) 
                           for j in range(len(features)) if i != j]
                diversity = np.mean(distances) if distances else 0
                # æ­£è¦åŒ–
                diversity = min(diversity / np.max(pdist(features)) if len(features) > 1 else 0, 1.0)
            else:
                diversity = 0.5
            
            # çµ±åˆã‚¹ã‚³ã‚¢
            composite_score = (self.sampling_params['uncertainty_weight'] * uncertainty +
                             self.sampling_params['diversity_weight'] * diversity)
            composite_scores.append(composite_score)
        
        # ä¸Šä½ã‚¹ã‚³ã‚¢ã§ã‚µãƒ³ãƒ—ãƒ«é¸æŠ
        sorted_indices = sorted(range(len(candidates)), 
                              key=lambda i: composite_scores[i], 
                              reverse=True)
        
        selected_indices = sorted_indices[:target_samples]
        selected_samples = [candidates[i] for i in selected_indices]
        
        return {
            'selected_samples': selected_samples,
            'rationale': {
                'strategy': 'active_learning',
                'uncertainty_weight': self.sampling_params['uncertainty_weight'],
                'diversity_weight': self.sampling_params['diversity_weight'],
                'avg_composite_score': np.mean([composite_scores[i] for i in selected_indices])
            }
        }
    
    def _cost_effective_sampling(self, candidates: List[Dict],
                                features: np.ndarray,
                                target_samples: int) -> Dict[str, Any]:
        """ã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        # ã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆä¾¡å€¤/ã‚³ã‚¹ãƒˆæ¯”ï¼‰
        efficiency_scores = []
        
        for candidate in candidates:
            # ä¾¡å€¤ã‚¹ã‚³ã‚¢ï¼ˆä¸ç¢ºå®Ÿæ€§ + å“è³ªã®ãƒãƒ©ãƒ³ã‚¹ï¼‰
            value = (candidate['uncertainty_score'] * 0.6 + 
                    (1.0 - abs(candidate['quality_score'] - 0.5) * 2) * 0.4)
            
            # ã‚³ã‚¹ãƒˆã‚¹ã‚³ã‚¢
            cost = candidate['cost_score']
            
            # åŠ¹ç‡ã‚¹ã‚³ã‚¢ï¼ˆã‚³ã‚¹ãƒˆãŒã‚¼ãƒ­ã®å ´åˆã¯ä¾¡å€¤ã®ã¿ï¼‰
            efficiency = value / (cost + 0.01)  # ã‚¼ãƒ­é™¤ç®—å›é¿
            efficiency_scores.append(efficiency)
        
        # åŠ¹ç‡ã®é«˜ã„é †ã«é¸æŠ
        sorted_indices = sorted(range(len(candidates)), 
                              key=lambda i: efficiency_scores[i], 
                              reverse=True)
        
        selected_indices = sorted_indices[:target_samples]
        selected_samples = [candidates[i] for i in selected_indices]
        
        return {
            'selected_samples': selected_samples,
            'rationale': {
                'strategy': 'cost_effective',
                'avg_efficiency_score': np.mean([efficiency_scores[i] for i in selected_indices]),
                'total_estimated_cost': sum(candidates[i]['cost_score'] for i in selected_indices)
            }
        }
    
    def _hybrid_sampling(self, candidates: List[Dict],
                        features: np.ndarray,
                        target_samples: int) -> Dict[str, Any]:
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆè¤‡æ•°æˆ¦ç•¥ã®çµ„ã¿åˆã‚ã›ï¼‰"""
        # å„æˆ¦ç•¥ã§å°è¦æ¨¡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Ÿè¡Œ
        strategies_samples = {
            'uncertainty': max(1, target_samples // 4),
            'diversity': max(1, target_samples // 4),
            'stratified': max(1, target_samples // 4),
            'cost_effective': max(1, target_samples // 4)
        }
        
        # æ®‹ã‚Šã‚µãƒ³ãƒ—ãƒ«æ•°
        remaining_samples = target_samples - sum(strategies_samples.values())
        if remaining_samples > 0:
            strategies_samples['uncertainty'] += remaining_samples
        
        all_selected_indices = set()
        strategy_results = {}
        
        # å„æˆ¦ç•¥å®Ÿè¡Œ
        for strategy_name, sample_count in strategies_samples.items():
            if strategy_name == 'uncertainty':
                result = self._uncertainty_based_sampling(candidates, features, sample_count)
            elif strategy_name == 'diversity':
                result = self._diversity_maximizing_sampling(candidates, features, sample_count)
            elif strategy_name == 'stratified':
                result = self._stratified_quality_sampling(candidates, features, sample_count)
            elif strategy_name == 'cost_effective':
                result = self._cost_effective_sampling(candidates, features, sample_count)
            
            strategy_results[strategy_name] = result
            
            # é¸æŠã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ 
            for sample in result['selected_samples']:
                sample_id = sample['id']
                for i, candidate in enumerate(candidates):
                    if candidate['id'] == sample_id:
                        all_selected_indices.add(i)
                        break
        
        # é‡è¤‡é™¤å»ã¨ç›®æ¨™æ•°èª¿æ•´
        selected_indices = list(all_selected_indices)
        
        if len(selected_indices) > target_samples:
            # è¶…éåˆ†ã‚’ãƒ©ãƒ³ãƒ€ãƒ é™¤å»
            selected_indices = random.sample(selected_indices, target_samples)
        elif len(selected_indices) < target_samples:
            # ä¸è¶³åˆ†ã‚’ãƒ©ãƒ³ãƒ€ãƒ è¿½åŠ 
            remaining_indices = [i for i in range(len(candidates)) if i not in selected_indices]
            additional_needed = target_samples - len(selected_indices)
            if remaining_indices and additional_needed > 0:
                additional = random.sample(remaining_indices, min(additional_needed, len(remaining_indices)))
                selected_indices.extend(additional)
        
        selected_samples = [candidates[i] for i in selected_indices]
        
        return {
            'selected_samples': selected_samples,
            'rationale': {
                'strategy': 'hybrid',
                'component_strategies': list(strategies_samples.keys()),
                'strategy_allocations': strategies_samples,
                'total_unique_selections': len(all_selected_indices)
            }
        }
    
    def _analyze_sampling_effectiveness(self, sampling_result: Dict,
                                      all_candidates: List[Dict],
                                      features: np.ndarray) -> Dict[str, Any]:
        """ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°åŠ¹æœåˆ†æ"""
        try:
            selected_samples = sampling_result['selected_samples']
            
            if not selected_samples:
                return {'error': 'No samples selected for analysis'}
            
            # é¸æŠã‚µãƒ³ãƒ—ãƒ«ã®ç‰¹æ€§çµ±è¨ˆ
            selected_qualities = [s['quality_score'] for s in selected_samples]
            selected_uncertainties = [s['uncertainty_score'] for s in selected_samples]
            selected_costs = [s['cost_score'] for s in selected_samples]
            
            # å…¨ä½“ã¨ã®æ¯”è¼ƒ
            all_qualities = [c['quality_score'] for c in all_candidates]
            all_uncertainties = [c['uncertainty_score'] for c in all_candidates]
            all_costs = [c['cost_score'] for c in all_candidates]
            
            effectiveness_metrics = {
                'coverage_analysis': {
                    'quality_coverage': {
                        'selected_mean': np.mean(selected_qualities),
                        'selected_std': np.std(selected_qualities),
                        'population_mean': np.mean(all_qualities),
                        'population_std': np.std(all_qualities),
                        'coverage_ratio': np.std(selected_qualities) / np.std(all_qualities) if np.std(all_qualities) > 0 else 0
                    },
                    'uncertainty_coverage': {
                        'selected_mean': np.mean(selected_uncertainties),
                        'population_mean': np.mean(all_uncertainties),
                        'high_uncertainty_ratio': sum(1 for u in selected_uncertainties if u > 0.7) / len(selected_uncertainties)
                    }
                },
                'efficiency_analysis': {
                    'avg_cost': np.mean(selected_costs),
                    'total_cost': np.sum(selected_costs),
                    'cost_effectiveness': np.mean(selected_uncertainties) / (np.mean(selected_costs) + 0.01)
                },
                'diversity_analysis': self._calculate_diversity_metrics(selected_samples, features)
            }
            
            return effectiveness_metrics
            
        except Exception as e:
            return {'error': f'Effectiveness analysis failed: {str(e)}'}
    
    def _calculate_diversity_metrics(self, selected_samples: List[Dict], 
                                   all_features: np.ndarray) -> Dict[str, Any]:
        """å¤šæ§˜æ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        try:
            if len(selected_samples) <= 1:
                return {'diversity_score': 0.0, 'note': 'insufficient_samples'}
            
            # é¸æŠã‚µãƒ³ãƒ—ãƒ«ã®ç‰¹å¾´é‡æŠ½å‡º
            selected_features = []
            for sample in selected_samples:
                for i, candidate_id in enumerate([f"candidate_{j}" for j in range(len(all_features))]):
                    if sample['id'] == candidate_id or sample.get('image_path') == f"path_{i}":
                        if i < len(all_features):
                            selected_features.append(all_features[i])
                        break
            
            if len(selected_features) <= 1:
                return {'diversity_score': 0.0, 'note': 'feature_extraction_failed'}
            
            selected_features = np.array(selected_features)
            
            # å¹³å‡ãƒšã‚¢ãƒ¯ã‚¤ã‚ºè·é›¢
            if HAS_SCIPY:
                pairwise_distances = pdist(selected_features)
                avg_distance = np.mean(pairwise_distances) if len(pairwise_distances) > 0 else 0
                
                # å…¨ä½“ç‰¹å¾´é‡ç©ºé–“ã§ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
                all_pairwise = pdist(all_features)
                max_possible_distance = np.max(all_pairwise) if len(all_pairwise) > 0 else 1
                
                diversity_score = avg_distance / max_possible_distance if max_possible_distance > 0 else 0
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç°¡æ˜“å¤šæ§˜æ€§è¨ˆç®—
                distances = []
                for i in range(len(selected_features)):
                    for j in range(i + 1, len(selected_features)):
                        dist = np.linalg.norm(selected_features[i] - selected_features[j])
                        distances.append(dist)
                
                avg_distance = np.mean(distances) if distances else 0
                diversity_score = min(avg_distance / 2.0, 1.0)  # æ­£è¦åŒ–
            
            return {
                'diversity_score': float(diversity_score),
                'avg_pairwise_distance': float(avg_distance),
                'feature_dimensions': selected_features.shape[1] if len(selected_features) > 0 else 0
            }
            
        except Exception as e:
            return {'error': f'Diversity calculation failed: {str(e)}'}
    
    def _generate_optimization_suggestions(self, sampling_result: Dict,
                                         effectiveness_analysis: Dict) -> List[str]:
        """æœ€é©åŒ–ææ¡ˆç”Ÿæˆ"""
        suggestions = []
        
        # åŠ¹æœåˆ†æã«åŸºã¥ãææ¡ˆ
        if 'coverage_analysis' in effectiveness_analysis:
            coverage = effectiveness_analysis['coverage_analysis']
            
            # å“è³ªã‚«ãƒãƒ¬ãƒƒã‚¸
            quality_coverage = coverage.get('quality_coverage', {})
            if quality_coverage.get('coverage_ratio', 0) < 0.5:
                suggestions.append("increase_quality_diversity")
            
            # ä¸ç¢ºå®Ÿæ€§ã‚«ãƒãƒ¬ãƒƒã‚¸
            uncertainty_coverage = coverage.get('uncertainty_coverage', {})
            if uncertainty_coverage.get('high_uncertainty_ratio', 0) < 0.3:
                suggestions.append("focus_on_uncertain_samples")
        
        # åŠ¹ç‡æ€§åˆ†æ
        if 'efficiency_analysis' in effectiveness_analysis:
            efficiency = effectiveness_analysis['efficiency_analysis']
            if efficiency.get('cost_effectiveness', 0) < 0.5:
                suggestions.append("optimize_cost_effectiveness")
        
        # å¤šæ§˜æ€§åˆ†æ
        if 'diversity_analysis' in effectiveness_analysis:
            diversity = effectiveness_analysis['diversity_analysis']
            if diversity.get('diversity_score', 0) < 0.4:
                suggestions.append("increase_sample_diversity")
        
        # æˆ¦ç•¥å›ºæœ‰ã®ææ¡ˆ
        strategy = sampling_result.get('rationale', {}).get('strategy')
        if strategy == 'uncertainty_based':
            suggestions.append("consider_adding_diversity_component")
        elif strategy == 'diversity_maximizing':
            suggestions.append("consider_adding_uncertainty_component")
        
        return suggestions
    
    def _generate_error_result(self, error_message: str) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼çµæœç”Ÿæˆ"""
        return {
            'error': error_message,
            'sampling_strategy': 'failed',
            'selected_samples': []
        }


def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ P1-010: åŠ¹ç‡çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ãƒ†ã‚¹ãƒˆç”¨å€™è£œãƒ‡ãƒ¼ã‚¿ä½œæˆ
    test_candidates = []
    for i in range(20):
        candidate = {
            'id': f'test_image_{i:03d}',
            'image_path': f'/test/path/image_{i:03d}.jpg',
            'quality_score': random.uniform(0.1, 0.9),
            'confidence_score': random.uniform(0.3, 0.95),
            'processing_time': random.uniform(1.0, 8.0),
            'complexity_score': random.uniform(0.2, 0.8),
            'characteristics': {
                'scene_type': random.choice(['indoor', 'outdoor']),
                'character_count': random.randint(1, 3)
            }
        }
        test_candidates.append(candidate)
    
    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Ÿè¡Œ
    sampler = EfficientSampling()
    result = sampler.generate_sampling_strategy(
        test_candidates, 
        target_samples=8, 
        strategy='hybrid'
    )
    
    print("\nğŸ“Š åŠ¹ç‡çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°çµæœ:")
    if 'error' not in result:
        print(f"  æˆ¦ç•¥: {result['sampling_strategy']}")
        print(f"  ç›®æ¨™ã‚µãƒ³ãƒ—ãƒ«æ•°: {result['target_samples']}")
        print(f"  å®Ÿé¸æŠæ•°: {result['actual_samples']}")
        print(f"  å€™è£œãƒ—ãƒ¼ãƒ«: {result['candidate_pool_size']}ä»¶")
        
        # é¸æŠã‚µãƒ³ãƒ—ãƒ«ä¾‹
        selected = result['selected_samples'][:3]  # æœ€åˆã®3ã¤è¡¨ç¤º
        print(f"\nğŸ” é¸æŠã‚µãƒ³ãƒ—ãƒ«ä¾‹:")
        for sample in selected:
            print(f"    {sample['id']}: å“è³ª{sample['quality_score']:.2f}, ä¸ç¢ºå®Ÿæ€§{sample['uncertainty_score']:.2f}")
        
        # æœ€é©åŒ–ææ¡ˆ
        suggestions = result.get('optimization_suggestions', [])
        if suggestions:
            print(f"\nğŸ’¡ æœ€é©åŒ–ææ¡ˆ: {', '.join(suggestions)}")
    else:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
    
    print(f"\nâœ… [P1-010] åŠ¹ç‡çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å®Œäº†")


if __name__ == "__main__":
    main()