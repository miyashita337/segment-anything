#!/usr/bin/env python3
"""
å­¦ç¿’ã—ãŸå“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
137ãƒ¬ã‚³ãƒ¼ãƒ‰ã®äººé–“è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãé©å¿œçš„å“è³ªäºˆæ¸¬ãƒ»æ‰‹æ³•é¸æŠ

çµ±åˆã•ã‚Œã‚‹segment-anythingãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã®ä½¿ç”¨:
- ç”»åƒç‰¹æ€§ã®è‡ªå‹•åˆ†æ
- æœ€é©æ‰‹æ³•ã®é¸æŠ
- å“è³ªã‚¹ã‚³ã‚¢ã®äºˆæ¸¬
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’æ›´æ–°
"""

import json
import os
import logging
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
import numpy as np
from pathlib import Path

# åŸºæœ¬çš„ãªç”»åƒå‡¦ç†ï¼ˆSAMãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã§ã®åˆ©ç”¨ã‚’æƒ³å®šï¼‰
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    logging.warning("OpenCV not available. Image analysis will be limited.")


@dataclass
class QualityPrediction:
    """å“è³ªäºˆæ¸¬çµæœ"""
    predicted_quality: float
    confidence: float
    recommended_method: str
    fallback_method: str
    reasoning: str
    image_characteristics: Dict[str, Any]


@dataclass
class ImageCharacteristics:
    """ç”»åƒç‰¹æ€§ã®åˆ†æçµæœ"""
    has_complex_pose: bool
    has_full_body: bool
    has_multiple_characters: bool
    is_face_focus: bool
    aspect_ratio: float
    estimated_difficulty: float
    manga_style_score: float
    has_screentone_issues: bool = False
    has_mosaic_issues: bool = False
    has_boundary_complexity: bool = False


class LearnedQualityAssessment:
    """å­¦ç¿’ã—ãŸå“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, 
                 analysis_data_path: str = "/mnt/c/AItools/image_evaluation_system/analysis/quality_analysis_report.json",
                 recommendations_path: str = "/mnt/c/AItools/image_evaluation_system/analysis/method_recommendations.json"):
        self.analysis_data_path = analysis_data_path
        self.recommendations_path = recommendations_path
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
        self.method_stats = {}
        self.method_recommendations = {}
        self.quality_baseline = {}
        
        # è¨­å®š
        self.confidence_threshold = 0.7
        self.fallback_threshold = 0.5
        
        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        self._load_learned_data()
    
    def _load_learned_data(self):
        """å­¦ç¿’æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        try:
            # å“è³ªåˆ†æãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            if os.path.exists(self.analysis_data_path):
                with open(self.analysis_data_path, 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)
                
                self.method_stats = analysis_data['method_performance']['method_performance']
                self.problem_rates = analysis_data['method_performance']['method_problem_rates']
                
                self.logger.info(f"âœ… å“è³ªåˆ†æãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿: {len(self.method_stats)}æ‰‹æ³•")
            
            # æ¨å¥¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            if os.path.exists(self.recommendations_path):
                with open(self.recommendations_path, 'r', encoding='utf-8') as f:
                    self.method_recommendations = json.load(f)
                
                self.logger.info(f"âœ… æ¨å¥¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿: {len(self.method_recommendations['method_strengths'])}æ‰‹æ³•")
            
            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å“è³ªè¨­å®š
            self._setup_quality_baseline()
            
        except Exception as e:
            self.logger.error(f"âŒ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            self._setup_fallback_data()
    
    def _setup_quality_baseline(self):
        """å“è³ªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®è¨­å®š"""
        if self.method_stats:
            # å®Ÿéš›ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨­å®š
            self.quality_baseline = {
                'excellent': 4.0,
                'good': 3.0,
                'acceptable': 2.0,
                'poor': 1.0,
                'failed': 0.0
            }
            
            # æ‰‹æ³•åˆ¥æœŸå¾…å“è³ª
            self.method_expected_quality = {
                method: stats['mean'] 
                for method, stats in self.method_stats.items()
            }
        else:
            self._setup_fallback_data()
    
    def _setup_fallback_data(self):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®åŸºæœ¬ãƒ‡ãƒ¼ã‚¿è¨­å®šï¼ˆæœ€æ–°ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãï¼‰"""
        self.logger.warning("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆæœ€æ–°è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰")
        
        # 2025-07-16æ›´æ–°: 281ãƒ¬ã‚³ãƒ¼ãƒ‰ã®å®Ÿéš›ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã
        self.method_expected_quality = {
            'size_priority': 2.05,        # æœ€é«˜è©•ä¾¡æ‰‹æ³•
            'clean_version': 2.00,        # 2ç•ªç›®
            'balanced': 1.96,             # å®‰å®šã—ãŸæ¨™æº–æ‰‹æ³•
            'v043_improved': 1.96,        # æ”¹è‰¯ç‰ˆ
            'reference_standard': 1.71,   # åŸºæº–ç‰ˆ
            'confidence_priority': 1.28,  # å®Ÿéš›ã¯æœŸå¾…ã‚ˆã‚Šä½è©•ä¾¡
            'fullbody_priority': 2.0,     # æ¨å®šå€¤
            'central_priority': 1.8       # æ¨å®šå€¤
        }
        
        self.quality_baseline = {
            'excellent': 4.0,
            'good': 3.0,
            'acceptable': 2.0,
            'poor': 1.0,
            'failed': 0.0
        }
    
    def analyze_image_characteristics(self, image_path: str, 
                                    yolo_detections: Optional[List] = None,
                                    mask_candidates: Optional[List] = None) -> ImageCharacteristics:
        """ç”»åƒç‰¹æ€§ã®åˆ†æ"""
        if not CV2_AVAILABLE:
            # OpenCVãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return ImageCharacteristics(
                has_complex_pose=False,
                has_full_body=True,
                has_multiple_characters=False,
                is_face_focus=False,
                aspect_ratio=1.0,
                estimated_difficulty=0.5,
                manga_style_score=0.8,
                has_screentone_issues=False,
                has_mosaic_issues=False,
                has_boundary_complexity=False
            )
        
        try:
            # ç”»åƒèª­ã¿è¾¼ã¿
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {image_path}")
            
            height, width = image.shape[:2]
            aspect_ratio = width / height
            
            # YOLOæ¤œå‡ºçµæœã‹ã‚‰ã®ç‰¹æ€§åˆ†æ
            has_multiple_characters = False
            has_full_body = False
            has_complex_pose = False
            
            if yolo_detections:
                # è¤‡æ•°ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¤å®š
                high_confidence_detections = [d for d in yolo_detections if d.get('confidence', 0) > 0.7]
                has_multiple_characters = len(high_confidence_detections) > 1
                
                # å…¨èº«åˆ¤å®šï¼ˆæ¤œå‡ºãƒœãƒƒã‚¯ã‚¹ã®é«˜ã•ã‹ã‚‰æ¨å®šï¼‰
                for detection in high_confidence_detections:
                    bbox_height = detection.get('bbox', [0, 0, 0, 100])[3]
                    if bbox_height / height > 0.6:  # ç”»åƒã®60%ä»¥ä¸Šã®é«˜ã•
                        has_full_body = True
                        break
                
                # è¤‡é›‘å§¿å‹¢åˆ¤å®šï¼ˆã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã¨æ¤œå‡ºã‚¹ã‚³ã‚¢ã‹ã‚‰æ¨å®šï¼‰
                for detection in high_confidence_detections:
                    bbox = detection.get('bbox', [0, 0, 100, 100])
                    bbox_aspect = bbox[2] / bbox[3]  # width/height
                    confidence = detection.get('confidence', 0)
                    
                    # æ¨ªé•·ã®ãƒœãƒƒã‚¯ã‚¹ã‹ã¤ä¸­ç¨‹åº¦ã®ä¿¡é ¼åº¦ = è¤‡é›‘å§¿å‹¢ã®å¯èƒ½æ€§
                    if bbox_aspect > 1.5 and 0.3 < confidence < 0.8:
                        has_complex_pose = True
                        break
            
            # é¡”ãƒ•ã‚©ãƒ¼ã‚«ã‚¹åˆ¤å®šï¼ˆä¸ŠåŠåˆ†ã®é ˜åŸŸé‡è¦–ï¼‰
            is_face_focus = aspect_ratio > 0.7 and aspect_ratio < 1.3  # æ­£æ–¹å½¢ã«è¿‘ã„
            
            # å›°é›£åº¦æ¨å®š
            difficulty_factors = 0
            if has_complex_pose:
                difficulty_factors += 0.3
            if has_multiple_characters:
                difficulty_factors += 0.2
            if aspect_ratio > 2.0 or aspect_ratio < 0.5:  # æ¥µç«¯ãªã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”
                difficulty_factors += 0.2
            
            estimated_difficulty = min(difficulty_factors, 1.0)
            
            # æ¼«ç”»ã‚¹ã‚¿ã‚¤ãƒ«æ¨å®šï¼ˆã‚«ãƒ©ãƒ¼åˆ¤å®šã‹ã‚‰ï¼‰
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            color_variance = np.var(image)
            gray_variance = np.var(gray)
            
            # è‰²ã®åˆ†æ•£ãŒå°ã•ã„ = ãƒ¢ãƒã‚¯ãƒ­/æ¼«ç”»é¢¨
            manga_style_score = 1.0 - min(color_variance / 10000, 1.0)
            
            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒˆãƒ¼ãƒ³å¢ƒç•Œå•é¡Œæ¤œå‡ºï¼ˆãƒ¢ã‚¶ã‚¤ã‚¯å‡¦ç†ã‚’ç„¡åŠ¹åŒ–ï¼‰
            has_screentone = self._detect_screentone_patterns(gray)
            has_mosaic_patterns = False  # ãƒ¢ã‚¶ã‚¤ã‚¯å‡¦ç†ç„¡åŠ¹åŒ–
            
            # å¢ƒç•Œè¤‡é›‘åº¦ã®è¨ˆç®—ï¼ˆã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒˆãƒ¼ãƒ³ã®ã¿ï¼‰
            boundary_complexity = has_screentone
            if boundary_complexity:
                estimated_difficulty = min(estimated_difficulty + 0.3, 1.0)
            
            return ImageCharacteristics(
                has_complex_pose=has_complex_pose,
                has_full_body=has_full_body,
                has_multiple_characters=has_multiple_characters,
                is_face_focus=is_face_focus,
                aspect_ratio=aspect_ratio,
                estimated_difficulty=estimated_difficulty,
                manga_style_score=manga_style_score,
                has_screentone_issues=has_screentone,
                has_mosaic_issues=has_mosaic_patterns,
                has_boundary_complexity=boundary_complexity
            )
            
        except Exception as e:
            self.logger.error(f"ç”»åƒç‰¹æ€§åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return ImageCharacteristics(
                has_complex_pose=True,  # å®‰å…¨å´ã«å€’ã™
                has_full_body=True,
                has_multiple_characters=False,
                is_face_focus=False,
                aspect_ratio=1.0,
                estimated_difficulty=0.7,
                manga_style_score=0.8,
                has_screentone_issues=True,  # å®‰å…¨å´ã«å€’ã™
                has_mosaic_issues=False,
                has_boundary_complexity=True
            )
    
    def _detect_screentone_patterns(self, gray_image: np.ndarray) -> bool:
        """ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒˆãƒ¼ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º"""
        if not CV2_AVAILABLE:
            return False
            
        try:
            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒˆãƒ¼ãƒ³ã¯è¦å‰‡çš„ãªç‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŒã¤
            # FFTã‚’ä½¿ç”¨ã—ã¦å‘¨æœŸçš„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
            f_transform = np.fft.fft2(gray_image)
            f_shift = np.fft.fftshift(f_transform)
            magnitude_spectrum = np.log(np.abs(f_shift) + 1)
            
            # é«˜å‘¨æ³¢æˆåˆ†ã®å¼·åº¦ã‚’è¨ˆç®—
            h, w = magnitude_spectrum.shape
            center_h, center_w = h // 2, w // 2
            high_freq_region = magnitude_spectrum[center_h-50:center_h+50, center_w-50:center_w+50]
            high_freq_intensity = np.mean(high_freq_region)
            
            # é–¾å€¤ä»¥ä¸Šã§ã‚ã‚Œã°ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒˆãƒ¼ãƒ³ã¨åˆ¤å®š
            return high_freq_intensity > 12.0  # çµŒé¨“çš„é–¾å€¤
            
        except Exception:
            return False
    
    def _detect_mosaic_patterns(self, image: np.ndarray) -> bool:
        """ãƒ¢ã‚¶ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º"""
        if not CV2_AVAILABLE:
            return False
            
        try:
            # ãƒ¢ã‚¶ã‚¤ã‚¯ã¯çŸ©å½¢ãƒ–ãƒ­ãƒƒã‚¯ã®å¢ƒç•Œç·šãŒç‰¹å¾´çš„
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
            
            # ã‚¨ãƒƒã‚¸æ¤œå‡º
            edges = cv2.Canny(gray, 50, 150)
            
            # æ°´å¹³ãƒ»å‚ç›´ç·šã®æ¤œå‡º
            horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))
            vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))
            
            horizontal_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, horizontal_kernel)
            vertical_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, vertical_kernel)
            
            # æ ¼å­ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
            grid_pattern = cv2.bitwise_or(horizontal_lines, vertical_lines)
            grid_ratio = np.sum(grid_pattern > 0) / grid_pattern.size
            
            # é–¾å€¤ä»¥ä¸Šã§ã‚ã‚Œã°ãƒ¢ã‚¶ã‚¤ã‚¯ã¨åˆ¤å®š
            return grid_ratio > 0.05  # çµŒé¨“çš„é–¾å€¤
            
        except Exception:
            return False
    
    def predict_quality_and_method(self, image_characteristics: ImageCharacteristics,
                                 context: Optional[Dict] = None) -> QualityPrediction:
        """ç”»åƒç‰¹æ€§ã«åŸºã¥ãå“è³ªäºˆæ¸¬ã¨æ‰‹æ³•é¸æŠ"""
        
        # åŸºæœ¬ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰
        method_scores = {}
        
        for method, expected_quality in self.method_expected_quality.items():
            score = expected_quality
            
            # ç”»åƒç‰¹æ€§ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆæœ€æ–°ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãï¼‰
            if image_characteristics.has_complex_pose:
                if method == 'size_priority':
                    score += 0.4  # size_priorityãŒè¤‡é›‘å§¿å‹¢ã«æœ€ã‚‚å¼·ã„
                elif method == 'balanced':
                    score -= 0.1  # balancedã¯å®‰å®šã ãŒè¤‡é›‘å§¿å‹¢ã§ã¯è‹¥å¹²åŠ£ã‚‹
                elif method == 'confidence_priority':
                    score -= 0.2  # å®Ÿéš›ã¯è¤‡é›‘å§¿å‹¢ã«å¼±ã„ã“ã¨ãŒåˆ¤æ˜
            
            if image_characteristics.has_full_body:
                if method == 'size_priority':
                    score += 0.2  # å…¨èº«æ¤œå‡ºã«å¼·ã„
                elif method == 'fullbody_priority':
                    score += 0.4  # å…¨èº«ç‰¹åŒ–
            
            if image_characteristics.has_multiple_characters:
                if method == 'balanced':
                    score += 0.1  # balancedã¯è¤‡æ•°ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å‡¦ç†ãŒå®‰å®š
                elif method == 'size_priority':
                    score += 0.05  # size_priorityã‚‚è¤‡æ•°ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã«å¯¾å¿œå¯èƒ½
                elif method == 'confidence_priority':
                    score -= 0.15  # confidence_priorityã¯è¤‡æ•°ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ™‚ã«å•é¡ŒãŒå¤šã„
            
            if image_characteristics.is_face_focus:
                if method == 'size_priority':
                    score += 0.1  # size_priorityã¯é¡”ã‚‚é©åˆ‡ã«æŠ½å‡º
                elif method == 'balanced':
                    score += 0.05  # balancedã‚‚é¡”é‡è¦–ã§ã¯å®‰å®š
                elif method == 'confidence_priority':
                    score -= 0.1  # confidence_priorityã¯é¡”ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã§ã‚‚æœŸå¾…ä»¥ä¸‹
            
            # å›°é›£åº¦ã«ã‚ˆã‚‹èª¿æ•´
            difficulty_penalty = image_characteristics.estimated_difficulty * 0.3
            if method == 'size_priority':
                # size_priorityã¯å›°é›£åº¦ã®å½±éŸ¿ã‚’å—ã‘ã«ãã„ï¼ˆæœ€ã‚‚å …ç‰¢ï¼‰
                difficulty_penalty *= 0.5
            elif method == 'balanced':
                # balancedã¯ä¸­ç¨‹åº¦ã®å›°é›£åº¦è€æ€§
                difficulty_penalty *= 0.8
            elif method == 'confidence_priority':
                # confidence_priorityã¯å›°é›£åº¦ã®å½±éŸ¿ã‚’å—ã‘ã‚„ã™ã„
                difficulty_penalty *= 1.2
            
            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒˆãƒ¼ãƒ³ãƒ»ãƒ¢ã‚¶ã‚¤ã‚¯å¢ƒç•Œå•é¡Œã«ã‚ˆã‚‹èª¿æ•´
            if image_characteristics.has_boundary_complexity:
                if method == 'size_priority':
                    score -= 0.1  # size_priorityã§ã‚‚å¢ƒç•Œå•é¡Œã¯é›£ã—ã„
                elif method == 'balanced':
                    score -= 0.15  # balancedã¯å¢ƒç•Œå•é¡Œã«å¼±ã„
                elif method == 'confidence_priority':
                    score -= 0.25  # confidence_priorityã¯å¢ƒç•Œå•é¡Œã§å¤§å¹…åŠ£åŒ–
            
            score -= difficulty_penalty
            method_scores[method] = max(score, 0.1)  # æœ€ä½ã‚¹ã‚³ã‚¢ä¿è¨¼
        
        # æœ€é©æ‰‹æ³•ã®é¸æŠ
        best_method = max(method_scores.items(), key=lambda x: x[1])
        fallback_method = sorted(method_scores.items(), key=lambda x: x[1], reverse=True)[1]
        
        # ä¿¡é ¼åº¦è¨ˆç®—
        score_gap = best_method[1] - fallback_method[1]
        confidence = min(score_gap / 2.0 + 0.5, 1.0)
        
        # æ¨å¥¨ç†ç”±ç”Ÿæˆ
        reasoning_parts = [f"æœŸå¾…å“è³ª: {best_method[1]:.2f}"]
        
        if image_characteristics.has_complex_pose:
            reasoning_parts.append("è¤‡é›‘å§¿å‹¢å¯¾å¿œ")
        if image_characteristics.has_full_body:
            reasoning_parts.append("å…¨èº«æ¤œå‡º")
        if image_characteristics.has_multiple_characters:
            reasoning_parts.append("è¤‡æ•°ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å‡¦ç†")
        if image_characteristics.estimated_difficulty > 0.6:
            reasoning_parts.append(f"é«˜é›£æ˜“åº¦({image_characteristics.estimated_difficulty:.1f})")
        if image_characteristics.has_boundary_complexity:
            boundary_issues = []
            if image_characteristics.has_screentone_issues:
                boundary_issues.append("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒˆãƒ¼ãƒ³")
            if image_characteristics.has_mosaic_issues:
                boundary_issues.append("ãƒ¢ã‚¶ã‚¤ã‚¯")
            if boundary_issues:
                reasoning_parts.append(f"å¢ƒç•Œå•é¡Œ({'+'.join(boundary_issues)})")
        
        reasoning = "; ".join(reasoning_parts)
        
        return QualityPrediction(
            predicted_quality=best_method[1],
            confidence=confidence,
            recommended_method=best_method[0],
            fallback_method=fallback_method[0],
            reasoning=reasoning,
            image_characteristics=image_characteristics.__dict__
        )
    
    def should_use_adaptive_learning(self, prediction: QualityPrediction) -> bool:
        """é©å¿œå­¦ç¿’ã‚’ä½¿ç”¨ã™ã¹ãã‹ã®åˆ¤å®š"""
        # é«˜ä¿¡é ¼åº¦ã§è‰¯å¥½ãªäºˆæ¸¬å“è³ªã®å ´åˆã¯å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã‚’æ¨å¥¨
        return (prediction.confidence >= self.confidence_threshold and 
                prediction.predicted_quality >= self.quality_baseline['good'])
    
    def get_method_parameters(self, method: str, image_characteristics: ImageCharacteristics) -> Dict[str, Any]:
        """æ‰‹æ³•åˆ¥ã®æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—ï¼ˆå®Ÿç”¨çš„ãªé–¾å€¤ã«ä¿®æ­£ï¼‰"""
        # å®Ÿç”¨çš„ãªä½é–¾å€¤ã‚’ä½¿ç”¨ï¼ˆkaname05æ¤œè¨¼çµæœã«åŸºã¥ãï¼‰
        base_params = {
            'score_threshold': 0.005,  # 0.02 â†’ 0.005 ã«ä¿®æ­£ï¼ˆkaname05ã§å‹•ä½œç¢ºèªæ¸ˆã¿ï¼‰
            'multi_character_criteria': method,
            'anime_yolo': True
        }
        
        # ç”»åƒç‰¹æ€§ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆã‚ˆã‚Šå®Ÿç”¨çš„ã«ï¼‰
        if image_characteristics.has_complex_pose:
            base_params['score_threshold'] = 0.003  # è¤‡é›‘å§¿å‹¢ã§ã¯æ›´ã«ä½ã
        
        if image_characteristics.has_multiple_characters:
            base_params['score_threshold'] = 0.01  # è¤‡æ•°ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã¯è‹¥å¹²ä¸Šã’ã‚‹
        
        if image_characteristics.estimated_difficulty > 0.7:
            base_params['score_threshold'] = 0.002  # é«˜é›£åº¦ã§ã¯æœ€ä½ãƒ¬ãƒ™ãƒ«
        
        # å¢ƒç•Œå•é¡ŒãŒã‚ã‚‹å ´åˆã¯ã•ã‚‰ã«æ„Ÿåº¦ã‚’ä¸Šã’ã‚‹
        if image_characteristics.has_boundary_complexity:
            base_params['score_threshold'] = min(base_params['score_threshold'], 0.005)
        
        return base_params
    
    def log_prediction_result(self, image_path: str, prediction: QualityPrediction, 
                            actual_quality: Optional[float] = None):
        """äºˆæ¸¬çµæœã®ãƒ­ã‚°è¨˜éŒ²ï¼ˆå°†æ¥ã®å­¦ç¿’æ›´æ–°ç”¨ï¼‰"""
        # NumPy booleanå‹ã‚’Python booleanå‹ã«å¤‰æ›
        def convert_numpy_types(obj):
            if isinstance(obj, np.bool_):
                return bool(obj)
            elif isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, dict):
                return {k: convert_numpy_types(v) for k, v in obj.items()}
            return obj
        
        log_entry = {
            'timestamp': str(pd.Timestamp.now() if 'pd' in globals() else 'timestamp'),
            'image_path': image_path,
            'predicted_quality': prediction.predicted_quality,
            'predicted_method': prediction.recommended_method,
            'confidence': prediction.confidence,
            'reasoning': prediction.reasoning,
            'image_characteristics': convert_numpy_types(prediction.image_characteristics)
        }
        
        if actual_quality is not None:
            log_entry['actual_quality'] = actual_quality
            log_entry['prediction_error'] = abs(prediction.predicted_quality - actual_quality)
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜ï¼ˆJSONLå½¢å¼ï¼‰
        log_path = Path(__file__).parent.parent / "logs" / "quality_predictions.jsonl"
        log_path.parent.mkdir(exist_ok=True)
        
        try:
            with open(log_path, 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
        except Exception as e:
            self.logger.error(f"ãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
    
    def update_learning_data(self, feedback_data: List[Dict]):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹å­¦ç¿’æ›´æ–°ï¼ˆå°†æ¥å®Ÿè£…ï¼‰"""
        # ç¾åœ¨ã¯åŸºæœ¬å®Ÿè£…ã®ã¿
        # å®Ÿéš›ã®é‹ç”¨ã§ã¯ã€äºˆæ¸¬ç²¾åº¦ã¨å®Ÿéš›ã®çµæœã®å·®åˆ†ã‹ã‚‰
        # method_expected_qualityãªã©ã‚’å‹•çš„ã«æ›´æ–°
        self.logger.info(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ›´æ–°: {len(feedback_data)}ä»¶ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")


def create_quality_assessor() -> LearnedQualityAssessment:
    """å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°"""
    return LearnedQualityAssessment()


# segment-anythingãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆç”¨ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°
def assess_image_quality(image_path: str, 
                        yolo_detections: Optional[List] = None,
                        context: Optional[Dict] = None) -> QualityPrediction:
    """
    ç”»åƒã®å“è³ªè©•ä¾¡ã¨æœ€é©æ‰‹æ³•é¸æŠã®ãƒ¡ã‚¤ãƒ³é–¢æ•°
    
    Args:
        image_path: å¯¾è±¡ç”»åƒãƒ‘ã‚¹
        yolo_detections: YOLOæ¤œå‡ºçµæœï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        context: è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    Returns:
        QualityPrediction: å“è³ªäºˆæ¸¬çµæœ
    """
    assessor = create_quality_assessor()
    characteristics = assessor.analyze_image_characteristics(image_path, yolo_detections)
    prediction = assessor.predict_quality_and_method(characteristics, context)
    
    # ãƒ­ã‚°è¨˜éŒ²
    assessor.log_prediction_result(image_path, prediction)
    
    return prediction


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_image = "/mnt/c/AItools/lora/train/yadokugaeru/org/kaname05/kaname05_0001.jpg"
    
    if os.path.exists(test_image):
        print("ğŸ§ª å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        
        prediction = assess_image_quality(test_image)
        
        print(f"ğŸ“Š äºˆæ¸¬çµæœ:")
        print(f"   æ¨å¥¨æ‰‹æ³•: {prediction.recommended_method}")
        print(f"   äºˆæ¸¬å“è³ª: {prediction.predicted_quality:.3f}")
        print(f"   ä¿¡é ¼åº¦: {prediction.confidence:.3f}")
        print(f"   ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {prediction.fallback_method}")
        print(f"   ç†ç”±: {prediction.reasoning}")
        print(f"   ç”»åƒç‰¹æ€§: {prediction.image_characteristics}")
        
        print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
    else:
        print("âŒ ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")