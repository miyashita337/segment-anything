#!/usr/bin/env python3
"""
Text Detection Utilities
Text region detection and filtering for character extraction
"""

import cv2
import numpy as np
from typing import List, Tuple, Optional, Dict, Any

# Optional dependencies
try:
    import easyocr
    EASYOCR_AVAILABLE = True
except ImportError:
    EASYOCR_AVAILABLE = False

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False


class TextDetector:
    """
    ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºã‚¯ãƒ©ã‚¹
    EasyOCR ã¾ãŸã¯ OpenCV ãƒ™ãƒ¼ã‚¹ã®æ¤œå‡ºã‚’æä¾›
    """
    
    def __init__(self, use_easyocr: bool = True, languages: List[str] = ['ja', 'en']):
        """
        Initialize text detector
        
        Args:
            use_easyocr: Use EasyOCR if available
            languages: Languages for EasyOCR
        """
        self.use_easyocr = use_easyocr and EASYOCR_AVAILABLE
        self.reader = None
        
        if self.use_easyocr:
            self._init_easyocr(languages)
        
        print(f"ğŸ“ Text detector initialized (EasyOCR: {self.use_easyocr})")
    
    def _init_easyocr(self, languages: List[str]):
        """Initialize EasyOCR reader"""
        if EASYOCR_AVAILABLE and TORCH_AVAILABLE:
            try:
                gpu_available = torch.cuda.is_available()
                self.reader = easyocr.Reader(languages, gpu=gpu_available)
                print("âœ… EasyOCRåˆæœŸåŒ–å®Œäº†")
            except Exception as e:
                print(f"âš ï¸ EasyOCRåˆæœŸåŒ–å¤±æ•—: {e}")
                self.reader = None
        else:
            self.reader = None
    
    def detect_text_regions_easyocr(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        EasyOCRã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’æ¤œå‡º
        
        Args:
            image: å…¥åŠ›ç”»åƒ
            
        Returns:
            ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸæƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        if not self.reader:
            return []
        
        try:
            results = self.reader.readtext(image)
            text_regions = []
            
            for (bbox, text, confidence) in results:
                if confidence > 0.5:  # ä¿¡é ¼åº¦é–¾å€¤
                    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‹ã‚‰ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆ
                    mask = np.zeros(image.shape[:2], dtype=np.uint8)
                    points = np.array(bbox, dtype=np.int32)
                    cv2.fillPoly(mask, [points], 255)
                    
                    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’ [x, y, w, h] å½¢å¼ã«å¤‰æ›
                    x_coords = [p[0] for p in bbox]
                    y_coords = [p[1] for p in bbox]
                    x, y = min(x_coords), min(y_coords)
                    w, h = max(x_coords) - x, max(y_coords) - y
                    
                    text_regions.append({
                        'bbox': [x, y, w, h],
                        'mask': mask,
                        'text': text,
                        'confidence': confidence,
                        'polygon': bbox
                    })
            
            return text_regions
            
        except Exception as e:
            print(f"âš ï¸ EasyOCRãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def detect_text_regions_opencv(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        OpenCVã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚‰ã—ã„é ˜åŸŸã‚’æ¤œå‡º
        
        Args:
            image: å…¥åŠ›ç”»åƒ
            
        Returns:
            ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸæƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        try:
            # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()
            
            # ã‚¨ãƒƒã‚¸æ¤œå‡º
            edges = cv2.Canny(gray, 50, 150)
            
            # æ°´å¹³ãƒ»å‚ç›´æ–¹å‘ã®ã‚¨ãƒƒã‚¸ã®æ¤œå‡º
            horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))
            vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))
            
            horizontal_edges = cv2.morphologyEx(edges, cv2.MORPH_OPEN, horizontal_kernel)
            vertical_edges = cv2.morphologyEx(edges, cv2.MORPH_OPEN, vertical_kernel)
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚‰ã—ã„ç‰¹å¾´ã®æ¤œå‡º
            text_features = cv2.bitwise_or(horizontal_edges, vertical_edges)
            
            # è†¨å¼µå‡¦ç†ã§ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’çµåˆ
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
            text_features = cv2.dilate(text_features, kernel, iterations=2)
            
            # è¼ªéƒ­æ¤œå‡º
            contours, _ = cv2.findContours(text_features, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            text_regions = []
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 100:  # æœ€å°é¢ç©ãƒ•ã‚£ãƒ«ã‚¿
                    x, y, w, h = cv2.boundingRect(contour)
                    
                    # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã‚‰ã—ã„å½¢çŠ¶ï¼‰
                    aspect_ratio = w / h if h > 0 else 0
                    if 0.1 < aspect_ratio < 10:  # ãƒ†ã‚­ã‚¹ãƒˆã‚‰ã—ã„ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”
                        # ãƒã‚¹ã‚¯ä½œæˆ
                        mask = np.zeros(image.shape[:2], dtype=np.uint8)
                        cv2.rectangle(mask, (x, y), (x + w, y + h), 255, -1)
                        
                        text_regions.append({
                            'bbox': [x, y, w, h],
                            'mask': mask,
                            'text': '',  # OpenCVã§ã¯æ–‡å­—èªè­˜ã—ãªã„
                            'confidence': 0.7,  # å›ºå®šå€¤
                            'area': area,
                            'aspect_ratio': aspect_ratio
                        })
            
            return text_regions
            
        except Exception as e:
            print(f"âš ï¸ OpenCVãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def detect_text_regions(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’æ¤œå‡º
        
        Args:
            image: å…¥åŠ›ç”»åƒ
            
        Returns:
            ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸæƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        if self.use_easyocr and self.reader:
            return self.detect_text_regions_easyocr(image)
        else:
            return self.detect_text_regions_opencv(image)
    
    def has_significant_text(self, image: np.ndarray, threshold: float = 0.1) -> bool:
        """
        ç”»åƒã«é‡è¦ãªãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        
        Args:
            image: å…¥åŠ›ç”»åƒ
            threshold: ãƒ†ã‚­ã‚¹ãƒˆé¢ç©ã®é–¾å€¤ï¼ˆç”»åƒå…¨ä½“ã«å¯¾ã™ã‚‹å‰²åˆï¼‰
            
        Returns:
            é‡è¦ãªãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹
        """
        text_regions = self.detect_text_regions(image)
        if not text_regions:
            return False
        
        # ãƒ†ã‚­ã‚¹ãƒˆé¢ç©ã®åˆè¨ˆã‚’è¨ˆç®—
        total_text_area = sum(np.sum(region['mask'] > 0) for region in text_regions)
        image_area = image.shape[0] * image.shape[1]
        text_ratio = total_text_area / image_area
        
        return text_ratio > threshold
    
    def calculate_text_density_score(self, image: np.ndarray, bbox: Tuple[int, int, int, int]) -> float:
        """
        æŒ‡å®šã•ã‚ŒãŸé ˜åŸŸã®ãƒ†ã‚­ã‚¹ãƒˆå¯†åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        
        Args:
            image: å…¥åŠ›ç”»åƒ
            bbox: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ [x, y, w, h]
            
        Returns:
            ãƒ†ã‚­ã‚¹ãƒˆå¯†åº¦ã‚¹ã‚³ã‚¢ (0.0-1.0, é«˜ã„ã»ã©ãƒ†ã‚­ã‚¹ãƒˆãŒå¤šã„)
        """
        try:
            x, y, w, h = bbox
            
            # é ˜åŸŸã‚’ã‚¯ãƒ­ãƒƒãƒ—
            height, width = image.shape[:2]
            x1, y1 = max(0, x), max(0, y)
            x2, y2 = min(width, x + w), min(height, y + h)
            
            if x2 <= x1 or y2 <= y1:
                return 0.0
            
            roi = image[y1:y2, x1:x2]
            
            # ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡º
            text_regions = self.detect_text_regions(roi)
            
            if not text_regions:
                return 0.0
            
            # ãƒ†ã‚­ã‚¹ãƒˆé¢ç©è¨ˆç®—
            total_text_area = sum(np.sum(region['mask'] > 0) for region in text_regions)
            roi_area = roi.shape[0] * roi.shape[1]
            
            text_density = total_text_area / roi_area if roi_area > 0 else 0.0
            
            # å¯†åº¦ã«åŸºã¥ãã‚¹ã‚³ã‚¢è¨ˆç®—
            if text_density > 0.15:  # 15%ä»¥ä¸ŠãŒãƒ†ã‚­ã‚¹ãƒˆ
                return 0.8
            elif text_density > 0.1:  # 10%ä»¥ä¸Š
                return 0.6
            elif text_density > 0.05:  # 5%ä»¥ä¸Š
                return 0.3
            
            return text_density * 2  # 5%æœªæº€ã¯ç·šå½¢ã‚¹ã‚±ãƒ¼ãƒ«
            
        except Exception as e:
            print(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆå¯†åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def filter_text_heavy_masks(self, 
                               masks: List[Dict[str, Any]], 
                               image: np.ndarray,
                               max_text_density: float = 0.3) -> List[Dict[str, Any]]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆãŒå¤šã™ãã‚‹ãƒã‚¹ã‚¯ã‚’é™¤å¤–
        
        Args:
            masks: ãƒã‚¹ã‚¯ãƒªã‚¹ãƒˆ
            image: å…ƒç”»åƒ
            max_text_density: æœ€å¤§ãƒ†ã‚­ã‚¹ãƒˆå¯†åº¦é–¾å€¤
            
        Returns:
            ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ãƒã‚¹ã‚¯ãƒªã‚¹ãƒˆ
        """
        filtered_masks = []
        
        for mask in masks:
            bbox = mask['bbox']
            text_density = self.calculate_text_density_score(image, bbox)
            
            # ãƒ†ã‚­ã‚¹ãƒˆå¯†åº¦æƒ…å ±ã‚’ãƒã‚¹ã‚¯ã«è¿½åŠ 
            mask_with_text = mask.copy()
            mask_with_text['text_density'] = text_density
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if text_density <= max_text_density:
                filtered_masks.append(mask_with_text)
            else:
                print(f"ğŸš« ãƒ†ã‚­ã‚¹ãƒˆå¯†åº¦ãŒé«˜ã„ãƒã‚¹ã‚¯ã‚’é™¤å¤–: {text_density:.3f}")
        
        return filtered_masks
    
    def get_text_free_regions(self, image: np.ndarray) -> np.ndarray:
        """
        ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ãªã„é ˜åŸŸã®ãƒã‚¹ã‚¯ã‚’å–å¾—
        
        Args:
            image: å…¥åŠ›ç”»åƒ
            
        Returns:
            ãƒ†ã‚­ã‚¹ãƒˆãƒ•ãƒªãƒ¼é ˜åŸŸã®ãƒã‚¹ã‚¯
        """
        text_regions = self.detect_text_regions(image)
        
        # å…¨ä½“ãƒã‚¹ã‚¯ã‚’ä½œæˆï¼ˆç™½ã§åˆæœŸåŒ–ï¼‰
        text_free_mask = np.ones(image.shape[:2], dtype=np.uint8) * 255
        
        # ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’é»’ã§å¡—ã‚Šã¤ã¶ã—
        for region in text_regions:
            text_free_mask = cv2.bitwise_and(text_free_mask, cv2.bitwise_not(region['mask']))
        
        return text_free_mask


def detect_text_with_opencv_fallback(image: np.ndarray) -> List[np.ndarray]:
    """
    OpenCVãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ããƒ†ã‚­ã‚¹ãƒˆæ¤œå‡º
    
    Args:
        image: å…¥åŠ›ç”»åƒ
        
    Returns:
        ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸãƒã‚¹ã‚¯ã®ãƒªã‚¹ãƒˆ
    """
    detector = TextDetector(use_easyocr=True)
    text_regions = detector.detect_text_regions(image)
    
    return [region['mask'] for region in text_regions]


def is_text_heavy_region(image: np.ndarray, bbox: Tuple[int, int, int, int], threshold: float = 0.2) -> bool:
    """
    æŒ‡å®šé ˜åŸŸãŒãƒ†ã‚­ã‚¹ãƒˆãŒå¤šã„é ˜åŸŸã‹ã©ã†ã‹ã‚’åˆ¤å®š
    
    Args:
        image: å…¥åŠ›ç”»åƒ
        bbox: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ [x, y, w, h]
        threshold: ãƒ†ã‚­ã‚¹ãƒˆå¯†åº¦é–¾å€¤
        
    Returns:
        ãƒ†ã‚­ã‚¹ãƒˆãŒå¤šã„é ˜åŸŸã‹ã©ã†ã‹
    """
    detector = TextDetector(use_easyocr=False)  # OpenCVã®ã¿ä½¿ç”¨ï¼ˆé«˜é€Ÿï¼‰
    text_density = detector.calculate_text_density_score(image, bbox)
    
    return text_density > threshold


if __name__ == "__main__":
    # Test text detection
    print("ğŸ§ª Text detection test starting...")
    
    detector = TextDetector(use_easyocr=True)
    
    # Create test image with text-like patterns
    test_image = np.ones((200, 300, 3), dtype=np.uint8) * 255
    
    # Add some horizontal lines (text-like)
    for i in range(50, 150, 20):
        cv2.rectangle(test_image, (50, i), (250, i + 5), (0, 0, 0), -1)
    
    # Test detection
    text_regions = detector.detect_text_regions(test_image)
    has_text = detector.has_significant_text(test_image)
    
    print(f"âœ… Text detection test completed")
    print(f"   Detected {len(text_regions)} text regions")
    print(f"   Has significant text: {has_text}")
    print(f"   EasyOCR available: {EASYOCR_AVAILABLE}")
    
    # Test text density
    bbox = (40, 40, 220, 120)
    density = detector.calculate_text_density_score(test_image, bbox)
    print(f"   Text density in bbox: {density:.3f}")