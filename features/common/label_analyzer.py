#!/usr/bin/env python3
"""
Label Data Analyzer - æŠ½å‡ºã—ãŸãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°åˆ†æ
Analysis of extracted label data for character extraction learning
"""

import numpy as np
import cv2
import matplotlib.pyplot as plt

import json
import logging
from collections import defaultdict
from pathlib import Path
from typing import Any, Dict, List, Tuple

logger = logging.getLogger(__name__)


class LabelDataAnalyzer:
    """ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, labels_path: Path):
        """
        åˆæœŸåŒ–
        
        Args:
            labels_path: æŠ½å‡ºæ¸ˆã¿ãƒ©ãƒ™ãƒ«JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.labels_path = labels_path
        self.labels_data = self.load_labels()
        
    def load_labels(self) -> List[Dict[str, Any]]:
        """ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(self.labels_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            logger.info(f"ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(data)}ãƒ•ã‚¡ã‚¤ãƒ«")
            return data
        except Exception as e:
            logger.error(f"ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def analyze_character_regions(self) -> Dict[str, Any]:
        """
        ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é ˜åŸŸã®çµ±è¨ˆåˆ†æ
        
        Returns:
            çµ±è¨ˆæƒ…å ±è¾æ›¸
        """
        stats = {
            "total_files": len(self.labels_data),
            "files_with_character": 0,
            "aspect_ratios": [],
            "areas": [],
            "sizes": [],
            "positions": [],
            "fill_ratios": []
        }
        
        for label in self.labels_data:
            if label.get("character_region"):
                char_region = label["character_region"]
                bbox = char_region["bbox"]
                
                stats["files_with_character"] += 1
                
                # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”
                aspect_ratio = bbox["height"] / max(bbox["width"], 1)
                stats["aspect_ratios"].append(aspect_ratio)
                
                # é¢ç©
                area = bbox["width"] * bbox["height"]
                stats["areas"].append(area)
                
                # ã‚µã‚¤ã‚ºï¼ˆå¹…xé«˜ã•ï¼‰
                stats["sizes"].append((bbox["width"], bbox["height"]))
                
                # ä½ç½®ï¼ˆç”»åƒå†…ã®ç›¸å¯¾ä½ç½®ï¼‰
                img_w, img_h = label["image_size"]
                rel_x = (bbox["x"] + bbox["width"]/2) / max(img_w, 1)
                rel_y = (bbox["y"] + bbox["height"]/2) / max(img_h, 1)
                stats["positions"].append((rel_x, rel_y))
                
                # å¡—ã‚Šã¤ã¶ã—æ¯”ç‡
                if "fill_ratio" in char_region:
                    stats["fill_ratios"].append(char_region["fill_ratio"])
        
        # çµ±è¨ˆå€¤è¨ˆç®—
        if stats["aspect_ratios"]:
            stats["aspect_ratio_stats"] = {
                "mean": np.mean(stats["aspect_ratios"]),
                "std": np.std(stats["aspect_ratios"]),
                "min": np.min(stats["aspect_ratios"]),
                "max": np.max(stats["aspect_ratios"]),
                "median": np.median(stats["aspect_ratios"])
            }
        
        if stats["areas"]:
            stats["area_stats"] = {
                "mean": np.mean(stats["areas"]),
                "std": np.std(stats["areas"]),
                "min": np.min(stats["areas"]),
                "max": np.max(stats["areas"]),
                "median": np.median(stats["areas"])
            }
        
        logger.info(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é ˜åŸŸåˆ†æå®Œäº†: {stats['files_with_character']}/{stats['total_files']}ãƒ•ã‚¡ã‚¤ãƒ«")
        
        return stats
    
    def analyze_panel_patterns(self) -> Dict[str, Any]:
        """
        ã‚³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
        
        Returns:
            ã‚³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æçµæœ
        """
        panel_stats = {
            "panel_sizes": [],
            "panel_positions": [],
            "character_to_panel_ratios": [],
            "panel_types": defaultdict(int)
        }
        
        for label in self.labels_data:
            if label.get("largest_panel_box") and label.get("character_region"):
                panel = label["largest_panel_box"]["bbox"]
                char = label["character_region"]["bbox"]
                
                # ãƒ‘ãƒãƒ«ã‚µã‚¤ã‚º
                panel_area = panel["width"] * panel["height"]
                panel_stats["panel_sizes"].append(panel_area)
                
                # ãƒ‘ãƒãƒ«å†…ã§ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ¯”ç‡
                char_area = char["width"] * char["height"]
                char_to_panel_ratio = char_area / max(panel_area, 1)
                panel_stats["character_to_panel_ratios"].append(char_to_panel_ratio)
                
                # ãƒ‘ãƒãƒ«ã‚¿ã‚¤ãƒ—åˆ†é¡ï¼ˆã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ãƒ™ãƒ¼ã‚¹ï¼‰
                panel_aspect = panel["height"] / max(panel["width"], 1)
                if panel_aspect > 1.5:
                    panel_stats["panel_types"]["vertical"] += 1
                elif panel_aspect < 0.7:
                    panel_stats["panel_types"]["horizontal"] += 1
                else:
                    panel_stats["panel_types"]["square"] += 1
        
        return panel_stats
    
    def classify_character_types(self) -> Dict[str, Any]:
        """
        ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡ºã‚¿ã‚¤ãƒ—ã®åˆ†é¡
        
        Returns:
            ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚¿ã‚¤ãƒ—åˆ†æçµæœ
        """
        type_stats = {
            "full_body": 0,      # å…¨èº«
            "bust_up": 0,        # ãƒã‚¹ãƒˆã‚¢ãƒƒãƒ—
            "face_close": 0,     # é¡”ã‚¢ãƒƒãƒ—
            "other": 0
        }
        
        for label in self.labels_data:
            if label.get("character_region"):
                char_region = label["character_region"]
                aspect_ratio = char_region.get("aspect_ratio", 1.0)
                area = char_region.get("area", 0)
                
                # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã¨é¢ç©ã§åˆ†é¡
                if aspect_ratio > 2.0 and area > 50000:
                    type_stats["full_body"] += 1
                elif 1.2 <= aspect_ratio <= 2.0:
                    type_stats["bust_up"] += 1
                elif aspect_ratio < 1.2:
                    type_stats["face_close"] += 1
                else:
                    type_stats["other"] += 1
        
        return type_stats
    
    def generate_learning_insights(self) -> Dict[str, Any]:
        """
        å­¦ç¿’ã®ãŸã‚ã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ
        
        Returns:
            å­¦ç¿’ç”¨ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        """
        char_stats = self.analyze_character_regions()
        panel_stats = self.analyze_panel_patterns()
        type_stats = self.classify_character_types()
        
        insights = {
            "dataset_summary": {
                "total_labels": char_stats["total_files"],
                "successful_extractions": char_stats["files_with_character"],
                "success_rate": char_stats["files_with_character"] / max(char_stats["total_files"], 1)
            },
            
            "character_features": {
                "typical_aspect_ratio": char_stats.get("aspect_ratio_stats", {}).get("mean", 1.5),
                "size_variation": char_stats.get("area_stats", {}).get("std", 0),
                "position_distribution": char_stats["positions"] if char_stats["positions"] else []
            },
            
            "extraction_patterns": {
                "character_types": type_stats,
                "dominant_type": max(type_stats.items(), key=lambda x: x[1])[0] if type_stats else "unknown"
            },
            
            "learning_recommendations": []
        }
        
        # å­¦ç¿’æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
        if char_stats["files_with_character"] > 80:
            insights["learning_recommendations"].append(
                "è±Šå¯Œãªãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆ80+ï¼‰ãŒåˆ©ç”¨å¯èƒ½ã€‚æ·±å±¤å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒæœ‰åŠ¹ã€‚"
            )
        
        if char_stats.get("aspect_ratio_stats", {}).get("std", 0) > 0.5:
            insights["learning_recommendations"].append(
                "ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã®å¤‰å‹•ãŒå¤§ãã„ã€‚å¤šæ§˜ãªæŠ½å‡ºç¯„å›²ã«å¯¾å¿œã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚"
            )
        
        if type_stats.get("full_body", 0) > type_stats.get("face_close", 0):
            insights["learning_recommendations"].append(
                "å…¨èº«æŠ½å‡ºãŒå¤šã„ã€‚èº«ä½“æ¤œå‡ºæ©Ÿèƒ½ã®å¼·åŒ–ãŒé‡è¦ã€‚"
            )
        
        return insights
    
    def create_visualization_report(self, output_dir: Path):
        """
        å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        
        Args:
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        try:
            output_dir.mkdir(exist_ok=True)
            
            char_stats = self.analyze_character_regions()
            
            # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”åˆ†å¸ƒ
            if char_stats["aspect_ratios"]:
                plt.figure(figsize=(10, 6))
                plt.hist(char_stats["aspect_ratios"], bins=20, alpha=0.7, color='blue', edgecolor='black')
                plt.xlabel('Aspect Ratio (Height/Width)')
                plt.ylabel('Frequency')
                plt.title('Character Region Aspect Ratio Distribution')
                plt.grid(True, alpha=0.3)
                plt.savefig(output_dir / "aspect_ratio_distribution.png", dpi=150, bbox_inches='tight')
                plt.close()
            
            # é¢ç©åˆ†å¸ƒ
            if char_stats["areas"]:
                plt.figure(figsize=(10, 6))
                plt.hist(char_stats["areas"], bins=20, alpha=0.7, color='green', edgecolor='black')
                plt.xlabel('Area (pixelsÂ²)')
                plt.ylabel('Frequency')
                plt.title('Character Region Area Distribution')
                plt.grid(True, alpha=0.3)
                plt.savefig(output_dir / "area_distribution.png", dpi=150, bbox_inches='tight')
                plt.close()
            
            # ä½ç½®åˆ†å¸ƒï¼ˆæ•£å¸ƒå›³ï¼‰
            if char_stats["positions"]:
                positions = np.array(char_stats["positions"])
                plt.figure(figsize=(8, 8))
                plt.scatter(positions[:, 0], positions[:, 1], alpha=0.6, color='red')
                plt.xlabel('Relative X Position')
                plt.ylabel('Relative Y Position')
                plt.title('Character Position Distribution in Images')
                plt.xlim(0, 1)
                plt.ylim(0, 1)
                plt.grid(True, alpha=0.3)
                plt.savefig(output_dir / "position_distribution.png", dpi=150, bbox_inches='tight')
                plt.close()
            
            logger.info(f"å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {output_dir}")
            
        except Exception as e:
            logger.error(f"å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def export_analysis_report(self, output_path: Path):
        """
        ç·åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’JSONã§å‡ºåŠ›
        
        Args:
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        try:
            insights = self.generate_learning_insights()
            char_stats = self.analyze_character_regions()
            panel_stats = self.analyze_panel_patterns()
            type_stats = self.classify_character_types()
            
            report = {
                "analysis_summary": insights,
                "character_statistics": char_stats,
                "panel_statistics": panel_stats,
                "character_types": type_stats,
                "analysis_timestamp": str(Path(__file__).stat().st_mtime)
            }
            
            # NumPyé…åˆ—ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›
            def convert_numpy(obj):
                if isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, np.floating):
                    return float(obj)
                elif isinstance(obj, dict):
                    return {k: convert_numpy(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy(item) for item in obj]
                return obj
            
            report = convert_numpy(report)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            logger.info(f"åˆ†æãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›å®Œäº†: {output_path}")
            
        except Exception as e:
            logger.error(f"åˆ†æãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    logging.basicConfig(level=logging.INFO)
    
    # å…¥åŠ›ãƒ»å‡ºåŠ›ãƒ‘ã‚¹
    labels_path = Path("/mnt/c/AItools/segment-anything/extracted_labels.json")
    output_dir = Path("/mnt/c/AItools/segment-anything/label_analysis")
    report_path = output_dir / "analysis_report.json"
    
    # åˆ†æå®Ÿè¡Œ
    analyzer = LabelDataAnalyzer(labels_path)
    
    # åˆ†æçµæœå‡ºåŠ›
    analyzer.export_analysis_report(report_path)
    analyzer.create_visualization_report(output_dir)
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    insights = analyzer.generate_learning_insights()
    
    print("\nğŸ“Š ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿åˆ†æçµæœ:")
    print(f"  ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {insights['dataset_summary']['total_labels']}")
    print(f"  æˆåŠŸæŠ½å‡ºæ•°: {insights['dataset_summary']['successful_extractions']}")
    print(f"  æˆåŠŸç‡: {insights['dataset_summary']['success_rate']*100:.1f}%")
    
    print(f"\nğŸ¯ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç‰¹å¾´:")
    print(f"  å¹³å‡ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {insights['character_features']['typical_aspect_ratio']:.2f}")
    print(f"  æ”¯é…çš„ã‚¿ã‚¤ãƒ—: {insights['extraction_patterns']['dominant_type']}")
    
    print(f"\nğŸ’¡ å­¦ç¿’æ¨å¥¨äº‹é …:")
    for rec in insights['learning_recommendations']:
        print(f"  - {rec}")
    
    print(f"\nğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"  åˆ†æãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
    print(f"  å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«: {output_dir}")


if __name__ == "__main__":
    main()