#!/usr/bin/env python3
"""
Box Expansion Utilities
GPT-4Oæ¨å¥¨ã®YOLOæ¤œå‡ºãƒœãƒƒã‚¯ã‚¹æ‹¡å¼µæ©Ÿèƒ½
é¡”æ¤œå‡ºãƒœãƒƒã‚¯ã‚¹ã‚’2.5-3å€æ°´å¹³ã€4å€å‚ç›´ã«æ‹¡å¼µã—ã¦ã‹ã‚‰SAMå‡¦ç†
"""

import numpy as np
from typing import List, Dict, Any, Tuple


class BoxExpansionProcessor:
    """
    YOLOæ¤œå‡ºãƒœãƒƒã‚¯ã‚¹æ‹¡å¼µå‡¦ç†ã‚¯ãƒ©ã‚¹
    GPT-4Oæ¨å¥¨ã®æ‹¡å¼µãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åŸºã¥ãå®Ÿè£…
    """
    
    def __init__(self, 
                 horizontal_expansion: float = 2.75,  # 2.5-3å€ã®ä¸­é–“å€¤
                 vertical_expansion: float = 4.0,     # 4å€
                 min_expansion_factor: float = 1.2,   # æœ€å°æ‹¡å¼µç‡
                 max_expansion_factor: float = 5.0):  # æœ€å¤§æ‹¡å¼µç‡
        """
        ãƒœãƒƒã‚¯ã‚¹æ‹¡å¼µãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’åˆæœŸåŒ–
        
        Args:
            horizontal_expansion: æ°´å¹³æ–¹å‘æ‹¡å¼µå€ç‡ (2.5-3.0æ¨å¥¨)
            vertical_expansion: å‚ç›´æ–¹å‘æ‹¡å¼µå€ç‡ (4.0æ¨å¥¨)
            min_expansion_factor: æœ€å°æ‹¡å¼µå€ç‡ï¼ˆå®‰å…¨åˆ¶é™ï¼‰
            max_expansion_factor: æœ€å¤§æ‹¡å¼µå€ç‡ï¼ˆå®‰å…¨åˆ¶é™ï¼‰
        """
        self.horizontal_expansion = max(min_expansion_factor, 
                                      min(horizontal_expansion, max_expansion_factor))
        self.vertical_expansion = max(min_expansion_factor, 
                                    min(vertical_expansion, max_expansion_factor))
        self.min_expansion_factor = min_expansion_factor
        self.max_expansion_factor = max_expansion_factor
    
    def expand_detection_box(self, 
                           bbox: List[int], 
                           image_shape: Tuple[int, int],
                           detection_type: str = 'person') -> Dict[str, Any]:
        """
        YOLOæ¤œå‡ºãƒœãƒƒã‚¯ã‚¹ã‚’æ‹¡å¼µ
        
        Args:
            bbox: YOLOæ¤œå‡ºãƒœãƒƒã‚¯ã‚¹ [x, y, w, h]
            image_shape: ç”»åƒã‚µã‚¤ã‚º (height, width)
            detection_type: æ¤œå‡ºã‚¿ã‚¤ãƒ— ('person', 'face' ãªã©)
            
        Returns:
            æ‹¡å¼µçµæœè¾æ›¸ï¼ˆå…ƒãƒœãƒƒã‚¯ã‚¹ã€æ‹¡å¼µãƒœãƒƒã‚¯ã‚¹ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰
        """
        x, y, w, h = bbox
        img_height, img_width = image_shape
        
        # æ‹¡å¼µå€ç‡ã®é©ç”¨
        if detection_type == 'face':
            # é¡”æ¤œå‡ºã®å ´åˆã¯ã‚ˆã‚Šå¤§ããæ‹¡å¼µï¼ˆå…¨èº«ã‚’å«ã‚€å¯èƒ½æ€§ï¼‰
            h_expansion = self.horizontal_expansion * 1.2
            v_expansion = self.vertical_expansion * 1.1
        else:
            # äººç‰©æ¤œå‡ºã®å ´åˆã¯æ¨™æº–æ‹¡å¼µ
            h_expansion = self.horizontal_expansion
            v_expansion = self.vertical_expansion
        
        # æ–°ã—ã„å¹…ã¨é«˜ã•ã‚’è¨ˆç®—
        new_w = int(w * h_expansion)
        new_h = int(h * v_expansion)
        
        # ä¸­å¿ƒç‚¹ã‚’ç¶­æŒã—ã¦æ‹¡å¼µ
        center_x = x + w // 2
        center_y = y + h // 2
        
        new_x = center_x - new_w // 2
        new_y = center_y - new_h // 2
        
        # ç”»åƒå¢ƒç•Œå†…ã«åˆ¶é™
        new_x = max(0, min(new_x, img_width - new_w))
        new_y = max(0, min(new_y, img_height - new_h))
        new_w = min(new_w, img_width - new_x)
        new_h = min(new_h, img_height - new_y)
        
        # æ‹¡å¼µçµæœ
        expanded_bbox = [new_x, new_y, new_w, new_h]
        
        return {
            'original_bbox': bbox,
            'expanded_bbox': expanded_bbox,
            'expansion_factors': {
                'horizontal': new_w / w if w > 0 else 0,
                'vertical': new_h / h if h > 0 else 0
            },
            'detection_type': detection_type,
            'clipped_to_bounds': (
                new_x != center_x - new_w // 2 or 
                new_y != center_y - new_h // 2 or
                new_w != int(w * h_expansion) or
                new_h != int(h * v_expansion)
            )
        }
    
    def expand_all_detections(self, 
                            detections: List[Dict[str, Any]], 
                            image_shape: Tuple[int, int]) -> List[Dict[str, Any]]:
        """
        è¤‡æ•°ã®YOLOæ¤œå‡ºçµæœã‚’ä¸€æ‹¬æ‹¡å¼µ
        
        Args:
            detections: YOLOæ¤œå‡ºçµæœãƒªã‚¹ãƒˆ
            image_shape: ç”»åƒã‚µã‚¤ã‚º (height, width)
            
        Returns:
            æ‹¡å¼µæ¸ˆã¿æ¤œå‡ºçµæœãƒªã‚¹ãƒˆ
        """
        expanded_detections = []
        
        for detection in detections:
            bbox = detection['bbox']  # [x, y, w, h]
            detection_type = detection.get('class_name', 'person')
            
            expansion_result = self.expand_detection_box(
                bbox, image_shape, detection_type
            )
            
            # å…ƒã®æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã«æ‹¡å¼µæƒ…å ±ã‚’è¿½åŠ 
            expanded_detection = detection.copy()
            expanded_detection.update({
                'bbox_original': expansion_result['original_bbox'],
                'bbox': expansion_result['expanded_bbox'],  # æ‹¡å¼µãƒœãƒƒã‚¯ã‚¹ã§ä¸Šæ›¸ã
                'expansion_info': {
                    'horizontal_factor': expansion_result['expansion_factors']['horizontal'],
                    'vertical_factor': expansion_result['expansion_factors']['vertical'],
                    'clipped_to_bounds': expansion_result['clipped_to_bounds'],
                    'expansion_type': f"H{self.horizontal_expansion:.1f}xV{self.vertical_expansion:.1f}"
                }
            })
            
            expanded_detections.append(expanded_detection)
        
        return expanded_detections
    
    def create_sam_prompts_from_expanded_boxes(self, 
                                             expanded_detections: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æ‹¡å¼µãƒœãƒƒã‚¯ã‚¹ã‹ã‚‰SAMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå½¢å¼ã‚’ç”Ÿæˆ
        
        Args:
            expanded_detections: æ‹¡å¼µæ¸ˆã¿æ¤œå‡ºçµæœ
            
        Returns:
            SAMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå½¢å¼ã®ãƒªã‚¹ãƒˆ
        """
        sam_prompts = []
        
        for detection in expanded_detections:
            bbox = detection['bbox']  # æ‹¡å¼µæ¸ˆã¿ãƒœãƒƒã‚¯ã‚¹ [x, y, w, h]
            x, y, w, h = bbox
            
            # SAMã®ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå½¢å¼ [x1, y1, x2, y2]
            sam_box = [x, y, x + w, y + h]
            
            sam_prompt = {
                'type': 'box',
                'coordinates': sam_box,
                'confidence': detection.get('confidence', 0.0),
                'original_detection': detection,
                'expansion_info': detection.get('expansion_info', {})
            }
            
            sam_prompts.append(sam_prompt)
        
        return sam_prompts
    
    def get_expansion_config(self) -> Dict[str, float]:
        """
        ç¾åœ¨ã®æ‹¡å¼µè¨­å®šã‚’å–å¾—
        
        Returns:
            æ‹¡å¼µè¨­å®šè¾æ›¸
        """
        return {
            'horizontal_expansion': self.horizontal_expansion,
            'vertical_expansion': self.vertical_expansion,
            'min_expansion_factor': self.min_expansion_factor,
            'max_expansion_factor': self.max_expansion_factor,
            'gpt4o_recommended': {
                'horizontal_range': [2.5, 3.0],
                'vertical_target': 4.0,
                'purpose': 'Face detection box expansion for full-body character extraction'
            }
        }


def apply_gpt4o_expansion_strategy(detections: List[Dict[str, Any]], 
                                  image_shape: Tuple[int, int],
                                  strategy: str = 'balanced') -> List[Dict[str, Any]]:
    """
    GPT-4Oæ¨å¥¨æˆ¦ç•¥ã«ã‚ˆã‚‹æ¤œå‡ºãƒœãƒƒã‚¯ã‚¹æ‹¡å¼µ
    
    Args:
        detections: YOLOæ¤œå‡ºçµæœ
        image_shape: ç”»åƒã‚µã‚¤ã‚º
        strategy: æ‹¡å¼µæˆ¦ç•¥ ('conservative', 'balanced', 'aggressive')
        
    Returns:
        æ‹¡å¼µæ¸ˆã¿æ¤œå‡ºçµæœ
    """
    strategy_configs = {
        'conservative': {'horizontal': 2.5, 'vertical': 3.5},
        'balanced': {'horizontal': 2.75, 'vertical': 4.0},      # GPT-4Oæ¨å¥¨
        'aggressive': {'horizontal': 3.0, 'vertical': 4.5}
    }
    
    config = strategy_configs.get(strategy, strategy_configs['balanced'])
    
    processor = BoxExpansionProcessor(
        horizontal_expansion=config['horizontal'],
        vertical_expansion=config['vertical']
    )
    
    expanded_detections = processor.expand_all_detections(detections, image_shape)
    
    return expanded_detections


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
    test_detections = [
        {'bbox': [100, 150, 80, 120], 'confidence': 0.85, 'class_name': 'person'},
        {'bbox': [300, 200, 60, 80], 'confidence': 0.92, 'class_name': 'face'}
    ]
    
    test_image_shape = (720, 1280)  # height, width
    
    # GPT-4Oæ¨å¥¨æˆ¦ç•¥ã‚’ãƒ†ã‚¹ãƒˆ
    expanded = apply_gpt4o_expansion_strategy(test_detections, test_image_shape, 'balanced')
    
    print("ğŸ¯ GPT-4Oæ¨å¥¨ãƒœãƒƒã‚¯ã‚¹æ‹¡å¼µãƒ†ã‚¹ãƒˆ:")
    for i, detection in enumerate(expanded):
        print(f"  æ¤œå‡º{i+1}:")
        print(f"    å…ƒãƒœãƒƒã‚¯ã‚¹: {detection['bbox_original']}")
        print(f"    æ‹¡å¼µãƒœãƒƒã‚¯ã‚¹: {detection['bbox']}")
        print(f"    æ‹¡å¼µå€ç‡: H{detection['expansion_info']['horizontal_factor']:.1f}x V{detection['expansion_info']['vertical_factor']:.1f}x")
        print(f"    å¢ƒç•Œåˆ¶é™: {'ã‚ã‚Š' if detection['expansion_info']['clipped_to_bounds'] else 'ãªã—'}")