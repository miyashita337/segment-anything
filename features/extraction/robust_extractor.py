#!/usr/bin/env python3
"""
Robust Character Extractor - ãƒ­ãƒã‚¹ãƒˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ 
è¤‡æ•°æ‰‹æ³•ã®ä¸¦åˆ—å®Ÿè¡Œã«ã‚ˆã‚‹æœ€é©çµæžœé¸æŠžã¨å“è³ªä¿è¨¼
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

import numpy as np
import cv2

import json
import logging
import subprocess
import tempfile
from features.common.hooks.start import get_sam_model, get_yolo_model, initialize_models
from features.evaluation.utils.face_detection import filter_non_character_masks
from features.evaluation.utils.non_character_filter import apply_non_character_filter
from features.processing.preprocessing.color_preserving_enhancer import ColorPreservingEnhancer
from features.processing.preprocessing.preprocessing import preprocess_image_pipeline
from PIL import Image
from typing import Any, Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


class RobustCharacterExtractor:
    """ãƒ­ãƒã‚¹ãƒˆå“è³ªä¿è¨¼ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.color_enhancer = ColorPreservingEnhancer(
            preserve_luminance=True,
            preserve_saturation=True,
            adaptive_enhancement=True
        )
        
        # éŽåŽ»ã®æˆåŠŸçµæžœã‚’è¨˜éŒ²ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        self.success_history = {}
        
        logger.info("RobustCharacterExtractoråˆæœŸåŒ–å®Œäº†")

    def extract_character_robust(self, 
                                input_path: Path, 
                                output_path: Path,
                                verbose: bool = False) -> Dict[str, Any]:
        """
        ãƒ­ãƒã‚¹ãƒˆå“è³ªä¿è¨¼ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡º
        
        Args:
            input_path: å…¥åŠ›ç”»åƒãƒ‘ã‚¹
            output_path: å‡ºåŠ›ãƒ‘ã‚¹
            verbose: è©³ç´°ãƒ­ã‚°å‡ºåŠ›
            
        Returns:
            æŠ½å‡ºçµæžœæƒ…å ±
        """
        logger.info(f"ãƒ­ãƒã‚¹ãƒˆæŠ½å‡ºé–‹å§‹: {input_path.name}")
        
        # åŸºæœ¬å‰å‡¦ç†
        processed_bgr, processed_rgb, scale = preprocess_image_pipeline(str(input_path))
        if processed_bgr is None:
            return {"success": False, "error": "preprocessing_failed"}
        
        # 3ã¤ã®æ‰‹æ³•ã§ä¸¦åˆ—å®Ÿè¡Œ
        methods = [
            ("enhanced_system", self._extract_enhanced_system),
            ("color_preserving", self._extract_color_preserving),
            ("backup_method", self._extract_backup_method)
        ]
        
        results = {}
        best_result = None
        best_quality = 0.0
        
        for method_name, method_func in methods:
            try:
                if verbose:
                    print(f"ðŸ”„ å®Ÿè¡Œä¸­: {method_name}")
                
                result = method_func(processed_bgr, processed_rgb, input_path, verbose)
                
                if result and result.get("success", False):
                    quality_score = self._evaluate_result_quality(result, processed_rgb)
                    result["quality_score"] = quality_score
                    result["method"] = method_name
                    
                    results[method_name] = result
                    
                    if verbose:
                        print(f"âœ… {method_name}: å“è³ªã‚¹ã‚³ã‚¢ {quality_score:.3f}")
                    
                    # æœ€é«˜å“è³ªçµæžœã‚’è¨˜éŒ²
                    if quality_score > best_quality:
                        best_quality = quality_score
                        best_result = result
                else:
                    if verbose:
                        print(f"âŒ {method_name}: å¤±æ•—")
                        
            except Exception as e:
                logger.warning(f"{method_name} å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
                if verbose:
                    print(f"âš ï¸ {method_name}: ã‚¨ãƒ©ãƒ¼ - {e}")
        
        # æœ€é©çµæžœã‚’ä¿å­˜
        if best_result:
            try:
                # æœ€é«˜å“è³ªã®çµæžœã‚’å‡ºåŠ›ãƒ‘ã‚¹ã«ä¿å­˜
                cv2.imwrite(str(output_path), best_result["image_bgr"])
                
                final_result = {
                    "success": True,
                    "method": best_result["method"],
                    "quality_score": best_quality,
                    "size": best_result.get("size", "unknown"),
                    "face_detected": best_result.get("face_detected", False),
                    "alternative_methods": len(results),
                    "total_attempts": len(methods)
                }
                
                if verbose:
                    print(f"ðŸŽ¯ æœ€é©æ‰‹æ³•: {best_result['method']} (å“è³ª: {best_quality:.3f})")
                
                # æˆåŠŸå±¥æ­´ã«è¨˜éŒ²
                self.success_history[input_path.name] = {
                    "method": best_result["method"],
                    "quality": best_quality
                }
                
                return final_result
                
            except Exception as e:
                logger.error(f"çµæžœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                return {"success": False, "error": f"save_failed: {e}"}
        
        else:
            # å…¨æ‰‹æ³•ãŒå¤±æ•—ã—ãŸå ´åˆ â†’ å¼·åˆ¶æŠ½å‡ºã‚’è©¦è¡Œ
            logger.warning(f"å…¨æ‰‹æ³•å¤±æ•—: {input_path.name} â†’ å¼·åˆ¶æŠ½å‡ºãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œ")
            
            # å¼·åˆ¶æŠ½å‡ºï¼šå“è³ªã‚’å•ã‚ãšä½•ã‚‰ã‹ã®å€™è£œã‚’æŠ½å‡º
            forced_result = self._force_extract_any_candidate(
                processed_bgr, processed_rgb, input_path, results, verbose
            )
            
            if forced_result and forced_result.get("success", False):
                logger.info(f"ðŸš€ å¼·åˆ¶æŠ½å‡ºæˆåŠŸ: {input_path.name}")
                
                # å¼·åˆ¶æŠ½å‡ºçµæžœã‚’æŒ‡å®šã•ã‚ŒãŸå‡ºåŠ›ãƒ‘ã‚¹ã«ä¿å­˜
                forced_output_path = input_path.parent / f"forced_{input_path.name}"
                if forced_output_path.exists():
                    try:
                        # å¼·åˆ¶æŠ½å‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šå‡ºåŠ›ãƒ‘ã‚¹ã«ã‚³ãƒ”ãƒ¼
                        import shutil
                        shutil.copy2(forced_output_path, output_path)
                        logger.info(f"ðŸ“‹ å¼·åˆ¶æŠ½å‡ºçµæžœã‚’å‡ºåŠ›ãƒ‘ã‚¹ã«ã‚³ãƒ”ãƒ¼: {output_path}")
                        
                        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                        forced_output_path.unlink()
                    except Exception as e:
                        logger.warning(f"å¼·åˆ¶æŠ½å‡ºãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•ã‚¨ãƒ©ãƒ¼: {e}")
                
                return forced_result
            else:
                logger.error(f"ðŸ’¥ å¼·åˆ¶æŠ½å‡ºã‚‚å¤±æ•—: {input_path.name}")
                return {
                    "success": False,
                    "error": "all_methods_and_forced_extraction_failed",
                    "attempted_methods": len(methods),
                    "results": {k: v.get("error", "unknown_error") for k, v in results.items()}
                }

    def _force_extract_any_candidate(self, 
                                    processed_bgr: np.ndarray,
                                    processed_rgb: np.ndarray, 
                                    input_path: Path,
                                    previous_results: Dict[str, Any],
                                    verbose: bool = False) -> Optional[Dict[str, Any]]:
        """
        å¼·åˆ¶æŠ½å‡ºï¼šå“è³ªã‚’å•ã‚ãšä½•ã‚‰ã‹ã®å€™è£œã‚’æŠ½å‡º
        """
        try:
            logger.info(f"ðŸš€ å¼·åˆ¶æŠ½å‡ºãƒ¢ãƒ¼ãƒ‰é–‹å§‹: {input_path.name}")
            
            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ç¢ºèª
            if get_sam_model() is None or get_yolo_model() is None:
                initialize_models()
            
            sam_model = get_sam_model()
            yolo_model = get_yolo_model()
            
            # SAMãƒžã‚¹ã‚¯ç”Ÿæˆï¼ˆå…¨å€™è£œï¼‰
            all_masks = sam_model.generate_masks(processed_bgr)
            if not all_masks:
                logger.warning(f"SAMãƒžã‚¹ã‚¯ç”Ÿæˆå¤±æ•—")
                return None
                
            logger.info(f"SAMå€™è£œæ•°: {len(all_masks)}")
            
            # æœ€ä½Žé™ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå¹ãå‡ºã—ãƒ»ãƒ†ã‚­ã‚¹ãƒˆã®ã¿é™¤å¤–ï¼‰
            from features.evaluation.utils.non_character_filter import apply_non_character_filter
            filtered_masks = apply_non_character_filter(all_masks, processed_rgb)
            
            # å¼·åˆ¶æŠ½å‡ºãƒ¢ãƒ¼ãƒ‰ï¼šãƒ•ã‚£ãƒ«ã‚¿ã§å…¨ã¦é™¤å¤–ã•ã‚Œã¦ã‚‚æœ€å¤§å€™è£œã‚’é¸æŠž
            if not filtered_masks:
                logger.warning(f"ãƒ•ã‚£ãƒ«ã‚¿å¾Œå€™è£œãªã— â†’ å¼·åˆ¶çš„ã«æœ€å¤§å€™è£œé¸æŠž")
                if all_masks:
                    filtered_masks = [max(all_masks, key=lambda x: np.sum(x.get('segmentation', np.zeros((1, 1))) > 0))]
                else:
                    return None
            
            logger.info(f"æœ€ä½Žé™ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(filtered_masks)}å€™è£œ")
            
            # æœ€å¤§ã®ãƒžã‚¹ã‚¯ã‚’é¸æŠžï¼ˆé¢ç©ãƒ™ãƒ¼ã‚¹å¼·åˆ¶é¸æŠžï¼‰
            best_candidate = max(filtered_masks, key=lambda x: np.sum(x.get('segmentation', np.zeros((1, 1))) > 0))
            
            if best_candidate is None:
                return None
            
            # æŠ½å‡ºå®Ÿè¡Œ
            mask = best_candidate.get('segmentation')
            if mask is None:
                return None
            
            # ãƒžã‚¹ã‚¯é©ç”¨ã—ã¦æŠ½å‡º
            extraction_result = self._apply_mask_and_extract(
                processed_rgb, mask, input_path.name
            )
            
            if extraction_result and extraction_result.get("extracted_rgb") is not None:
                # ä¿å­˜ï¼ˆå‡ºåŠ›ãƒ‘ã‚¹ã¯å‘¼ã³å‡ºã—å…ƒã§æŒ‡å®šã•ã‚ŒãŸå ´æ‰€ï¼‰
                extracted_rgb = extraction_result["extracted_rgb"]
                extracted_bgr = cv2.cvtColor(extracted_rgb, cv2.COLOR_RGB2BGR)
                cv2.imwrite(str(input_path.parent / f"forced_{input_path.name}"), extracted_bgr)
                
                logger.info(f"âœ… å¼·åˆ¶æŠ½å‡ºå®Œäº†: {input_path.parent / f'forced_{input_path.name}'}")
                
                return {
                    "success": True,
                    "method": "forced_extraction",
                    "quality_score": 0.1,  # ä½Žå“è³ªã ãŒæˆåŠŸ
                    "size": f"{extracted_rgb.shape[1]}x{extracted_rgb.shape[0]}",
                    "face_detected": False,
                    "forced": True,
                    "original_candidates": len(all_masks),
                    "filtered_candidates": len(filtered_masks)
                }
            
            return None
            
        except Exception as e:
            logger.error(f"å¼·åˆ¶æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None

    def _apply_mask_and_extract(self, 
                               image_rgb: np.ndarray, 
                               mask: np.ndarray, 
                               filename: str) -> Optional[Dict[str, Any]]:
        """
        ãƒžã‚¹ã‚¯ã‚’é©ç”¨ã—ã¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’æŠ½å‡º
        """
        try:
            # ãƒžã‚¹ã‚¯ã®æ­£è¦åŒ–
            if mask.max() > 1:
                mask = mask.astype(np.float32) / 255.0
            
            # 3ãƒãƒ£ãƒ³ãƒãƒ«ãƒžã‚¹ã‚¯ã«å¤‰æ›
            if len(mask.shape) == 2:
                mask_3d = np.stack([mask, mask, mask], axis=2)
            else:
                mask_3d = mask
            
            # ãƒžã‚¹ã‚¯é©ç”¨
            masked_image = image_rgb * mask_3d
            
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹è¨ˆç®—
            y_indices, x_indices = np.where(mask > 0.1)
            if len(y_indices) == 0 or len(x_indices) == 0:
                return None
            
            y_min, y_max = y_indices.min(), y_indices.max()
            x_min, x_max = x_indices.min(), x_indices.max()
            
            # ä½™ç™½è¿½åŠ 
            padding = 10
            h, w = image_rgb.shape[:2]
            y_min = max(0, y_min - padding)
            y_max = min(h, y_max + padding)
            x_min = max(0, x_min - padding)
            x_max = min(w, x_max + padding)
            
            # åˆ‡ã‚Šå‡ºã—
            cropped = masked_image[y_min:y_max, x_min:x_max]
            
            if cropped.size == 0:
                return None
            
            # uint8ã«å¤‰æ›
            cropped_uint8 = (cropped * 255).astype(np.uint8)
            
            return {
                "extracted_rgb": cropped_uint8,
                "bbox": (x_min, y_min, x_max - x_min, y_max - y_min),
                "mask_area": np.sum(mask > 0.1)
            }
            
        except Exception as e:
            logger.error(f"ãƒžã‚¹ã‚¯é©ç”¨ã‚¨ãƒ©ãƒ¼ {filename}: {e}")
            return None

    def _extract_enhanced_system(self, 
                               processed_bgr: np.ndarray,
                               processed_rgb: np.ndarray, 
                               input_path: Path,
                               verbose: bool = False) -> Optional[Dict[str, Any]]:
        """Enhanced Systemæ‰‹æ³•ã§ã®æŠ½å‡º"""
        try:
            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ç¢ºèª
            if get_sam_model() is None or get_yolo_model() is None:
                initialize_models()
            
            sam_model = get_sam_model()
            yolo_model = get_yolo_model()
            
            # SAMãƒžã‚¹ã‚¯ç”Ÿæˆ
            all_masks = sam_model.generate_masks(processed_bgr)
            if not all_masks:
                return {"success": False, "error": "no_masks_generated"}
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            character_masks = sam_model.filter_character_masks(all_masks)
            if not character_masks:
                return {"success": False, "error": "no_character_masks"}
            
            # YOLOæ¤œå‡ºã¨ã®çµ„ã¿åˆã‚ã›
            scored_masks = yolo_model.score_masks_with_detections(character_masks, processed_bgr)
            if not scored_masks:
                return {"success": False, "error": "no_scored_masks"}
            
            # Enhanced System ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            filtered_masks = apply_non_character_filter(scored_masks, processed_bgr)
            validated_masks = filter_non_character_masks(filtered_masks, processed_bgr)
            
            final_masks = validated_masks if validated_masks else filtered_masks
            
            if not final_masks:
                return {"success": False, "error": "no_final_masks"}
            
            # æœ€é©ãƒžã‚¹ã‚¯é¸æŠžï¼ˆfullbody_priorityï¼‰
            best_mask = self._select_best_mask_simple(final_masks, processed_bgr.shape, "fullbody_priority")
            
            if best_mask:
                # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡ºãƒ»ä¿å­˜
                extracted_image = self._extract_character_from_mask(processed_bgr, best_mask)
                cropped_image = self._crop_to_content(extracted_image)
                
                # å“è³ªæƒ…å ±
                has_face = self._detect_face_simple(cropped_image)
                size_info = f"{cropped_image.shape[1]}x{cropped_image.shape[0]}"
                
                return {
                    "success": True,
                    "image_bgr": cropped_image,
                    "size": size_info,
                    "face_detected": has_face,
                    "mask_count": len(final_masks)
                }
            
            return {"success": False, "error": "mask_selection_failed"}
            
        except Exception as e:
            return {"success": False, "error": f"enhanced_system_error: {e}"}

    def _extract_color_preserving(self, 
                                processed_bgr: np.ndarray,
                                processed_rgb: np.ndarray,
                                input_path: Path,
                                verbose: bool = False) -> Optional[Dict[str, Any]]:
        """è‰²èª¿ä¿æŒå¢ƒç•Œå¼·èª¿æ‰‹æ³•ã§ã®æŠ½å‡º"""
        try:
            # è‰²èª¿ä¿æŒå¢ƒç•Œå¼·èª¿
            enhanced_rgb, metrics = self.color_enhancer.enhance_image_boundaries(processed_rgb)
            enhanced_bgr = cv2.cvtColor(enhanced_rgb, cv2.COLOR_RGB2BGR)
            
            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ç¢ºèª
            if get_sam_model() is None or get_yolo_model() is None:
                initialize_models()
            
            sam_model = get_sam_model()
            yolo_model = get_yolo_model()
            
            # å¼·åŒ–ã•ã‚ŒãŸç”»åƒã§ãƒžã‚¹ã‚¯ç”Ÿæˆ
            all_masks = sam_model.generate_masks(enhanced_bgr)
            if not all_masks:
                return {"success": False, "error": "no_masks_generated"}
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            character_masks = sam_model.filter_character_masks(all_masks)
            if not character_masks:
                return {"success": False, "error": "no_character_masks"}
            
            # YOLOæ¤œå‡º
            scored_masks = yolo_model.score_masks_with_detections(character_masks, enhanced_bgr)
            if not scored_masks:
                return {"success": False, "error": "no_scored_masks"}
            
            # æœ€é©ãƒžã‚¹ã‚¯é¸æŠž
            best_mask = self._select_best_mask_simple(scored_masks, enhanced_bgr.shape, "balanced")
            
            if best_mask:
                # å…ƒã®ï¼ˆéžå¼·åŒ–ï¼‰ç”»åƒã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡ºï¼ˆè‰²èª¿ä¿æŒã®ãŸã‚ï¼‰
                extracted_image = self._extract_character_from_mask(processed_bgr, best_mask)
                cropped_image = self._crop_to_content(extracted_image)
                
                # å“è³ªæƒ…å ±
                has_face = self._detect_face_simple(cropped_image)
                size_info = f"{cropped_image.shape[1]}x{cropped_image.shape[0]}"
                
                return {
                    "success": True,
                    "image_bgr": cropped_image,
                    "size": size_info,
                    "face_detected": has_face,
                    "mask_count": len(scored_masks),
                    "color_quality": metrics.get("overall_quality", 0.5)
                }
            
            return {"success": False, "error": "mask_selection_failed"}
            
        except Exception as e:
            return {"success": False, "error": f"color_preserving_error: {e}"}

    def _extract_backup_method(self, 
                             processed_bgr: np.ndarray,
                             processed_rgb: np.ndarray,
                             input_path: Path,
                             verbose: bool = False) -> Optional[Dict[str, Any]]:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ‰‹æ³•ã§ã®æŠ½å‡º"""
        try:
            # ã‚ˆã‚Šä¿å®ˆçš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®å‡¦ç†
            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ç¢ºèª
            if get_sam_model() is None or get_yolo_model() is None:
                initialize_models()
            
            sam_model = get_sam_model()
            yolo_model = get_yolo_model()
            
            # åŸºæœ¬çš„ãªãƒžã‚¹ã‚¯ç”Ÿæˆï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å°‘ãªã‚ï¼‰
            all_masks = sam_model.generate_masks(processed_bgr)
            if not all_masks:
                return {"success": False, "error": "no_masks_generated"}
            
            # åŸºæœ¬çš„ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ã®ã¿
            character_masks = sam_model.filter_character_masks(all_masks)
            if not character_masks:
                return {"success": False, "error": "no_character_masks"}
            
            # YOLOæ¤œå‡º
            scored_masks = yolo_model.score_masks_with_detections(character_masks, processed_bgr)
            if not scored_masks:
                # YOLOã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°å¤±æ•—æ™‚ã¯å…ƒã®ãƒžã‚¹ã‚¯ã‚’ä½¿ç”¨
                scored_masks = character_masks
            
            # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒžã‚¹ã‚¯é¸æŠžï¼ˆé¢ç©å„ªå…ˆï¼‰
            best_mask = self._select_best_mask_simple(scored_masks, processed_bgr.shape, "size_priority")
            
            if best_mask:
                # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡º
                extracted_image = self._extract_character_from_mask(processed_bgr, best_mask)
                cropped_image = self._crop_to_content(extracted_image)
                
                # å“è³ªæƒ…å ±
                has_face = self._detect_face_simple(cropped_image)
                size_info = f"{cropped_image.shape[1]}x{cropped_image.shape[0]}"
                
                return {
                    "success": True,
                    "image_bgr": cropped_image,
                    "size": size_info,
                    "face_detected": has_face,
                    "mask_count": len(scored_masks)
                }
            
            return {"success": False, "error": "mask_selection_failed"}
            
        except Exception as e:
            return {"success": False, "error": f"backup_method_error: {e}"}

    def _select_best_mask_simple(self, masks: List[Any], image_shape: Tuple, method: str) -> Optional[Any]:
        """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒžã‚¹ã‚¯é¸æŠž"""
        if not masks:
            return None
        
        height, width = image_shape[:2]
        
        best_mask = None
        best_score = -1.0
        
        for mask in masks:
            if hasattr(mask, 'mask') and hasattr(mask, 'composite_score'):
                mask_area = np.sum(mask.mask > 0) / (width * height)
                
                if method == "size_priority":
                    score = mask_area * 0.7 + mask.composite_score * 0.3
                elif method == "fullbody_priority":
                    score = mask.composite_score
                else:  # balanced
                    score = mask_area * 0.4 + mask.composite_score * 0.6
                
                if score > best_score:
                    best_score = score
                    best_mask = mask
        
        return best_mask

    def _extract_character_from_mask(self, image: np.ndarray, mask_obj: Any) -> np.ndarray:
        """ãƒžã‚¹ã‚¯ã‹ã‚‰ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’æŠ½å‡º"""
        if hasattr(mask_obj, 'mask'):
            mask = mask_obj.mask
        else:
            mask = mask_obj
        
        # ãƒžã‚¹ã‚¯ãŒ2æ¬¡å…ƒã§ãªã„å ´åˆã¯å¤‰æ›
        if len(mask.shape) == 3:
            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
        
        # ãƒžã‚¹ã‚¯ã‚’æ­£è¦åŒ–
        if mask.max() > 1:
            mask = (mask > 0).astype(np.uint8) * 255
        else:
            mask = (mask * 255).astype(np.uint8)
        
        # ãƒžã‚¹ã‚¯ã‚’3ãƒãƒ£ãƒ³ãƒãƒ«ã«å¤‰æ›
        mask_3ch = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
        mask_normalized = mask_3ch.astype(np.float32) / 255.0
        
        # èƒŒæ™¯ã‚’é»’ã«è¨­å®š
        background = np.zeros_like(image, dtype=np.uint8)
        
        # ãƒžã‚¹ã‚¯é©ç”¨
        result = (image.astype(np.float32) * mask_normalized + 
                 background.astype(np.float32) * (1.0 - mask_normalized))
        
        return result.astype(np.uint8)

    def _crop_to_content(self, image: np.ndarray, padding: int = 10) -> np.ndarray:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„éƒ¨åˆ†ã®ã¿ã«ã‚¯ãƒ­ãƒƒãƒ—"""
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # éžã‚¼ãƒ­ãƒ”ã‚¯ã‚»ãƒ«ã®å¢ƒç•Œã‚’æ¤œå‡º
        rows = np.any(gray > 0, axis=1)
        cols = np.any(gray > 0, axis=0)
        
        if not np.any(rows) or not np.any(cols):
            return image
        
        rmin, rmax = np.where(rows)[0][[0, -1]]
        cmin, cmax = np.where(cols)[0][[0, -1]]
        
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¿½åŠ 
        rmin = max(0, rmin - padding)
        rmax = min(image.shape[0] - 1, rmax + padding)
        cmin = max(0, cmin - padding)
        cmax = min(image.shape[1] - 1, cmax + padding)
        
        return image[rmin:rmax+1, cmin:cmax+1]

    def _detect_face_simple(self, image: np.ndarray) -> bool:
        """ç°¡æ˜“é¡”æ¤œå‡º"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            faces = face_cascade.detectMultiScale(gray, 1.1, 4)
            return len(faces) > 0
        except:
            return False

    def _evaluate_result_quality(self, result: Dict[str, Any], original_image: np.ndarray) -> float:
        """çµæžœã®å“è³ªã‚’è©•ä¾¡"""
        if not result.get("success", False):
            return 0.0
        
        base_score = 0.5
        
        # é¡”æ¤œå‡ºãƒœãƒ¼ãƒŠã‚¹
        if result.get("face_detected", False):
            base_score += 0.3
        
        # ã‚µã‚¤ã‚ºå“è³ª
        size_str = result.get("size", "0x0")
        try:
            w, h = map(int, size_str.split('x'))
            size_score = min(1.0, (w * h) / 50000)  # 50000ãƒ”ã‚¯ã‚»ãƒ«ã‚’åŸºæº–
            base_score += size_score * 0.2
        except:
            pass
        
        # è‰²èª¿å“è³ªï¼ˆè‰²èª¿ä¿æŒæ‰‹æ³•ã®ã¿ï¼‰
        if "color_quality" in result:
            base_score += result["color_quality"] * 0.1
        
        # ãƒžã‚¹ã‚¯æ•°ã«ã‚ˆã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆå¤šã™ãŽã‚‹ã¨ä¸å®‰å®šï¼‰
        mask_count = result.get("mask_count", 0)
        if mask_count > 100:
            base_score *= 0.9
        elif mask_count < 5:
            base_score *= 0.95
        
        return min(1.0, base_score)


def test_robust_extractor():
    """ãƒ­ãƒã‚¹ãƒˆæŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    extractor = RobustCharacterExtractor()
    
    # ãƒ†ã‚¹ãƒˆç”»åƒ
    test_images = [
        "kana08_0001.jpg",  # å‰å›žFè©•ä¾¡
        "kana08_0003.jpg",  # å‰å›žAè©•ä¾¡
        "kana08_0000_cover.jpg"  # è…•ã®ã¿æŠ½å‡ºå•é¡Œ
    ]
    
    input_dir = Path("/mnt/c/AItools/lora/train/yado/org/kana08")
    output_dir = Path("/tmp/robust_test")
    output_dir.mkdir(exist_ok=True)
    
    print("ðŸš€ ãƒ­ãƒã‚¹ãƒˆæŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆ")
    
    for filename in test_images:
        input_path = input_dir / filename
        output_path = output_dir / filename
        
        if input_path.exists():
            print(f"\nðŸ“¸ ãƒ†ã‚¹ãƒˆ: {filename}")
            result = extractor.extract_character_robust(input_path, output_path, verbose=True)
            
            if result["success"]:
                print(f"âœ… æˆåŠŸ: {result}")
            else:
                print(f"âŒ å¤±æ•—: {result}")
        else:
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨: {filename}")


if __name__ == "__main__":
    test_robust_extractor()