#!/usr/bin/env python3
"""
SAM + YOLOv8 æ¼«ç”»ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ‡ã‚Šå‡ºã—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ v0.0.1

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€Segment Anything Model (SAM) ã¨ YOLOv8 ã‚’çµ„ã¿åˆã‚ã›ã¦
æ¼«ç”»ç”»åƒã‹ã‚‰ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’è‡ªå‹•çš„ã«åˆ‡ã‚Šå‡ºã™ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚

ã€æ–°æ©Ÿèƒ½ v0.0.1ã€‘
- å®Œå…¨è‡ªå‹•æŠ½å‡ºãƒ¢ãƒ¼ãƒ‰ï¼ˆreproduce-autoï¼‰
- ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºãƒ»é™¤å»æ©Ÿèƒ½
- ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
- èƒŒæ™¯é™¤å»ãƒ»é»’çµ±ä¸€å‡¦ç†
- ä¸ŠåŠèº«ä¸­å¿ƒæŠ½å‡ºæ©Ÿèƒ½

ä½¿ç”¨ä¾‹:
    # å†ç¾ãƒ¢ãƒ¼ãƒ‰ï¼šæ‰‹å‹•æŠ½å‡ºã‚’è‡ªå‹•å†ç¾
    python sam_yolo_character_segment.py --mode reproduce-auto --input_dir ./org/ --output_dir ./auto_extracted/
    
    # å¯¾è©±å½¢å¼ï¼š1æšã®ç”»åƒã‚’ç¢ºèªã—ãªãŒã‚‰æœ€é©åŒ–
    python sam_yolo_character_segment.py --mode interactive --input image.jpg
    
    # ãƒãƒƒãƒå½¢å¼ï¼šè‡ªå‹•ã§è¤‡æ•°æšã‚’ä¸€æ°—ã«å‡¦ç†
    python sam_yolo_character_segment.py --mode batch --input_dir ./manga_images/ --output_dir ./results/
"""

import os
import sys
import argparse
import cv2
import numpy as np
import torch
from pathlib import Path
from typing import List, Tuple, Optional
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import time
import glob
import urllib.request
import psutil
import gc

# SAMé–¢é€£ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator
from segment_anything.utils.amg import batched_mask_to_box

# YOLOv8é–¢é€£ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ultralytics import YOLO

# OCRãƒ»ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºé–¢é€£ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import easyocr
    EASYOCR_AVAILABLE = True
except ImportError:
    EASYOCR_AVAILABLE = False
    print("Warning: EasyOCR not available. Text detection will be disabled.")

# èƒŒæ™¯é™¤å»é–¢é€£ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from rembg import remove, new_session
    REMBG_AVAILABLE = True
except ImportError:
    REMBG_AVAILABLE = False
    print("Warning: rembg not available. Background removal will use mask-based method.")


class PerformanceMonitor:
    """
    å‡¦ç†ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç›£è¦–ã™ã‚‹ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self):
        self.start_time = None
        self.stage_times = {}
        self.memory_usage = {}
        self.current_stage = None
        
    def start_monitoring(self):
        """ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°é–‹å§‹"""
        self.start_time = time.time()
        self.log_system_info()
        
    def start_stage(self, stage_name: str):
        """å‡¦ç†æ®µéšã®é–‹å§‹"""
        if self.current_stage:
            self.end_stage()
        
        self.current_stage = stage_name
        self.stage_times[stage_name] = time.time()
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¨˜éŒ²
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        gpu_memory = self.get_gpu_memory() if torch.cuda.is_available() else 0
        
        print(f"ğŸ”„ é–‹å§‹: {stage_name} (RAM: {memory_mb:.1f}MB, GPU: {gpu_memory:.1f}MB)")
        
    def end_stage(self):
        """å‡¦ç†æ®µéšã®çµ‚äº†"""
        if not self.current_stage:
            return
            
        elapsed = time.time() - self.stage_times[self.current_stage]
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¨˜éŒ²
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        gpu_memory = self.get_gpu_memory() if torch.cuda.is_available() else 0
        
        print(f"âœ… å®Œäº†: {self.current_stage} ({elapsed:.2f}ç§’, RAM: {memory_mb:.1f}MB, GPU: {gpu_memory:.1f}MB)")
        
        self.stage_times[self.current_stage] = elapsed
        self.current_stage = None
        
        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    def get_gpu_memory(self):
        """GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—"""
        try:
            if torch.cuda.is_available():
                return torch.cuda.memory_allocated() / 1024 / 1024
            return 0
        except:
            return 0
    
    def log_system_info(self):
        """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›"""
        print("=== ã‚·ã‚¹ãƒ†ãƒ æƒ…å ± ===")
        print(f"CPU: {psutil.cpu_count()} ã‚³ã‚¢")
        print(f"RAM: {psutil.virtual_memory().total / 1024 / 1024 / 1024:.1f}GB")
        if torch.cuda.is_available():
            print(f"GPU: {torch.cuda.get_device_name()}")
            print(f"GPU RAM: {torch.cuda.get_device_properties(0).total_memory / 1024 / 1024 / 1024:.1f}GB")
        print("=" * 20)
    
    def print_summary(self):
        """å‡¦ç†æ™‚é–“ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›"""
        if not self.start_time:
            return
            
        total_time = time.time() - self.start_time
        
        print("\n=== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ã‚µãƒãƒªãƒ¼ ===")
        print(f"ç·å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")
        
        for stage, duration in self.stage_times.items():
            if isinstance(duration, float):
                percentage = (duration / total_time) * 100
                print(f"  {stage}: {duration:.2f}ç§’ ({percentage:.1f}%)")
        print("=" * 30)


def setup_japanese_font():
    """
    matplotlibç”¨ã®æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è¨­å®š
    """
    try:
        # Windowsç’°å¢ƒã§ã®æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆå€™è£œ
        font_candidates = [
            'Yu Gothic UI',
            'Meiryo',
            'MS Gothic',
            'Hiragino Sans',
            'Noto Sans CJK JP',
            'DejaVu Sans'  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        ]
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚©ãƒ³ãƒˆã‚’æ¤œç´¢
        available_fonts = [font.name for font in fm.fontManager.ttflist]
        
        selected_font = None
        for font_name in font_candidates:
            if font_name in available_fonts:
                selected_font = font_name
                break
        
        if selected_font:
            plt.rcParams['font.family'] = selected_font
            print(f"âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šå®Œäº†: {selected_font}")
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: Unicodeå¯¾å¿œ
            plt.rcParams['font.family'] = 'DejaVu Sans'
            plt.rcParams['axes.unicode_minus'] = False
            print("âš ï¸ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è‹±èªè¡¨ç¤ºã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
            
    except Exception as e:
        print(f"âš ï¸ ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        # æœ€å°é™ã®è¨­å®š
        plt.rcParams['axes.unicode_minus'] = False


class TextDetector:
    """
    ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºãƒ»é™¤å»ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self):
        if EASYOCR_AVAILABLE:
            try:
                self.reader = easyocr.Reader(['ja', 'en'], gpu=torch.cuda.is_available())
                print("âœ… EasyOCRåˆæœŸåŒ–å®Œäº†")
            except Exception as e:
                print(f"âš ï¸ EasyOCRåˆæœŸåŒ–å¤±æ•—: {e}")
                self.reader = None
        else:
            self.reader = None
    
    def detect_text_regions(self, image: np.ndarray) -> List[np.ndarray]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’æ¤œå‡ºã—ã¦ãƒã‚¹ã‚¯ã‚’è¿”ã™
        
        Args:
            image: å…¥åŠ›ç”»åƒ
            
        Returns:
            ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã®ãƒã‚¹ã‚¯ãƒªã‚¹ãƒˆ
        """
        if not self.reader:
            return []
        
        try:
            results = self.reader.readtext(image)
            text_masks = []
            
            for (bbox, text, confidence) in results:
                if confidence > 0.5:  # ä¿¡é ¼åº¦é–¾å€¤
                    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‹ã‚‰ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆ
                    mask = np.zeros(image.shape[:2], dtype=np.uint8)
                    points = np.array(bbox, dtype=np.int32)
                    cv2.fillPoly(mask, [points], 255)
                    text_masks.append(mask)
            
            return text_masks
        except Exception as e:
            print(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def has_significant_text(self, image: np.ndarray, threshold: float = 0.1) -> bool:
        """
        ç”»åƒã«é‡è¦ãªãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        
        Args:
            image: å…¥åŠ›ç”»åƒ
            threshold: ãƒ†ã‚­ã‚¹ãƒˆé¢ç©ã®é–¾å€¤ï¼ˆç”»åƒå…¨ä½“ã«å¯¾ã™ã‚‹å‰²åˆï¼‰
            
        Returns:
            é‡è¦ãªãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹
        """
        text_masks = self.detect_text_regions(image)
        if not text_masks:
            return False
        
        # ãƒ†ã‚­ã‚¹ãƒˆé¢ç©ã®åˆè¨ˆã‚’è¨ˆç®—
        total_text_area = sum(np.sum(mask > 0) for mask in text_masks)
        image_area = image.shape[0] * image.shape[1]
        text_ratio = total_text_area / image_area
        
        return text_ratio > threshold


class BackgroundRemover:
    """
    èƒŒæ™¯é™¤å»ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self):
        if REMBG_AVAILABLE:
            try:
                self.session = new_session('u2net')
                print("âœ… rembgåˆæœŸåŒ–å®Œäº†")
            except Exception as e:
                print(f"âš ï¸ rembgåˆæœŸåŒ–å¤±æ•—: {e}")
                self.session = None
        else:
            self.session = None
    
    def remove_background(self, image: np.ndarray, mask: Optional[np.ndarray] = None) -> np.ndarray:
        """
        èƒŒæ™¯ã‚’é™¤å»ã—ã¦é»’èƒŒæ™¯ã«çµ±ä¸€
        
        Args:
            image: å…¥åŠ›ç”»åƒ
            mask: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼šå‰æ™¯ãƒã‚¹ã‚¯
            
        Returns:
            èƒŒæ™¯é™¤å»å¾Œã®ç”»åƒ
        """
        if self.session and mask is None:
            # rembgã‚’ä½¿ç”¨ã—ãŸèƒŒæ™¯é™¤å»
            try:
                from PIL import Image
                pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
                result = remove(pil_image, session=self.session)
                result_array = np.array(result)
                
                # ã‚¢ãƒ«ãƒ•ã‚¡ãƒãƒ£ãƒ³ãƒãƒ«ã‚’ä½¿ç”¨ã—ã¦é»’èƒŒæ™¯ã«åˆæˆ
                if result_array.shape[2] == 4:  # RGBA
                    alpha = result_array[:, :, 3:4] / 255.0
                    rgb = result_array[:, :, :3]
                    # é»’èƒŒæ™¯ã«åˆæˆ
                    black_bg = np.zeros_like(rgb)
                    result_bgr = rgb * alpha + black_bg * (1 - alpha)
                    return cv2.cvtColor(result_bgr.astype(np.uint8), cv2.COLOR_RGB2BGR)
                else:
                    return cv2.cvtColor(result_array, cv2.COLOR_RGB2BGR)
            except Exception as e:
                print(f"âš ï¸ rembgèƒŒæ™¯é™¤å»å¤±æ•—: {e}")
        
        # ãƒã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹ã®èƒŒæ™¯é™¤å»
        if mask is not None:
            result = image.copy()
            result[mask == 0] = [0, 0, 0]  # ãƒã‚¹ã‚¯å¤–ã‚’é»’ã«
            return result
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå…ƒç”»åƒã‚’ãã®ã¾ã¾è¿”ã™
        return image


class CharacterQualityEvaluator:
    """
    ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å“è³ªè©•ä¾¡ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self):
        pass
    
    def evaluate_character_quality(self, image: np.ndarray, mask: np.ndarray, bbox: Tuple[int, int, int, int]) -> float:
        """
        ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡ºã®å“è³ªã‚’è©•ä¾¡
        
        Args:
            image: å…ƒç”»åƒ
            mask: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒã‚¹ã‚¯
            bbox: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ (x, y, w, h)
            
        Returns:
            å“è³ªã‚¹ã‚³ã‚¢ (0.0-1.0)
        """
        score = 0.0
        
        # 1. ã‚µã‚¤ã‚ºè©•ä¾¡ï¼ˆé©åˆ‡ãªã‚µã‚¤ã‚ºã‹ï¼‰v4æ”¹è‰¯ç‰ˆ
        x, y, w, h = bbox
        image_area = image.shape[0] * image.shape[1]
        bbox_area = w * h
        size_ratio = bbox_area / image_area
        
        # 110.jpgå¯¾ç­–ï¼šãƒšãƒ¼ã‚¸å…¨ä½“ã‚’å–ã‚‰ãªã„ã‚ˆã†å³æ ¼åŒ–
        if size_ratio > 0.85:  # 85%ä»¥ä¸Šã¯æ˜ã‚‰ã‹ã«å…¨ä½“å–å¾—
            score -= 0.5  # å¤§å¹…æ¸›ç‚¹
        elif size_ratio > 0.7:  # 70%ä»¥ä¸Šã‚‚æ¸›ç‚¹
            score -= 0.3
        elif 0.1 <= size_ratio <= 0.6:  # ç†æƒ³çš„ãªç¯„å›²ã‚’ç‹­ã‚ã‚‹
            score += 0.3
        elif 0.05 <= size_ratio <= 0.7:
            score += 0.2
        elif size_ratio < 0.02:  # éå¸¸ã«å°ã•ã™ãã‚‹å ´åˆã‚‚æ¸›ç‚¹
            score -= 0.1
        
        # 2. ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”è©•ä¾¡ï¼ˆäººç‰©ã‚‰ã—ã„ã‹ï¼‰
        aspect_ratio = h / w if w > 0 else 0
        # ç¸¦é•·ï¼ˆ1.2-3.0ï¼‰ãŒäººç‰©ã‚‰ã—ã„
        if 1.2 <= aspect_ratio <= 3.0:
            score += 0.2
        elif 1.0 <= aspect_ratio <= 3.5:
            score += 0.1
        
        # 3. ä½ç½®è©•ä¾¡ï¼ˆç”»åƒã®ä¸­å¤®ä»˜è¿‘ã«ã‚ã‚‹ã‹ï¼‰
        center_x, center_y = x + w/2, y + h/2
        img_center_x, img_center_y = image.shape[1]/2, image.shape[0]/2
        center_distance = np.sqrt((center_x - img_center_x)**2 + (center_y - img_center_y)**2)
        max_distance = np.sqrt(img_center_x**2 + img_center_y**2)
        center_score = 1.0 - (center_distance / max_distance)
        score += center_score * 0.2
        
        # 4. ãƒã‚¹ã‚¯å“è³ªè©•ä¾¡ï¼ˆé€£ç¶šæ€§ã€å½¢çŠ¶ï¼‰
        mask_area = np.sum(mask > 0)
        if mask_area > 0:
            # ãƒã‚¹ã‚¯ã®é€£ç¶šæ€§ï¼ˆç©´ã®å°‘ãªã•ï¼‰
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if len(contours) == 1:  # å˜ä¸€ã®é€£ç¶šé ˜åŸŸ
                score += 0.2
            elif len(contours) <= 3:  # å°‘æ•°ã®é ˜åŸŸ
                score += 0.1
        
        # 5. é¡”é ˜åŸŸã®æ¤œå‡ºï¼ˆä¸ŠåŠèº«ã‚‰ã—ã•ï¼‰
        upper_mask = mask[:mask.shape[0]//2, :]  # ä¸ŠåŠåˆ†
        upper_area = np.sum(upper_mask > 0)
        total_area = np.sum(mask > 0)
        if total_area > 0:
            upper_ratio = upper_area / total_area
            if upper_ratio >= 0.3:  # ä¸ŠåŠèº«ãŒãƒ¡ã‚¤ãƒ³
                score += 0.1
        
        # 6. ã‚·ãƒ«ã‚¨ãƒƒãƒˆæ¤œå‡ºï¼ˆé»’ã„é ˜åŸŸã®ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
        silhouette_penalty = self._detect_silhouette(image, mask, bbox)
        score -= silhouette_penalty * 0.4  # ã‚·ãƒ«ã‚¨ãƒƒãƒˆã¯ã‚¹ã‚³ã‚¢ã‚’å¤§å¹…ã«ä¸‹ã’ã‚‹
        
        # 7. ãƒ†ã‚­ã‚¹ãƒˆå¯†åº¦æ¤œå‡ºï¼ˆ110.jpgå¯¾ç­–ï¼‰
        text_density = self._detect_text_density(image, mask, bbox)
        score -= text_density * 0.3  # ãƒ†ã‚­ã‚¹ãƒˆãŒå¤šã„å ´åˆã¯æ¸›ç‚¹
        
        return min(max(score, 0.0), 1.0)  # 0.0-1.0ã«åˆ¶é™
    
    def _detect_silhouette(self, image: np.ndarray, mask: np.ndarray, bbox: Tuple[int, int, int, int]) -> float:
        """
        ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚’æ¤œå‡ºã—ã¦ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’è¿”ã™
        
        Args:
            image: å…ƒç”»åƒ
            mask: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒã‚¹ã‚¯
            bbox: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
            
        Returns:
            ã‚·ãƒ«ã‚¨ãƒƒãƒˆãƒšãƒŠãƒ«ãƒ†ã‚£ (0.0-1.0)
        """
        try:
            x, y, w, h = bbox
            
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹é ˜åŸŸã‚’å–å¾—
            bbox_region = image[y:y+h, x:x+w]
            bbox_mask = mask[y:y+h, x:x+w]
            
            if bbox_region.shape[0] == 0 or bbox_region.shape[1] == 0:
                return 1.0  # ç„¡åŠ¹ãªé ˜åŸŸ
            
            # ãƒã‚¹ã‚¯é ˜åŸŸã®ã¿ã‚’æŠ½å‡º
            masked_region = cv2.bitwise_and(bbox_region, bbox_region, mask=bbox_mask)
            
            # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
            gray = cv2.cvtColor(masked_region, cv2.COLOR_BGR2GRAY)
            
            # ãƒã‚¹ã‚¯é ˜åŸŸã®ãƒ”ã‚¯ã‚»ãƒ«ã‚’å–å¾—
            valid_pixels = gray[bbox_mask > 0]
            
            if len(valid_pixels) == 0:
                return 1.0
            
            # é»’ã„ãƒ”ã‚¯ã‚»ãƒ«ã®å‰²åˆã‚’è¨ˆç®—
            dark_pixels = np.sum(valid_pixels < 40)  # é—¾å€¤: 40
            dark_ratio = dark_pixels / len(valid_pixels)
            
            # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã®è¨ˆç®—
            contrast = np.std(valid_pixels) / 255.0
            
            # å¹³å‡è¼åº¦ã®è¨ˆç®—
            mean_brightness = np.mean(valid_pixels) / 255.0
            
            # ã‚·ãƒ«ã‚¨ãƒƒãƒˆã®ç‰¹å¾´
            # 1. é»’ã„ãƒ”ã‚¯ã‚»ãƒ«ãŒå¤šã„ (60%ä»¥ä¸Š)
            # 2. ä½ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ (0.1æœªæº€)
            # 3. ä½å¹³å‡è¼åº¦ (0.2æœªæº€)
            silhouette_score = 0.0
            
            if dark_ratio > 0.6:  # 60%ä»¥ä¸ŠãŒé»’ã„
                silhouette_score += 0.5
            elif dark_ratio > 0.4:  # 40%ä»¥ä¸ŠãŒé»’ã„
                silhouette_score += 0.3
            
            if contrast < 0.1:  # ä½ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ
                silhouette_score += 0.3
            
            if mean_brightness < 0.2:  # ä½è¼åº¦
                silhouette_score += 0.2
            
            return min(1.0, max(0.0, silhouette_score))
            
        except Exception as e:
            print(f"âš ï¸ ã‚·ãƒ«ã‚¨ãƒƒãƒˆæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def _detect_text_density(self, image: np.ndarray, mask: np.ndarray, bbox: Tuple[int, int, int, int]) -> float:
        """
        ãƒ†ã‚­ã‚¹ãƒˆå¯†åº¦ã‚’æ¤œå‡ºã—ã¦ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’è¿”ã™ï¼ˆ110.jpgå¯¾ç­–ï¼‰
        
        Args:
            image: å…ƒç”»åƒ
            mask: ãƒã‚¹ã‚¯
            bbox: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ (x, y, w, h)
            
        Returns:
            ãƒ†ã‚­ã‚¹ãƒˆå¯†åº¦ãƒšãƒŠãƒ«ãƒ†ã‚£ (0.0-1.0)
        """
        try:
            x, y, w, h = bbox
            
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹é ˜åŸŸã‚’å–å¾—
            bbox_region = image[y:y+h, x:x+w]
            bbox_mask = mask[y:y+h, x:x+w]
            
            if bbox_region.shape[0] == 0 or bbox_region.shape[1] == 0:
                return 0.0
            
            # ãƒã‚¹ã‚¯é ˜åŸŸã®ã¿ã‚’æŠ½å‡º
            masked_region = cv2.bitwise_and(bbox_region, bbox_region, mask=bbox_mask)
            
            # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
            gray = cv2.cvtColor(masked_region, cv2.COLOR_BGR2GRAY)
            
            # ã‚¨ãƒƒã‚¸æ¤œå‡ºã§ãƒ†ã‚­ã‚¹ãƒˆã‚‰ã—ã„é ˜åŸŸã‚’æ¤œå‡º
            edges = cv2.Canny(gray, 50, 150)
            
            # æ°´å¹³ãƒ»å‚ç›´æ–¹å‘ã®ã‚¨ãƒƒã‚¸ã®æ¤œå‡º
            horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 1))
            vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 9))
            
            horizontal_edges = cv2.morphologyEx(edges, cv2.MORPH_OPEN, horizontal_kernel)
            vertical_edges = cv2.morphologyEx(edges, cv2.MORPH_OPEN, vertical_kernel)
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚‰ã—ã„ç‰¹å¾´ã®æ¤œå‡º
            text_features = cv2.bitwise_or(horizontal_edges, vertical_edges)
            
            # ãƒã‚¹ã‚¯é ˜åŸŸã§ã®ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´å¯†åº¦
            masked_text = cv2.bitwise_and(text_features, text_features, mask=bbox_mask)
            text_pixel_count = np.sum(masked_text > 0)
            mask_pixel_count = np.sum(bbox_mask > 0)
            
            if mask_pixel_count == 0:
                return 0.0
            
            text_density = text_pixel_count / mask_pixel_count
            
            # é«˜ã„å¯†åº¦ã®å ´åˆã¯ãƒšãƒŠãƒ«ãƒ†ã‚£
            if text_density > 0.15:  # 15%ä»¥ä¸ŠãŒãƒ†ã‚­ã‚¹ãƒˆã‚‰ã—ã„
                return 0.8
            elif text_density > 0.1:  # 10%ä»¥ä¸Š
                return 0.6
            elif text_density > 0.05:  # 5%ä»¥ä¸Š
                return 0.3
            
            return 0.0
            
        except Exception as e:
            print(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆå¯†åº¦æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0


def is_color_image(image: np.ndarray, threshold: float = 0.01) -> bool:
    """
    ç”»åƒãŒã‚«ãƒ©ãƒ¼ç”»åƒã‹ã©ã†ã‹ã‚’åˆ¤å®š
    
    Args:
        image: å…¥åŠ›ç”»åƒ (BGR/RGB)
        threshold: ã‚«ãƒ©ãƒ¼åˆ¤å®šã®é–¾å€¤
        
    Returns:
        True if ã‚«ãƒ©ãƒ¼ç”»åƒ, False if ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒ
    """
    if len(image.shape) != 3 or image.shape[2] != 3:
        return False
    
    # RGBãƒãƒ£ãƒ³ãƒãƒ«é–“ã®å·®åˆ†ã‚’è¨ˆç®—
    r, g, b = cv2.split(image)
    
    # å„ãƒãƒ£ãƒ³ãƒãƒ«é–“ã®æ¨™æº–åå·®ã‚’è¨ˆç®—
    diff_rg = np.std(r.astype(np.float32) - g.astype(np.float32))
    diff_rb = np.std(r.astype(np.float32) - b.astype(np.float32))
    diff_gb = np.std(g.astype(np.float32) - b.astype(np.float32))
    
    # ã„ãšã‚Œã‹ã®ãƒãƒ£ãƒ³ãƒãƒ«é–“å·®åˆ†ãŒé–¾å€¤ã‚’è¶…ãˆã‚Œã°ã‚«ãƒ©ãƒ¼ç”»åƒ
    max_diff = max(diff_rg, diff_rb, diff_gb)
    is_color = max_diff > threshold
    
    print(f"ã‚«ãƒ©ãƒ¼åˆ¤å®š: æœ€å¤§ãƒãƒ£ãƒ³ãƒãƒ«å·®åˆ†={max_diff:.3f}, é–¾å€¤={threshold}, çµæœ={'ã‚«ãƒ©ãƒ¼' if is_color else 'ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«'}")
    
    return is_color


def download_anime_yolo_model():
    """
    ã‚¢ãƒ‹ãƒ¡å°‚ç”¨YOLOãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    """
    anime_model_url = "https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt"
    anime_model_path = "yolov8n-anime.pt"
    
    if not os.path.exists(anime_model_path):
        try:
            print("ğŸŒ ã‚¢ãƒ‹ãƒ¡å°‚ç”¨YOLOãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            urllib.request.urlretrieve(anime_model_url, anime_model_path)
            print(f"âœ… ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {anime_model_path}")
            return anime_model_path
        except Exception as e:
            print(f"âŒ ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
            return None
    else:
        print(f"âœ… ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ‡ãƒ«æ—¢å­˜: {anime_model_path}")
        return anime_model_path


def cleanup_old_preview_images(preview_dir: str, days_old: int = 7):
    """
    æŒ‡å®šã—ãŸæ—¥æ•°ã‚ˆã‚Šå¤ã„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã‚’å‰Šé™¤
    
    Args:
        preview_dir: ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        days_old: å‰Šé™¤å¯¾è±¡ã®çµŒéæ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 7æ—¥ï¼‰
    """
    if not os.path.exists(preview_dir):
        return
        
    current_time = time.time()
    cutoff_time = current_time - (days_old * 24 * 60 * 60)  # æŒ‡å®šæ—¥æ•°å‰ã®ç§’æ•°
    
    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
    patterns = [
        os.path.join(preview_dir, "choice_preview_*.jpg"),
        os.path.join(preview_dir, "choice_preview_*.jpeg"),
        os.path.join(preview_dir, "choice_preview_*.png")
    ]
    
    deleted_count = 0
    for pattern in patterns:
        for file_path in glob.glob(pattern):
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆæ—¥æ™‚ã‚’ãƒã‚§ãƒƒã‚¯
                file_mtime = os.path.getmtime(file_path)
                if file_mtime < cutoff_time:
                    os.remove(file_path)
                    deleted_count += 1
                    print(f"å¤ã„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã‚’å‰Šé™¤: {file_path}")
            except Exception as e:
                print(f"ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
    
    if deleted_count > 0:
        print(f"åˆè¨ˆ {deleted_count} å€‹ã®å¤ã„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
    else:
        print("å‰Šé™¤å¯¾è±¡ã®å¤ã„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


class ClickHandler:
    """
    matplotlibã§ã®ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹
    å³ã‚¯ãƒªãƒƒã‚¯ã§ã®è¤‡æ•°é¸æŠæ©Ÿèƒ½ã‚’è¿½åŠ 
    """
    
    def __init__(self, masks, image_shape, display_shape):
        self.masks = masks  # ãƒã‚¹ã‚¯ã®ãƒªã‚¹ãƒˆ
        self.image_shape = image_shape  # å…ƒç”»åƒã®ã‚µã‚¤ã‚º (height, width)
        self.display_shape = display_shape  # è¡¨ç¤ºç”»åƒã®ã‚µã‚¤ã‚º (height, width)
        self.clicked_point = None
        self.selected_mask_idx = None
        self.selected_masks = []  # è¤‡æ•°é¸æŠã•ã‚ŒãŸãƒã‚¹ã‚¯ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        self.is_multi_select = False  # è¤‡æ•°é¸æŠãƒ¢ãƒ¼ãƒ‰ãƒ•ãƒ©ã‚°
        self.figure = None
        self.ax = None
        
    def on_click(self, event):
        """
        ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        å·¦ã‚¯ãƒªãƒƒã‚¯: å˜ä¸€é¸æŠã¾ãŸã¯ç¢ºå®š
        å³ã‚¯ãƒªãƒƒã‚¯: è¤‡æ•°é¸æŠãƒ¢ãƒ¼ãƒ‰
        """
        if event.inaxes is None:
            # ãƒã‚¹ã‚¯å¤–ã‚¯ãƒªãƒƒã‚¯ã§ç¢ºå®š
            if self.is_multi_select and self.selected_masks:
                print(f"ãƒã‚¹ã‚¯å¤–ã‚¯ãƒªãƒƒã‚¯ã§ç¢ºå®š: {len(self.selected_masks)}å€‹ã®ãƒã‚¹ã‚¯ã‚’çµåˆ")
                plt.close()
            return
            
        # ã‚¯ãƒªãƒƒã‚¯åº§æ¨™ã‚’å–å¾—
        x, y = event.xdata, event.ydata
        if x is None or y is None:
            return
            
        self.clicked_point = (x, y)
        
        # è¡¨ç¤ºåº§æ¨™ã‚’å…ƒç”»åƒåº§æ¨™ã«å¤‰æ›
        orig_x = int(x * self.image_shape[1] / self.display_shape[1])
        orig_y = int(y * self.image_shape[0] / self.display_shape[0])
        
        # åº§æ¨™å¤‰æ›ã®ã‚ºãƒ¬ã‚’è¨ˆç®—
        scale_x = self.image_shape[1] / self.display_shape[1]
        scale_y = self.image_shape[0] / self.display_shape[0]
        
        # ã‚ºãƒ¬ãŒå¤§ãã„å ´åˆã¯è­¦å‘Š
        if abs(scale_x - scale_y) > 0.1:
            print(f"è­¦å‘Š: åº§æ¨™å¤‰æ›ã§ã‚ºãƒ¬ãŒç™ºç”Ÿã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ (scale_x: {scale_x:.3f}, scale_y: {scale_y:.3f})")
        
        # å¢ƒç•Œãƒã‚§ãƒƒã‚¯
        orig_x = max(0, min(orig_x, self.image_shape[1] - 1))
        orig_y = max(0, min(orig_y, self.image_shape[0] - 1))
        
        # ã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸãƒã‚¹ã‚¯ã‚’åˆ¤å®š
        clicked_mask_idx = self._determine_mask(orig_x, orig_y)
        
        if clicked_mask_idx is None:
            print(f"ã‚¯ãƒªãƒƒã‚¯åº§æ¨™({orig_x}, {orig_y})ã«ãƒã‚¹ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“")
            return
            
        print(f"ã‚¯ãƒªãƒƒã‚¯åº§æ¨™: è¡¨ç¤º({x:.1f}, {y:.1f}) -> å…ƒç”»åƒ({orig_x}, {orig_y}) -> ãƒã‚¹ã‚¯{clicked_mask_idx}")
        
        # ãƒœã‚¿ãƒ³ã«ã‚ˆã‚‹å‡¦ç†åˆ†å²
        if event.button == 1:  # å·¦ã‚¯ãƒªãƒƒã‚¯
            if self.is_multi_select:
                # ãƒãƒ«ãƒã‚»ãƒ¬ã‚¯ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã®å·¦ã‚¯ãƒªãƒƒã‚¯ã¯ç¢ºå®š
                if self.selected_masks:
                    print(f"å·¦ã‚¯ãƒªãƒƒã‚¯ã§ç¢ºå®š: {len(self.selected_masks)}å€‹ã®ãƒã‚¹ã‚¯ã‚’çµåˆ")
                    plt.close()
                else:
                    print("é¸æŠã•ã‚ŒãŸãƒã‚¹ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“")
            else:
                # å˜ä¸€é¸æŠãƒ¢ãƒ¼ãƒ‰
                self.selected_mask_idx = clicked_mask_idx
                print(f"å·¦ã‚¯ãƒªãƒƒã‚¯ã§ãƒã‚¹ã‚¯{clicked_mask_idx}ã‚’é¸æŠ")
                plt.close()
                
        elif event.button == 3:  # å³ã‚¯ãƒªãƒƒã‚¯
            self.is_multi_select = True
            if clicked_mask_idx in self.selected_masks:
                # æ—¢ã«é¸æŠã•ã‚Œã¦ã„ã‚‹ãƒã‚¹ã‚¯ã‚’å³ã‚¯ãƒªãƒƒã‚¯ã—ãŸå ´åˆã¯é¸æŠè§£é™¤
                self.selected_masks.remove(clicked_mask_idx)
                print(f"å³ã‚¯ãƒªãƒƒã‚¯ã§ãƒã‚¹ã‚¯{clicked_mask_idx}ã‚’é¸æŠè§£é™¤ (é¸æŠä¸­: {self.selected_masks})")
            else:
                # æ–°ã—ã„ãƒã‚¹ã‚¯ã‚’è¿½åŠ 
                self.selected_masks.append(clicked_mask_idx)
                print(f"å³ã‚¯ãƒªãƒƒã‚¯ã§ãƒã‚¹ã‚¯{clicked_mask_idx}ã‚’è¿½åŠ  (é¸æŠä¸­: {self.selected_masks})")
                
            # è¡¨ç¤ºã‚’æ›´æ–°ã—ã¦é¸æŠçŠ¶æ…‹ã‚’åæ˜ 
            self._update_display()
        
    def _determine_mask(self, x, y):
        """
        ã‚¯ãƒªãƒƒã‚¯ä½ç½®ã§ã®ãƒã‚¹ã‚¯ã‚’åˆ¤å®š
        """
        candidate_masks = []
        
        # ã‚¯ãƒªãƒƒã‚¯ä½ç½®ã«è©²å½“ã™ã‚‹ãƒã‚¹ã‚¯ã‚’æ¢ã™
        for i, mask_data in enumerate(self.masks):
            mask = mask_data['segmentation']
            if y < mask.shape[0] and x < mask.shape[1] and mask[y, x]:
                # ãƒã‚¹ã‚¯ã®ãƒ”ã‚¯ã‚»ãƒ«æ•°ã‚’è¨ˆç®—
                pixel_count = np.sum(mask)
                candidate_masks.append((i, pixel_count))
        
        if not candidate_masks:
            print("ã‚¨ãƒ©ãƒ¼: ã‚¯ãƒªãƒƒã‚¯ä½ç½®ã«ãƒã‚¹ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚‚ã†ä¸€åº¦ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
            return None
        
        # ãƒ”ã‚¯ã‚»ãƒ«æ•°ãŒæœ€å¤§ã®ãƒã‚¹ã‚¯ã‚’é¸æŠ
        selected_idx, max_pixels = max(candidate_masks, key=lambda x: x[1])
        
        print(f"é¸æŠã•ã‚ŒãŸãƒã‚¹ã‚¯: {selected_idx} (ãƒ”ã‚¯ã‚»ãƒ«æ•°: {max_pixels})")
        if len(candidate_masks) > 1:
            print(f"é‡è¤‡ãƒã‚¹ã‚¯æ•°: {len(candidate_masks)}, æœ€å¤§ãƒ”ã‚¯ã‚»ãƒ«æ•°ã§é¸æŠ")
        
        return selected_idx
    
    def _update_display(self):
        """
        é¸æŠã•ã‚ŒãŸãƒã‚¹ã‚¯ã®è¡¨ç¤ºã‚’æ›´æ–°ï¼ˆå¢ƒç•Œç·šã‚’å¤ªãã™ã‚‹ï¼‰
        """
        if not self.figure or not self.ax:
            return
            
        # æ—¢å­˜ã®å¢ƒç•Œç·šã‚’å‰Šé™¤
        for artist in self.ax.get_children():
            if hasattr(artist, 'get_label'):
                label = artist.get_label()
                if label and isinstance(label, str) and label.startswith('selected_'):
                    artist.remove()
        
        # é¸æŠã•ã‚ŒãŸãƒã‚¹ã‚¯ã«å¤ªã„å¢ƒç•Œç·šã‚’è¿½åŠ 
        colors = [
            (1.0, 0.0, 0.0),   # èµ¤
            (0.0, 1.0, 0.0),   # ç·‘
            (0.0, 0.0, 1.0),   # é’
            (1.0, 1.0, 0.0),   # é»„
            (1.0, 0.0, 1.0),   # ãƒã‚¼ãƒ³ã‚¿
            (0.0, 1.0, 1.0),   # ã‚·ã‚¢ãƒ³
            (1.0, 0.5, 0.0),   # ã‚ªãƒ¬ãƒ³ã‚¸
            (0.5, 0.0, 1.0),   # ç´«
            (0.0, 0.5, 0.0),   # æ¿ƒã„ç·‘
            (0.5, 0.5, 0.5)    # ã‚°ãƒ¬ãƒ¼
        ]
        
        for mask_idx in self.selected_masks:
            if mask_idx < len(self.masks):
                mask = self.masks[mask_idx]['segmentation']
                
                # ãƒã‚¹ã‚¯ã®å¢ƒç•Œç·šã‚’æŠ½å‡º
                import cv2
                # è¡¨ç¤ºã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
                resized_mask = cv2.resize(mask.astype(np.uint8), 
                                        (self.display_shape[1], self.display_shape[0]))
                
                # å¢ƒç•Œç·šã‚’è¦‹ã¤ã‘ã‚‹
                contours, _ = cv2.findContours(resized_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                # å¢ƒç•Œç·šã‚’æç”»
                for contour in contours:
                    contour = contour.squeeze()
                    if len(contour.shape) == 2 and contour.shape[0] > 2:
                        color = colors[mask_idx % len(colors)]
                        self.ax.plot(contour[:, 0], contour[:, 1], 
                                   color=color, linewidth=4, alpha=0.8,
                                   label=f'selected_{mask_idx}')
        
        # è¡¨ç¤ºã‚’æ›´æ–°
        self.figure.canvas.draw()
        
    def merge_selected_masks(self):
        """
        é¸æŠã•ã‚ŒãŸãƒã‚¹ã‚¯ã‚’è«–ç†å’Œï¼ˆORï¼‰ã§ãƒãƒ¼ã‚¸
        """
        if not self.selected_masks:
            return None
            
        # æœ€åˆã®ãƒã‚¹ã‚¯ã‚’åŸºæº–ã«ã™ã‚‹
        first_mask = self.masks[self.selected_masks[0]]['segmentation']
        merged_mask = first_mask.copy()
        
        # ä»–ã®ãƒã‚¹ã‚¯ã‚’è«–ç†å’Œã§çµåˆ
        for mask_idx in self.selected_masks[1:]:
            mask = self.masks[mask_idx]['segmentation']
            merged_mask = np.logical_or(merged_mask, mask)
        
        return merged_mask


class SAMYOLOCharacterSegmentor:
    """
    SAMã¨YOLOv8ã‚’çµ„ã¿åˆã‚ã›ãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ‡ã‚Šå‡ºã—ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, 
                 sam_checkpoint: str = "sam_vit_h_4b8939.pth",
                 model_type: str = "vit_h",
                 yolo_model: str = "yolov8n.pt",
                 score_threshold: float = 0.15,
                 device: Optional[str] = None,
                 use_anime_yolo: bool = False):
        """
        åˆæœŸåŒ–
        
        Args:
            sam_checkpoint: SAMã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            model_type: SAMãƒ¢ãƒ‡ãƒ«ã®ç¨®é¡ï¼ˆvit_h, vit_l, vit_bï¼‰
            yolo_model: YOLOv8ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            score_threshold: YOLOäººç‰©æ¤œå‡ºã‚¹ã‚³ã‚¢ã®é–¾å€¤
            device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹ï¼ˆcuda/cpuï¼‰
        """
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.score_threshold = score_threshold
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
        self.monitor = PerformanceMonitor()
        
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
        setup_japanese_font()
        
        # æ–°æ©Ÿèƒ½ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.text_detector = TextDetector()
        self.bg_remover = BackgroundRemover()
        self.quality_evaluator = CharacterQualityEvaluator()
        
        # ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€ã‚ˆã‚Šä½ã„é–¾å€¤ã‚’ä½¿ç”¨
        if use_anime_yolo:
            self.score_threshold = max(0.05, score_threshold * 0.7)  # é–¾å€¤ã‚’30%ä¸‹ã’ã‚‹
            print(f"ğŸŒ ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ¼ãƒ‰: ã‚¹ã‚³ã‚¢é–¾å€¤ã‚’ {score_threshold} â†’ {self.score_threshold} ã«èª¿æ•´")
        
        # SAMåˆæœŸåŒ–
        self.monitor.start_stage("SAMãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿")
        print(f"SAMãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­... ({model_type})")
        self.sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
        self.sam.to(device=self.device)
        self.monitor.end_stage()
        
        # SAMè‡ªå‹•ãƒã‚¹ã‚¯ç”Ÿæˆå™¨ï¼ˆäººç‰©å…¨ä½“ã‚’ã‚«ãƒãƒ¼ã™ã‚‹ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ï¼‰
        self.mask_generator = SamAutomaticMaskGenerator(
            model=self.sam,
            points_per_side=12,  # 32â†’12: é©åº¦ã«å¤§ããªé ˜åŸŸã‚’ç”Ÿæˆ
            pred_iou_thresh=0.6, # 0.88â†’0.6: ç¨‹ã‚ˆãç·©ã„é–¾å€¤
            stability_score_thresh=0.7, # 0.95â†’0.7: ç¨‹ã‚ˆãç·©ã„å®‰å®šæ€§
            crop_n_layers=0,     # ã‚¯ãƒ­ãƒƒãƒ—å‡¦ç†ã‚’ç„¡åŠ¹åŒ–
            crop_n_points_downscale_factor=1,
            min_mask_region_area=3000,  # 100â†’3000: é©åº¦ãªæœ€å°é ˜åŸŸ
            box_nms_thresh=0.6,  # é©åº¦ãªNMSé–¾å€¤
        )
        
        # YOLOv8åˆæœŸåŒ–
        self.monitor.start_stage("YOLOãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿")
        self.use_anime_yolo = use_anime_yolo
        
        if use_anime_yolo:
            # ã‚¢ãƒ‹ãƒ¡ãƒ»ãƒãƒ³ã‚¬å°‚ç”¨ãƒ¢ãƒ‡ãƒ«ã‚’è©¦è¡Œ
            anime_models = [
                # å®Ÿéš›ã«åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«
                "yolov8x.pt",  # ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«ã§ã‚¢ãƒ‹ãƒ¡æ¤œå‡ºç²¾åº¦å‘ä¸Š
                "yolov8l.pt",  # å¤§å‹ãƒ¢ãƒ‡ãƒ«
                "yolov8m.pt",  # ä¸­å‹ãƒ¢ãƒ‡ãƒ«
                yolo_model     # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨æ¨™æº–ãƒ¢ãƒ‡ãƒ«
            ]
            
            print("ğŸŒ ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ¼ãƒ‰: ã‚ˆã‚Šå¤§ããªYOLOãƒ¢ãƒ‡ãƒ«ã§æ¤œå‡ºç²¾åº¦å‘ä¸Šã‚’è©¦è¡Œã—ã¾ã™")
            
            model_loaded = False
            for anime_model in anime_models:
                try:
                    print(f"ã‚¢ãƒ‹ãƒ¡ç”¨YOLOãƒ¢ãƒ‡ãƒ«ã‚’è©¦è¡Œä¸­... ({anime_model})")
                    self.yolo = YOLO(anime_model)
                    self.current_yolo_model = anime_model
                    model_loaded = True
                    print(f"âœ… ã‚¢ãƒ‹ãƒ¡ç”¨YOLOãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿å®Œäº†: {anime_model}")
                    break
                except Exception as e:
                    print(f"âŒ {anime_model} ã®èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
                    continue
            
            if not model_loaded:
                print(f"âš ï¸ ã‚¢ãƒ‹ãƒ¡ç”¨ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¨™æº–ãƒ¢ãƒ‡ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {yolo_model}")
                self.yolo = YOLO(yolo_model)
                self.current_yolo_model = yolo_model
        else:
            print(f"YOLOv8ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­... ({yolo_model})")
            self.yolo = YOLO(yolo_model)
            self.current_yolo_model = yolo_model
        
        print(f"ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
        self.monitor.end_stage()
    
    def generate_masks(self, image: np.ndarray) -> List[dict]:
        """
        SAMã‚’ä½¿ç”¨ã—ã¦ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆ
        
        Args:
            image: å…¥åŠ›ç”»åƒ (RGB)
            
        Returns:
            ãƒã‚¹ã‚¯ã®ãƒªã‚¹ãƒˆ
        """
        self.monitor.start_stage("SAMãƒã‚¹ã‚¯ç”Ÿæˆ")
        print("SAMã§ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆä¸­...")
        masks = self.mask_generator.generate(image)
        print(f"ç”Ÿæˆã•ã‚ŒãŸãƒã‚¹ã‚¯æ•°: {len(masks)}")
        
        # ãƒã‚¹ã‚¯ã‚µã‚¤ã‚ºã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        if masks:
            mask_areas = [np.sum(mask['segmentation']) for mask in masks]
            print(f"ãƒã‚¹ã‚¯é¢ç©çµ±è¨ˆ: æœ€å°={min(mask_areas)}, æœ€å¤§={max(mask_areas)}, å¹³å‡={int(np.mean(mask_areas))}")
        
        self.monitor.end_stage()
        return masks
    
    def filter_masks_with_yolo(self, image: np.ndarray, masks: List[dict]) -> List[Tuple[dict, float]]:
        """
        YOLOv8ã‚’ä½¿ç”¨ã—ã¦ãƒã‚¹ã‚¯ã‚’äººç‰©æ¤œå‡ºã‚¹ã‚³ã‚¢ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        
        Args:
            image: å…¥åŠ›ç”»åƒ (RGB)
            masks: SAMã§ç”Ÿæˆã•ã‚ŒãŸãƒã‚¹ã‚¯
            
        Returns:
            (ãƒã‚¹ã‚¯, äººç‰©ã‚¹ã‚³ã‚¢)ã®ã‚¿ãƒ—ãƒ«ãƒªã‚¹ãƒˆ
        """
        self.monitor.start_stage("YOLOäººç‰©æ¤œå‡ºãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
        print("YOLOv8ã§äººç‰©æ¤œå‡ºã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ä¸­...")
        
        mask_scores = []
        
        print(f"YOLOv8ã§{len(masks)}å€‹ã®ãƒã‚¹ã‚¯ã‚’è©•ä¾¡é–‹å§‹...")
        
        for i, mask_data in enumerate(masks):
            try:
                mask = mask_data['segmentation']
                bbox = mask_data['bbox']  # x, y, w, h
                
                # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®åº§æ¨™ã‚’å–å¾—
                x, y, w, h = bbox
                x1, y1, x2, y2 = int(x), int(y), int(x + w), int(y + h)
                
                # ç”»åƒã®å¢ƒç•Œãƒã‚§ãƒƒã‚¯
                x1 = max(0, x1)
                y1 = max(0, y1)
                x2 = min(image.shape[1], x2)
                y2 = min(image.shape[0], y2)
                
                # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹å†…ã®ç”»åƒã‚’åˆ‡ã‚Šå‡ºã—
                cropped_image = image[y1:y2, x1:x2]
                
                if cropped_image.size == 0:
                    mask_scores.append((mask_data, 0.0))
                    continue
                    
                # YOLOv8ã§äººç‰©æ¤œå‡ºï¼ˆã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€ã‚ˆã‚Šç·©ã„è¨­å®šï¼‰
                if self.use_anime_yolo:
                    # ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ¼ãƒ‰: ã‚ˆã‚Šå¤šãã®å€™è£œã‚’æ¤œå‡º
                    results = self.yolo(cropped_image, verbose=False, conf=0.01, iou=0.7)
                else:
                    # æ¨™æº–ãƒ¢ãƒ¼ãƒ‰
                    results = self.yolo(cropped_image, verbose=False)
                
                # äººç‰©ã‚¯ãƒ©ã‚¹ã®æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’å–å¾—ï¼ˆã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ‡ãƒ«å¯¾å¿œï¼‰
                person_score = 0.0
                for result in results:
                    if result.boxes is not None:
                        boxes = result.boxes
                        for box in boxes:
                            class_id = int(box.cls)
                            
                            # æ¨™æº–YOLOã®äººç‰©ã‚¯ãƒ©ã‚¹ï¼ˆ0ï¼‰ã¾ãŸã¯ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ‡ãƒ«ã®æ–‡å­—ã‚¯ãƒ©ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
                            if self.use_anime_yolo:
                                # ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€ã‚ˆã‚Šå¤šãã®ã‚¯ãƒ©ã‚¹ã‚’äººç‰©ã¨ã—ã¦èªè­˜
                                if class_id in [0, 1, 2, 3]:  # person, character, face, body ãªã©
                                    person_score = max(person_score, float(box.conf))
                            else:
                                # æ¨™æº–ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€person ã‚¯ãƒ©ã‚¹ã®ã¿
                                if class_id == 0:  # person class
                                    person_score = max(person_score, float(box.conf))
                
                mask_scores.append((mask_data, person_score))
                
                if (i + 1) % 10 == 0:
                    print(f"YOLOå‡¦ç†æ¸ˆã¿: {i + 1}/{len(masks)} (ç¾åœ¨ã®ã‚¹ã‚³ã‚¢: {person_score:.3f})")
                    
            except Exception as e:
                print(f"âš ï¸ ãƒã‚¹ã‚¯{i}ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
                mask_scores.append((mask_data, 0.0))
                continue
        
        # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
        mask_scores.sort(key=lambda x: x[1], reverse=True)
        
        # é–¾å€¤ä»¥ä¸Šã®ãƒã‚¹ã‚¯ã®ã¿è¿”ã™
        filtered_masks = [(mask, score) for mask, score in mask_scores if score >= self.score_threshold]
        
        print(f"äººç‰©æ¤œå‡ºã‚¹ã‚³ã‚¢ >= {self.score_threshold} ã®ãƒã‚¹ã‚¯æ•°: {len(filtered_masks)}")
        
        # ã‚¹ã‚³ã‚¢åˆ†å¸ƒã‚’è¡¨ç¤º
        if mask_scores:
            all_scores = [score for _, score in mask_scores]
            print(f"YOLOæ¤œå‡ºã‚¹ã‚³ã‚¢çµ±è¨ˆ: æœ€é«˜={max(all_scores):.3f}, æœ€ä½={min(all_scores):.3f}, å¹³å‡={np.mean(all_scores):.3f}")
            
            # ä¸Šä½10å€‹ã®ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º
            top_scores = sorted(all_scores, reverse=True)[:10]
            print(f"ä¸Šä½10ã‚¹ã‚³ã‚¢: {[f'{s:.3f}' for s in top_scores]}")
            
            # ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚‚è¡¨ç¤º
            if self.use_anime_yolo:
                print(f"ğŸŒ ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ¼ãƒ‰ä½¿ç”¨ä¸­: {self.current_yolo_model}")
        
        self.monitor.end_stage()
        return filtered_masks
    
    def extract_character(self, image: np.ndarray, mask: np.ndarray) -> np.ndarray:
        """
        ãƒã‚¹ã‚¯ã‚’ä½¿ç”¨ã—ã¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’åˆ‡ã‚Šå‡ºã—
        
        Args:
            image: å…¥åŠ›ç”»åƒ (RGB)
            mask: ãƒã‚¹ã‚¯
            
        Returns:
            ãƒã‚¹ã‚¯ã•ã‚ŒãŸç”»åƒ
        """
        masked_image = image.copy()
        masked_image[~mask] = 0  # ãƒã‚¹ã‚¯å¤–ã‚’é»’ã«ã™ã‚‹
        return masked_image
    
    def process_single_image(self, image_path: str, output_dir: str, interactive: bool = False, mask_choice: int = None) -> str:
        """
        å˜ä¸€ç”»åƒã‚’å‡¦ç†
        
        Args:
            image_path: å…¥åŠ›ç”»åƒãƒ‘ã‚¹
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            interactive: å¯¾è©±ãƒ¢ãƒ¼ãƒ‰
            mask_choice: æ‰‹å‹•ã§ãƒã‚¹ã‚¯ç•ªå·ã‚’æŒ‡å®š (0-4)
            
        Returns:
            å‡¦ç†çµæœ ("success", "skip", "error")
        """
        try:
            # ç”»åƒèª­ã¿è¾¼ã¿
            image = cv2.imread(image_path)
            if image is None:
                print(f"ã‚¨ãƒ©ãƒ¼: ç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ - {image_path}")
                return "error"
            
            # ã‚«ãƒ©ãƒ¼ç”»åƒãƒã‚§ãƒƒã‚¯
            if is_color_image(image, threshold=10.0):  # é–¾å€¤ã‚’é«˜ã‚ã«è¨­å®šã—ã¦ã‚«ãƒ©ãƒ¼ç”»åƒã‚’ç¢ºå®Ÿã«æ¤œå‡º
                print(f"ã‚¹ã‚­ãƒƒãƒ—: ã‚«ãƒ©ãƒ¼ç”»åƒã®ãŸã‚å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ - {image_path}")
                return "skip"
            
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # ãƒã‚¹ã‚¯ç”Ÿæˆ
            masks = self.generate_masks(image)
            
            if not masks:
                print(f"ã‚¹ã‚­ãƒƒãƒ—: ãƒã‚¹ã‚¯ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ - {image_path}")
                return "skip"
            
            # YOLO ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            filtered_masks = self.filter_masks_with_yolo(image, masks)
            
            if not filtered_masks:
                print(f"ã‚¹ã‚­ãƒƒãƒ—: äººç‰©æ¤œå‡ºã‚¹ã‚³ã‚¢ãŒé–¾å€¤ä»¥ä¸Šã®ãƒã‚¹ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ - {image_path}")
                return "skip"
            
            # çµæœã®å‡¦ç†
            if interactive:
                return self._process_interactive(image, filtered_masks, image_path, output_dir, mask_choice)
            else:
                return self._process_automatic(image, filtered_masks, image_path, output_dir)
                
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {image_path} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ - {str(e)}")
            return "error"
    
    def process_choice_mode(self, input_dir: str, output_dir: str) -> None:
        """
        choiceãƒ¢ãƒ¼ãƒ‰ã§ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ç”»åƒã‚’å‡¦ç†
        
        Args:
            input_dir: å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.monitor.start_monitoring()
        self.monitor.start_stage("åˆæœŸåŒ–ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢")
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«å–å¾—
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        image_files = []
        
        input_path = Path(input_dir)
        for ext in image_extensions:
            image_files.extend(input_path.rglob(f"*{ext}"))
            image_files.extend(input_path.rglob(f"*{ext.upper()}"))
        
        # é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å»
        image_files = list(set(image_files))
        image_files.sort()  # ãƒ•ã‚¡ã‚¤ãƒ«åã§ã‚½ãƒ¼ãƒˆã—ã¦å‡¦ç†é †åºã‚’ä¸€å®šã«ã™ã‚‹
        
        if not image_files:
            print(f"ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_dir}")
            return
        
        print(f"å‡¦ç†å¯¾è±¡ç”»åƒæ•°: {len(image_files)} (é‡è¤‡é™¤å»å¾Œ)")
        self.monitor.end_stage()
        
        # ãƒãƒƒãƒå‡¦ç†
        self.monitor.start_stage("ç”»åƒãƒãƒƒãƒå‡¦ç†")
        success_count = 0
        skip_count = 0
        error_count = 0
        
        for i, image_file in enumerate(image_files):
            image_start_time = time.time()
            print(f"\né€²æ—: {i+1}/{len(image_files)} - {image_file.relative_to(input_path)}")
            
            try:
                # ç”»åƒèª­ã¿è¾¼ã¿
                image = cv2.imread(str(image_file))
                if image is None:
                    print(f"ã‚¨ãƒ©ãƒ¼: ç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ - {image_file}")
                    error_count += 1
                    continue
                
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                load_time = time.time() - image_start_time
                print(f"  ğŸ“‚ ç”»åƒèª­ã¿è¾¼ã¿: {load_time:.2f}ç§’")
                
                # ãƒã‚¹ã‚¯ç”Ÿæˆ
                masks = self.generate_masks(image)
                
                if not masks:
                    print(f"ã‚¹ã‚­ãƒƒãƒ—: ãƒã‚¹ã‚¯ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ - {image_file}")
                    skip_count += 1
                    continue
                
                # YOLO ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                filtered_masks = self.filter_masks_with_yolo(image, masks)
                
                if not filtered_masks:
                    print(f"ã‚¹ã‚­ãƒƒãƒ—: äººç‰©æ¤œå‡ºã‚¹ã‚³ã‚¢ãŒé–¾å€¤ä»¥ä¸Šã®ãƒã‚¹ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ - {image_file}")
                    skip_count += 1
                    continue
                
                # ç›¸å¯¾ãƒ‘ã‚¹ã‚’è¨ˆç®—ã—ã¦å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä¿æŒ
                relative_path = image_file.relative_to(input_path)
                output_subdir = Path(output_dir) / relative_path.parent
                
                # choiceãƒ¢ãƒ¼ãƒ‰ã§å‡¦ç†
                choice_start = time.time()
                result = self._process_choice_mode(image, filtered_masks, str(image_file), str(output_subdir))
                choice_time = time.time() - choice_start
                
                total_image_time = time.time() - image_start_time
                print(f"  ğŸ¯ é¸æŠå‡¦ç†: {choice_time:.2f}ç§’, ç”»åƒåˆè¨ˆ: {total_image_time:.2f}ç§’")
                
                if result == "success":
                    success_count += 1
                elif result == "skip":
                    skip_count += 1
                else:
                    error_count += 1
                    
            except KeyboardInterrupt:
                print("\nå‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
                break
            except Exception as e:
                print(f"ã‚¨ãƒ©ãƒ¼: {image_file} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ - {str(e)}")
                error_count += 1
        
        self.monitor.end_stage()
        
        print(f"\nå‡¦ç†å®Œäº†: {success_count}/{len(image_files)} æšæˆåŠŸ, {skip_count} æšã‚¹ã‚­ãƒƒãƒ—, {error_count} æšã‚¨ãƒ©ãƒ¼")
        
        # matplotlib ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        try:
            plt.close('all')  # å…¨ã¦ã®å›³ã‚’é–‰ã˜ã‚‹
            print("âœ… GUI ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"âš ï¸ GUI ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        self.monitor.print_summary()
    
    def _process_interactive(self, image: np.ndarray, filtered_masks: List[Tuple[dict, float]], 
                           image_path: str, output_dir: str, mask_choice: int = None) -> str:
        """
        å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã§ã®å‡¦ç†
        """
        print(f"\n=== å¯¾è©±ãƒ¢ãƒ¼ãƒ‰: {os.path.basename(image_path)} ===")
        
        # ä¸Šä½5ã¤ã®ãƒã‚¹ã‚¯ã‚’è¡¨ç¤º
        top_masks = filtered_masks[:5]
        
        if len(top_masks) == 0:
            print("è¡¨ç¤ºã™ã‚‹ãƒã‚¹ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“")
            return "skip"
        
        # ãƒã‚¹ã‚¯ã‚’è¡¨ç¤º
        fig, axes = plt.subplots(1, min(len(top_masks), 5), figsize=(15, 3))
        if len(top_masks) == 1:
            axes = [axes]
        
        for i, (mask_data, score) in enumerate(top_masks):
            mask = mask_data['segmentation']
            masked_image = self.extract_character(image, mask)
            
            ax = axes[i] if len(top_masks) > 1 else axes[0]
            ax.imshow(masked_image)
            ax.set_title(f"Mask {i}: Score {score:.3f}")
            ax.axis('off')
        
        plt.tight_layout()
        
        # å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã§ã¯è¡¨ç¤ºã‚’ç„¡åŠ¹åŒ–ï¼ˆWSLã§ã¯è¡¨ç¤ºã§ããªã„ï¼‰
        # plt.show()
        
        # ä»£ã‚ã‚Šã«ç”»åƒã‚’ä¿å­˜ã—ã¦ç¢ºèªç”¨ã«å‡ºåŠ›
        preview_path = os.path.join(os.path.dirname(image_path), "preview_masks.png")
        plt.savefig(preview_path, bbox_inches='tight', dpi=150)
        plt.close()
        print(f"ãƒã‚¹ã‚¯ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {preview_path}")
        
        # ãƒã‚¹ã‚¯ã®é¸æŠ
        if mask_choice is not None:
            # æ‰‹å‹•ã§ãƒã‚¹ã‚¯ç•ªå·ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆ
            if 0 <= mask_choice < len(top_masks):
                selected_mask_data, selected_score = top_masks[mask_choice]
                selected_mask = selected_mask_data['segmentation']
                
                # ä¿å­˜
                output_path = self._save_result(image, selected_mask, image_path, output_dir)
                print(f"ä¿å­˜å®Œäº†: {output_path} (ãƒã‚¹ã‚¯{mask_choice}é¸æŠã€ã‚¹ã‚³ã‚¢: {selected_score:.3f})")
                return "success"
            else:
                print(f"ã‚¨ãƒ©ãƒ¼: ãƒã‚¹ã‚¯ç•ªå·{mask_choice}ãŒç¯„å›²å¤–ã§ã™ (0-{len(top_masks)-1})")
                return "error"
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼é¸æŠï¼ˆWSLã§ã¯è‡ªå‹•çš„ã«æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’é¸æŠï¼‰
        if os.environ.get('WSL_DISTRO_NAME') or not sys.stdin.isatty():
            # WSLç’°å¢ƒã¾ãŸã¯éå¯¾è©±ç’°å¢ƒã§ã¯è‡ªå‹•é¸æŠ
            print("WSLç’°å¢ƒã¾ãŸã¯éå¯¾è©±ç’°å¢ƒã®ãŸã‚ã€æœ€é«˜ã‚¹ã‚³ã‚¢ã®ãƒã‚¹ã‚¯ã‚’è‡ªå‹•é¸æŠã—ã¾ã™")
            selected_mask_data, selected_score = top_masks[0]
            selected_mask = selected_mask_data['segmentation']
            
            # ä¿å­˜
            output_path = self._save_result(image, selected_mask, image_path, output_dir)
            print(f"ä¿å­˜å®Œäº†: {output_path} (ã‚¹ã‚³ã‚¢: {selected_score:.3f})")
            return "success"
        
        # é€šå¸¸ã®å¯¾è©±ãƒ¢ãƒ¼ãƒ‰
        while True:
            try:
                choice = input(f"é¸æŠã™ã‚‹ãƒã‚¹ã‚¯ç•ªå· (0-{len(top_masks)-1}), 's'ã§ã‚¹ã‚­ãƒƒãƒ—, 'q'ã§çµ‚äº†: ")
                
                if choice.lower() == 's':
                    print("ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")
                    return "skip"
                elif choice.lower() == 'q':
                    print("å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™")
                    return "quit"
                
                mask_idx = int(choice)
                if 0 <= mask_idx < len(top_masks):
                    selected_mask_data, selected_score = top_masks[mask_idx]
                    selected_mask = selected_mask_data['segmentation']
                    
                    # ä¿å­˜
                    output_path = self._save_result(image, selected_mask, image_path, output_dir)
                    print(f"ä¿å­˜å®Œäº†: {output_path} (ã‚¹ã‚³ã‚¢: {selected_score:.3f})")
                    return "success"
                else:
                    print(f"ç„¡åŠ¹ãªé¸æŠã§ã™ã€‚0-{len(top_masks)-1}ã®ç¯„å›²ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                    
            except ValueError:
                print("ç„¡åŠ¹ãªå…¥åŠ›ã§ã™ã€‚æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            except EOFError:
                print("å…¥åŠ›ãŒçµ‚äº†ã—ã¾ã—ãŸã€‚æœ€é«˜ã‚¹ã‚³ã‚¢ã®ãƒã‚¹ã‚¯ã‚’è‡ªå‹•é¸æŠã—ã¾ã™ã€‚")
                selected_mask_data, selected_score = top_masks[0]
                selected_mask = selected_mask_data['segmentation']
                
                # ä¿å­˜
                output_path = self._save_result(image, selected_mask, image_path, output_dir)
                print(f"ä¿å­˜å®Œäº†: {output_path} (ã‚¹ã‚³ã‚¢: {selected_score:.3f})")
                return "success"
    
    def _process_automatic(self, image: np.ndarray, filtered_masks: List[Tuple[dict, float]], 
                         image_path: str, output_dir: str) -> str:
        """
        è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰ã§ã®å‡¦ç†ï¼ˆæœ€é«˜ã‚¹ã‚³ã‚¢ã®ãƒã‚¹ã‚¯ã‚’é¸æŠï¼‰
        """
        if not filtered_masks:
            return "skip"
        
        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®ãƒã‚¹ã‚¯ã‚’é¸æŠ
        best_mask_data, best_score = filtered_masks[0]
        best_mask = best_mask_data['segmentation']
        
        # ä¿å­˜
        output_path = self._save_result(image, best_mask, image_path, output_dir)
        print(f"ä¿å­˜å®Œäº†: {output_path} (ã‚¹ã‚³ã‚¢: {best_score:.3f})")
        
        return "success"
    
    def _save_result(self, image: np.ndarray, mask: np.ndarray, image_path: str, output_dir: str) -> str:
        """
        çµæœã‚’ä¿å­˜
        """
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(output_dir, exist_ok=True)
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ‡ã‚Šå‡ºã—
        masked_image = self.extract_character(image, mask)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        input_filename = os.path.basename(image_path)
        name, ext = os.path.splitext(input_filename)
        output_filename = f"{name}_character{ext}"
        output_path = os.path.join(output_dir, output_filename)
        
        # ä¿å­˜
        masked_bgr = cv2.cvtColor(masked_image, cv2.COLOR_RGB2BGR)
        cv2.imwrite(output_path, masked_bgr, [int(cv2.IMWRITE_JPEG_QUALITY), 95])
        
        return output_path
    
    def _process_choice_mode(self, image: np.ndarray, filtered_masks: List[Tuple[dict, float]], 
                           image_path: str, output_dir: str) -> str:
        """
        choiceãƒ¢ãƒ¼ãƒ‰ã§ã®å‡¦ç†ï¼ˆ10å€‹ã®ãƒã‚¹ã‚¯ã‚’é‡ã­ã¦è¡¨ç¤ºã—ã¦ã‚¯ãƒªãƒƒã‚¯é¸æŠï¼‰
        å·¦ã‚¯ãƒªãƒƒã‚¯: å˜ä¸€é¸æŠ, å³ã‚¯ãƒªãƒƒã‚¯: è¤‡æ•°é¸æŠ
        """
        print(f"\n=== ã‚¯ãƒªãƒƒã‚¯é¸æŠãƒ¢ãƒ¼ãƒ‰: {os.path.basename(image_path)} ===")
        
        # ä¸Šä½10å€‹ã®ãƒã‚¹ã‚¯ã‚’å–å¾—
        top_masks = filtered_masks[:10]
        
        if len(top_masks) == 0:
            print(f"ã‚¹ã‚­ãƒƒãƒ—: ãƒã‚¹ã‚¯ãŒ0å€‹ã§ã™")
            return "skip"
        
        # é€æ˜åº¦ã‚’è¨­å®šã—ã¦ãƒã‚¹ã‚¯ã‚’é‡ã­ã¦è¡¨ç¤º
        max_retry = 3
        for retry in range(max_retry):
            try:
                selection_result = self._display_overlayed_masks(image, top_masks, image_path)
                
                if selection_result is not None:
                    # ãƒãƒ«ãƒã‚»ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å ´åˆã®å‡¦ç†
                    if isinstance(selection_result, dict) and selection_result.get("type") == "multi_select":
                        selected_masks = selection_result["masks"]
                        merged_mask = selection_result["merged_mask"]
                        
                        # ä¿å­˜
                        output_path = self._save_result(image, merged_mask, image_path, output_dir)
                        print(f"ä¿å­˜å®Œäº†: {output_path} (ãƒã‚¹ã‚¯{selected_masks}ã‚’çµåˆã€{len(selected_masks)}å€‹)")
                        return "success"
                    
                    # ã‚·ãƒ³ã‚°ãƒ«ã‚»ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å ´åˆã®å‡¦ç†
                    elif isinstance(selection_result, int):
                        selected_idx = selection_result
                        selected_mask_data, selected_score = top_masks[selected_idx]
                        selected_mask = selected_mask_data['segmentation']
                        
                        # ä¿å­˜
                        output_path = self._save_result(image, selected_mask, image_path, output_dir)
                        print(f"ä¿å­˜å®Œäº†: {output_path} (ãƒã‚¹ã‚¯{selected_idx}é¸æŠã€ã‚¹ã‚³ã‚¢: {selected_score:.3f})")
                        return "success"
                else:
                    if retry < max_retry - 1:
                        print(f"å†è©¦è¡Œ {retry + 1}/{max_retry}")
                    else:
                        print("æœ€å¤§è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸã€‚ã“ã®ç”»åƒã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        return "skip"
                        
            except Exception as e:
                print(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
                if retry < max_retry - 1:
                    print(f"å†è©¦è¡Œ {retry + 1}/{max_retry}")
                else:
                    print("æœ€å¤§è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸã€‚ã“ã®ç”»åƒã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                    return "error"
        
        return "skip"
    
    def _display_overlayed_masks(self, image: np.ndarray, top_masks: List[Tuple[dict, float]], 
                               image_path: str) -> Optional[int]:
        """
        10å€‹ã®ãƒã‚¹ã‚¯ã‚’é€æ˜åº¦ã‚’å¤‰ãˆã¦é‡ã­ã¦è¡¨ç¤ºã—ã€ã‚¯ãƒªãƒƒã‚¯é¸æŠã‚’å—ã‘ä»˜ã‘ã‚‹
        å·¦ã‚¯ãƒªãƒƒã‚¯: å˜ä¸€é¸æŠ, å³ã‚¯ãƒªãƒƒã‚¯: è¤‡æ•°é¸æŠ
        æˆ»ã‚Šå€¤: int (å˜ä¸€é¸æŠ) ã¾ãŸã¯ dict (è¤‡æ•°é¸æŠ) ã¾ãŸã¯ None (ã‚¹ã‚­ãƒƒãƒ—)
        """
        # è¡¨ç¤ºç”¨ã®ç”»åƒã‚’ä½œæˆ
        display_image = image.copy().astype(np.float32)
        
        # 10è‰²ã®é…è‰²ã‚’å®šç¾©ï¼ˆåŒºåˆ¥ã—ã‚„ã™ã„è‰²ï¼‰
        colors = [
            (1.0, 0.0, 0.0),   # èµ¤
            (0.0, 1.0, 0.0),   # ç·‘
            (0.0, 0.0, 1.0),   # é’
            (1.0, 1.0, 0.0),   # é»„
            (1.0, 0.0, 1.0),   # ãƒã‚¼ãƒ³ã‚¿
            (0.0, 1.0, 1.0),   # ã‚·ã‚¢ãƒ³
            (1.0, 0.5, 0.0),   # ã‚ªãƒ¬ãƒ³ã‚¸
            (0.5, 0.0, 1.0),   # ç´«
            (0.0, 0.5, 0.0),   # æ¿ƒã„ç·‘
            (0.5, 0.5, 0.5)    # ã‚°ãƒ¬ãƒ¼
        ]
        alpha = 0.3  # çµ±ä¸€é€æ˜åº¦
        
        # ãƒã‚¹ã‚¯ã‚’é‡ã­ã¦é©ç”¨
        for i, (mask_data, score) in enumerate(top_masks):
            mask = mask_data['segmentation']
            color = colors[i % len(colors)]  # 10è‰²ã‚’å¾ªç’°ä½¿ç”¨
            
            # ãƒã‚¹ã‚¯ã®éƒ¨åˆ†ã«è‰²ã‚’ä»˜ã‘ã‚‹
            for c in range(3):  # RGB
                display_image[:, :, c] = np.where(
                    mask,
                    display_image[:, :, c] * (1 - alpha) + color[c] * 255 * alpha,
                    display_image[:, :, c]
                )
        
        # uint8ã«å¤‰æ›
        display_image = np.clip(display_image, 0, 255).astype(np.uint8)
        
        # ç”»åƒã‚µã‚¤ã‚ºã‚’èª¿æ•´ï¼ˆå¤§ãã™ãã‚‹å ´åˆã¯ãƒªã‚µã‚¤ã‚ºï¼‰
        max_size = 800
        orig_h, orig_w = image.shape[:2]
        
        if max(orig_h, orig_w) > max_size:
            if orig_h > orig_w:
                new_h = max_size
                new_w = int(orig_w * max_size / orig_h)
            else:
                new_w = max_size
                new_h = int(orig_h * max_size / orig_w)
            
            display_image = cv2.resize(display_image, (new_w, new_h))
            display_shape = (new_h, new_w)
        else:
            display_shape = (orig_h, orig_w)
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã‚’ä¿å­˜
        preview_dir = "./character_boudingbox_preview"
        os.makedirs(preview_dir, exist_ok=True)
        
        # å¤ã„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆåˆå›ã®ã¿å®Ÿè¡Œï¼‰
        if not hasattr(self, '_preview_cleaned'):
            cleanup_old_preview_images(preview_dir, days_old=7)
            self._preview_cleaned = True
        
        preview_path = os.path.join(preview_dir, f"choice_preview_{os.path.basename(image_path)}")
        cv2.imwrite(preview_path, cv2.cvtColor(display_image, cv2.COLOR_RGB2BGR))
        print(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {preview_path}")
        # ãƒã‚¹ã‚¯æƒ…å ±ã‚’å‡ºåŠ›ï¼ˆãƒ•ã‚©ãƒ³ãƒˆå¯¾å¿œï¼‰
        mask_info = []
        color_names_jp = ["èµ¤", "ç·‘", "é’", "é»„", "ãƒã‚¼ãƒ³ã‚¿", "ã‚·ã‚¢ãƒ³", "ã‚ªãƒ¬ãƒ³ã‚¸", "ç´«", "æ¿ƒç·‘", "ã‚°ãƒ¬ãƒ¼"]
        color_names_en = ["Red", "Green", "Blue", "Yellow", "Magenta", "Cyan", "Orange", "Purple", "DarkGreen", "Gray"]
        
        use_english = plt.rcParams.get('font.family') == ['DejaVu Sans']
        color_names = color_names_en if use_english else color_names_jp
        
        for i, (mask_data, score) in enumerate(top_masks):
            color_name = color_names[i % len(color_names)]
            if use_english:
                mask_info.append(f"{color_name}=Mask{i}(Score:{score:.3f})")
            else:
                mask_info.append(f"{color_name}=ãƒã‚¹ã‚¯{i}(ã‚¹ã‚³ã‚¢:{score:.3f})")
        print(", ".join(mask_info))
        
        # matplotlibã‚’ä½¿ç”¨ã—ã¦ã‚¯ãƒªãƒƒã‚¯é¸æŠ
        backends_to_try = ['TkAgg', 'Qt5Agg', 'Agg']
        
        for backend in backends_to_try:
            try:
                print(f"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ '{backend}' ã‚’è©¦è¡Œä¸­...")
                import matplotlib
                matplotlib.use(backend)
                
                if backend == 'Agg':
                    # Aggãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã§ã¯ä¿å­˜ã®ã¿å¯¾å¿œ
                    print("Aggãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ãŸã‚ã€ã‚­ãƒ¼å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™")
                    break
                
                selected_idx = self._show_matplotlib_viewer_for_selection(display_image, top_masks, image_path, (orig_h, orig_w), display_shape)
                return selected_idx
                
            except Exception as e:
                print(f"ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ '{backend}' ã§ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        print("å…¨ã¦ã®GUIãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ã‚­ãƒ¼å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã‚­ãƒ¼å…¥åŠ›ã§é¸æŠ
        while True:
            try:
                max_idx = len(top_masks) - 1
                choice = input(f"é¸æŠã™ã‚‹ãƒã‚¹ã‚¯ç•ªå· (0-{max_idx}), 's'ã§ã‚¹ã‚­ãƒƒãƒ—: ")
                
                if choice.lower() == 's':
                    print("ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")
                    return None
                
                mask_idx = int(choice)
                if 0 <= mask_idx <= max_idx:
                    selected_mask_data, selected_score = top_masks[mask_idx]
                    print(f"ãƒã‚¹ã‚¯{mask_idx}ã‚’é¸æŠã—ã¾ã—ãŸ (ã‚¹ã‚³ã‚¢: {selected_score:.3f})")
                    return mask_idx
                else:
                    print(f"ç„¡åŠ¹ãªé¸æŠã§ã™ã€‚0-{max_idx}ã®ç¯„å›²ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                    
            except ValueError:
                print("ç„¡åŠ¹ãªå…¥åŠ›ã§ã™ã€‚æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            except EOFError:
                print("å…¥åŠ›ãŒçµ‚äº†ã—ã¾ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return None
    
    def _show_matplotlib_viewer_for_selection(self, display_image: np.ndarray, top_masks: List[Tuple[dict, float]], 
                                            image_path: str, orig_shape: Tuple[int, int], display_shape: Tuple[int, int]) -> Optional[int]:
        """
        matplotlibã®ClickHandlerã‚’ä½¿ç”¨ã—ã¦ã‚¯ãƒªãƒƒã‚¯é¸æŠã‚’å®Ÿè£…
        å·¦ã‚¯ãƒªãƒƒã‚¯: å˜ä¸€é¸æŠã¾ãŸã¯ç¢ºå®š
        å³ã‚¯ãƒªãƒƒã‚¯: è¤‡æ•°é¸æŠãƒ¢ãƒ¼ãƒ‰
        """
        print("matplotlibã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ãƒã‚¹ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠã—ã¦ãã ã•ã„...")
        
        # ãƒã‚¹ã‚¯æƒ…å ±ã‚’è¡¨ç¤ºï¼ˆãƒ•ã‚©ãƒ³ãƒˆå¯¾å¿œï¼‰
        color_names_jp = ["èµ¤", "ç·‘", "é’", "é»„", "ãƒã‚¼ãƒ³ã‚¿", "ã‚·ã‚¢ãƒ³", "ã‚ªãƒ¬ãƒ³ã‚¸", "ç´«", "æ¿ƒç·‘", "ã‚°ãƒ¬ãƒ¼"]
        color_names_en = ["Red", "Green", "Blue", "Yellow", "Magenta", "Cyan", "Orange", "Purple", "DarkGreen", "Gray"]
        
        # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã«å¿œã˜ã¦è¡¨ç¤ºè¨€èªã‚’é¸æŠ
        use_english = plt.rcParams.get('font.family') == ['DejaVu Sans']
        color_names = color_names_en if use_english else color_names_jp
        
        for i, (mask_data, score) in enumerate(top_masks):
            color_name = color_names[i % len(color_names)]
            if use_english:
                print(f"{color_name}=Mask{i}(Score:{score:.3f})")
            else:
                print(f"{color_name}=ãƒã‚¹ã‚¯{i}(ã‚¹ã‚³ã‚¢:{score:.3f})")
        
        if use_english:
            print("\nControls:")
            print("- Left click: Single selection or confirm")
            print("- Right click: Multiple selection (add/remove)")
            print("- Click outside masks: Confirm multiple selection")
            print("- Click on colored mask areas")
        else:
            print("\næ“ä½œæ–¹æ³•:")
            print("- å·¦ã‚¯ãƒªãƒƒã‚¯: å˜ä¸€é¸æŠã¾ãŸã¯ç¢ºå®š")
            print("- å³ã‚¯ãƒªãƒƒã‚¯: è¤‡æ•°é¸æŠï¼ˆè¿½åŠ /å‰Šé™¤ï¼‰")
            print("- ãƒã‚¹ã‚¯å¤–ã‚’ã‚¯ãƒªãƒƒã‚¯: è¤‡æ•°é¸æŠã®ç¢ºå®š")
            print("- ãƒã‚¹ã‚¯ã®è‰²ãŒã¤ã„ãŸéƒ¨åˆ†ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")
        
        # å›³ã‚’è¡¨ç¤º
        fig, ax = plt.subplots(figsize=(12, 8))
        ax.imshow(display_image)
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ›´æ–°ã—ã¦10ãƒã‚¹ã‚¯å¯¾å¿œï¼ˆãƒ•ã‚©ãƒ³ãƒˆå¯¾å¿œï¼‰
        title_parts = []
        for i, (mask_data, score) in enumerate(top_masks):
            color_name = color_names[i % len(color_names)]
            if use_english:
                title_parts.append(f"{color_name}=Mask{i}(Score:{score:.3f})")
            else:
                title_parts.append(f"{color_name}=ãƒã‚¹ã‚¯{i}(ã‚¹ã‚³ã‚¢:{score:.3f})")
        
        if use_english:
            title_text = f"Mask Selection: {os.path.basename(image_path)}\n{', '.join(title_parts)}\nLeft: Single/Confirm, Right: Multi-select"
        else:
            title_text = f"ãƒã‚¹ã‚¯é¸æŠ: {os.path.basename(image_path)}\n{', '.join(title_parts)}\nå·¦ã‚¯ãƒªãƒƒã‚¯: å˜ä¸€é¸æŠ/ç¢ºå®š, å³ã‚¯ãƒªãƒƒã‚¯: è¤‡æ•°é¸æŠ"
        
        ax.set_title(title_text, fontsize=10)
        ax.axis('off')
        
        # ClickHandlerã‚’ä½œæˆ
        mask_list = [mask_data for mask_data, _ in top_masks]
        click_handler = ClickHandler(mask_list, orig_shape, display_shape)
        click_handler.figure = fig
        click_handler.ax = ax
        
        # ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ¥ç¶š
        cid = fig.canvas.mpl_connect('button_press_event', click_handler.on_click)
        
        # è¡¨ç¤ºã—ã¦å¾…æ©Ÿ
        try:
            print("ç”»åƒå†…ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„...")
            plt.show()
            
            # çµæœã‚’å‡¦ç†
            if click_handler.is_multi_select and click_handler.selected_masks:
                # è¤‡æ•°é¸æŠãƒ¢ãƒ¼ãƒ‰
                print(f"è¤‡æ•°é¸æŠ: {len(click_handler.selected_masks)}å€‹ã®ãƒã‚¹ã‚¯ãŒé¸æŠã•ã‚Œã¾ã—ãŸ")
                print(f"é¸æŠã•ã‚ŒãŸãƒã‚¹ã‚¯: {click_handler.selected_masks}")
                
                # è¤‡æ•°ãƒã‚¹ã‚¯ã‚’ãƒãƒ¼ã‚¸
                merged_mask = click_handler.merge_selected_masks()
                
                # ä»®æƒ³çš„ãªçµæœã‚’è¿”ã™ï¼ˆè¤‡æ•°é¸æŠã®å ´åˆã¯ç‰¹åˆ¥ãªå‡¦ç†ï¼‰
                return {"type": "multi_select", "masks": click_handler.selected_masks, "merged_mask": merged_mask}
                
            elif click_handler.selected_mask_idx is not None:
                # å˜ä¸€é¸æŠãƒ¢ãƒ¼ãƒ‰
                selected_idx = click_handler.selected_mask_idx
                print(f"ãƒã‚¹ã‚¯{selected_idx}ãŒé¸æŠã•ã‚Œã¾ã—ãŸ (ã‚¹ã‚³ã‚¢: {top_masks[selected_idx][1]:.3f})")
                return selected_idx
            else:
                print("ã‚¯ãƒªãƒƒã‚¯ä½ç½®ã«ãƒã‚¹ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return None
                
        except Exception as e:
            print(f"ã‚¯ãƒªãƒƒã‚¯é¸æŠã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return None
        finally:
            # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’è§£é™¤
            if 'cid' in locals():
                try:
                    fig.canvas.mpl_disconnect(cid)
                except:
                    pass
            # å›³ã‚’ç¢ºå®Ÿã«é–‰ã˜ã‚‹
            try:
                plt.close(fig)
                plt.close('all')
            except:
                pass
    
    def _determine_mask_from_click(self, x: int, y: int, top_masks: List[Tuple[dict, float]]) -> Optional[int]:
        """
        ã‚¯ãƒªãƒƒã‚¯ä½ç½®ã‹ã‚‰ãƒã‚¹ã‚¯ã‚’åˆ¤å®š
        """
        candidate_masks = []
        
        # ã‚¯ãƒªãƒƒã‚¯ä½ç½®ã«è©²å½“ã™ã‚‹ãƒã‚¹ã‚¯ã‚’æ¢ã™
        for i, (mask_data, score) in enumerate(top_masks):
            mask = mask_data['segmentation']
            if y < mask.shape[0] and x < mask.shape[1] and mask[y, x]:
                # ãƒã‚¹ã‚¯ã®ãƒ”ã‚¯ã‚»ãƒ«æ•°ã‚’è¨ˆç®—
                pixel_count = np.sum(mask)
                candidate_masks.append((i, pixel_count, score))
        
        if not candidate_masks:
            return None
        
        # ãƒ”ã‚¯ã‚»ãƒ«æ•°ãŒæœ€å¤§ã®ãƒã‚¹ã‚¯ã‚’é¸æŠ
        selected_idx, max_pixels, score = max(candidate_masks, key=lambda x: x[1])
        
        print(f"é¸æŠã•ã‚ŒãŸãƒã‚¹ã‚¯è©³ç´°: ãƒã‚¹ã‚¯{selected_idx} (ã‚¹ã‚³ã‚¢: {score:.3f}, ãƒ”ã‚¯ã‚»ãƒ«æ•°: {max_pixels})")
        if len(candidate_masks) > 1:
            print(f"é‡è¤‡ãƒã‚¹ã‚¯æ•°: {len(candidate_masks)}, æœ€å¤§ãƒ”ã‚¯ã‚»ãƒ«æ•°ã§é¸æŠ")
        
        return selected_idx
    
    def _show_image_viewer_for_selection(self, display_image: np.ndarray, top_masks: List[Tuple[dict, float]], 
                                       image_path: str, orig_shape: Tuple[int, int], display_shape: Tuple[int, int]) -> Optional[int]:
        """
        OpenCVã‚’ä½¿ç”¨ã—ã¦ç”»åƒãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚’è¡¨ç¤ºã—ã¦ã‚¯ãƒªãƒƒã‚¯é¸æŠã‚’å—ã‘ä»˜ã‘ã‚‹
        """
        class OpenCVImageViewer:
            def __init__(self, image, masks, image_name, orig_shape, display_shape):
                self.image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # OpenCVç”¨ã«BGRã«å¤‰æ›
                self.masks = [mask_data for mask_data, _ in masks]
                self.mask_scores = [score for _, score in masks]
                self.image_name = image_name
                self.orig_shape = orig_shape  # (height, width)
                self.display_shape = display_shape  # (height, width)
                self.selected_mask_idx = None
                
            def mouse_callback(self, event, x, y, flags, param):
                """ãƒã‚¦ã‚¹ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
                if event == cv2.EVENT_LBUTTONDOWN:
                    # è¡¨ç¤ºåº§æ¨™ã‚’å…ƒç”»åƒåº§æ¨™ã«å¤‰æ›
                    orig_x = int(x * self.orig_shape[1] / self.display_shape[1])
                    orig_y = int(y * self.orig_shape[0] / self.display_shape[0])
                    
                    # åº§æ¨™å¤‰æ›ã®ã‚ºãƒ¬ã‚’è¨ˆç®—
                    scale_x = self.orig_shape[1] / self.display_shape[1]
                    scale_y = self.orig_shape[0] / self.display_shape[0]
                    
                    # ã‚ºãƒ¬ãŒå¤§ãã„å ´åˆã¯è­¦å‘Š
                    if abs(scale_x - scale_y) > 0.1:
                        print(f"è­¦å‘Š: åº§æ¨™å¤‰æ›ã§ã‚ºãƒ¬ãŒç™ºç”Ÿã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ (scale_x: {scale_x:.3f}, scale_y: {scale_y:.3f})")
                    
                    # å¢ƒç•Œãƒã‚§ãƒƒã‚¯
                    orig_x = max(0, min(orig_x, self.orig_shape[1] - 1))
                    orig_y = max(0, min(orig_y, self.orig_shape[0] - 1))
                    
                    print(f"ã‚¯ãƒªãƒƒã‚¯åº§æ¨™: è¡¨ç¤º({x}, {y}) -> å…ƒç”»åƒ({orig_x}, {orig_y})")
                    
                    # ãƒã‚¹ã‚¯ã‚’åˆ¤å®š
                    self.selected_mask_idx = self._determine_mask(orig_x, orig_y)
                    
                    if self.selected_mask_idx is not None:
                        print(f"ãƒã‚¹ã‚¯{self.selected_mask_idx}ãŒé¸æŠã•ã‚Œã¾ã—ãŸï¼ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‰ã˜ã¦ã„ã¾ã™...")
                        cv2.destroyAllWindows()
                    else:
                        print("ãƒã‚¹ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒã‚¹ã‚¯ã®è‰²ãŒã¤ã„ãŸéƒ¨åˆ†ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
                
            def _determine_mask(self, x, y):
                """ã‚¯ãƒªãƒƒã‚¯ä½ç½®ã§ã®ãƒã‚¹ã‚¯ã‚’åˆ¤å®š"""
                candidate_masks = []
                
                # ã‚¯ãƒªãƒƒã‚¯ä½ç½®ã«è©²å½“ã™ã‚‹ãƒã‚¹ã‚¯ã‚’æ¢ã™
                for i, mask_data in enumerate(self.masks):
                    mask = mask_data['segmentation']
                    if y < mask.shape[0] and x < mask.shape[1] and mask[y, x]:
                        # ãƒã‚¹ã‚¯ã®ãƒ”ã‚¯ã‚»ãƒ«æ•°ã‚’è¨ˆç®—
                        pixel_count = np.sum(mask)
                        candidate_masks.append((i, pixel_count))
                
                if not candidate_masks:
                    return None
                
                # ãƒ”ã‚¯ã‚»ãƒ«æ•°ãŒæœ€å¤§ã®ãƒã‚¹ã‚¯ã‚’é¸æŠ
                selected_idx, max_pixels = max(candidate_masks, key=lambda x: x[1])
                
                print(f"é¸æŠã•ã‚ŒãŸãƒã‚¹ã‚¯: {selected_idx} (ã‚¹ã‚³ã‚¢: {self.mask_scores[selected_idx]:.3f}, ãƒ”ã‚¯ã‚»ãƒ«æ•°: {max_pixels})")
                if len(candidate_masks) > 1:
                    print(f"é‡è¤‡ãƒã‚¹ã‚¯æ•°: {len(candidate_masks)}, æœ€å¤§ãƒ”ã‚¯ã‚»ãƒ«æ•°ã§é¸æŠ")
                
                return selected_idx
            
            def show(self):
                """OpenCVã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ç”»åƒã‚’è¡¨ç¤º"""
                window_name = f"ãƒã‚¹ã‚¯é¸æŠ: {os.path.basename(self.image_name)}"
                
                # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ä½œæˆ
                cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)
                cv2.setMouseCallback(window_name, self.mouse_callback)
                
                # æƒ…å ±ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤º
                print(f"\n=== {window_name} ===")
                print(f"èµ¤=ãƒã‚¹ã‚¯0(ã‚¹ã‚³ã‚¢:{self.mask_scores[0]:.3f})")
                print(f"ç·‘=ãƒã‚¹ã‚¯1(ã‚¹ã‚³ã‚¢:{self.mask_scores[1]:.3f})")
                print(f"é’=ãƒã‚¹ã‚¯2(ã‚¹ã‚³ã‚¢:{self.mask_scores[2]:.3f})")
                print("ãƒã‚¹ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠã—ã¦ãã ã•ã„ã€‚")
                print("'s'ã‚­ãƒ¼ã§ã‚¹ã‚­ãƒƒãƒ—ã€'q'ã‚­ãƒ¼ã§çµ‚äº†")
                
                while True:
                    # ç”»åƒã‚’è¡¨ç¤º
                    cv2.imshow(window_name, self.image)
                    
                    # ã‚­ãƒ¼å…¥åŠ›ã‚’å¾…æ©Ÿ
                    key = cv2.waitKey(1) & 0xFF
                    
                    if key == ord('s'):
                        # ã‚¹ã‚­ãƒƒãƒ—
                        print("ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")
                        self.selected_mask_idx = None
                        break
                    elif key == ord('q') or key == 27:  # ESCã‚­ãƒ¼
                        # çµ‚äº†
                        print("å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™")
                        self.selected_mask_idx = None
                        break
                    elif self.selected_mask_idx is not None:
                        # ãƒã‚¹ã‚¯ãŒé¸æŠã•ã‚ŒãŸ
                        break
                
                cv2.destroyAllWindows()
                return self.selected_mask_idx
        
        # OpenCVç”»åƒãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚’ä½œæˆã—ã¦è¡¨ç¤º
        viewer = OpenCVImageViewer(display_image, top_masks, image_path, orig_shape, display_shape)
        return viewer.show()
    
    def process_reproduce_auto_mode(self, input_dir: str, output_dir: str):
        """
        æ‰‹å‹•æŠ½å‡ºã‚’å†ç¾ã™ã‚‹å®Œå…¨è‡ªå‹•æŠ½å‡ºãƒ¢ãƒ¼ãƒ‰
        
        Args:
            input_dir: å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.monitor.start_monitoring()
        self.monitor.start_stage("ãƒ•ã‚¡ã‚¤ãƒ«åé›†")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«å–å¾—
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        image_files = []
        
        input_path = Path(input_dir)
        for ext in image_extensions:
            image_files.extend(input_path.rglob(f"*{ext}"))
            image_files.extend(input_path.rglob(f"*{ext.upper()}"))
        
        # é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å»
        image_files = list(set(image_files))
        image_files.sort()  # ãƒ•ã‚¡ã‚¤ãƒ«åã§ã‚½ãƒ¼ãƒˆã—ã¦å‡¦ç†é †åºã‚’ä¸€å®šã«ã™ã‚‹
        
        if not image_files:
            print(f"ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_dir}")
            return
        
        print(f"å‡¦ç†å¯¾è±¡ç”»åƒæ•°: {len(image_files)} (é‡è¤‡é™¤å»å¾Œ)")
        self.monitor.end_stage()
        
        # è‡ªå‹•æŠ½å‡ºå‡¦ç†
        success_count = 0
        skip_count = 0
        quality_scores = []
        
        for i, image_file in enumerate(image_files):
            print(f"\né€²æ—: {i+1}/{len(image_files)} - {image_file.name}")
            
            result = self._process_single_auto_extraction(str(image_file), output_dir)
            
            if result == "success":
                success_count += 1
            elif result == "skip":
                skip_count += 1
        
        # å‡¦ç†çµæœã®çµ±è¨ˆ
        print(f"\nğŸ“Š å‡¦ç†å®Œäº†çµ±è¨ˆ:")
        print(f"  âœ… æˆåŠŸ: {success_count}/{len(image_files)} æš")
        print(f"  â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: {skip_count} æš")
        print(f"  ğŸ“ˆ å†ç¾ç‡: {success_count/132*100:.1f}% (æ‰‹å‹•æŠ½å‡º132æšã«å¯¾ã—ã¦)")
        
        # ç·åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¡¨ç¤º
        self.monitor.print_summary()
    
    def _process_single_auto_extraction(self, image_path: str, output_dir: str) -> str:
        """
        å˜ä¸€ç”»åƒã®è‡ªå‹•æŠ½å‡ºå‡¦ç†
        
        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            å‡¦ç†çµæœ ("success", "skip", "error")
        """
        try:
            self.monitor.start_stage("ç”»åƒèª­ã¿è¾¼ã¿")
            image = cv2.imread(image_path)
            if image is None:
                print(f"âš ï¸ ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—: {image_path}")
                return "error"
            
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            self.monitor.end_stage()
            
            # 1. ã‚«ãƒ©ãƒ¼ç”»åƒãƒã‚§ãƒƒã‚¯
            if is_color_image(image):
                print(f"ã‚¹ã‚­ãƒƒãƒ—: ã‚«ãƒ©ãƒ¼ç”»åƒã§ã™ - {os.path.basename(image_path)}")
                return "skip"
            
            # 2. ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºãƒã‚§ãƒƒã‚¯ï¼ˆEasyOCRãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿ï¼‰
            if hasattr(self, 'text_detector') and self.text_detector.reader:
                if self.text_detector.has_significant_text(image_rgb, threshold=0.05):
                    print(f"ã‚¹ã‚­ãƒƒãƒ—: å¤§é‡ã®ãƒ†ã‚­ã‚¹ãƒˆãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ - {os.path.basename(image_path)}")
                    return "skip"
            
            # 3. SAMãƒã‚¹ã‚¯ç”Ÿæˆ
            masks = self.generate_masks(image_rgb)
            if not masks:
                print(f"ã‚¹ã‚­ãƒƒãƒ—: ãƒã‚¹ã‚¯ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                return "skip"
            
            # 4. YOLOãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            filtered_masks = self.filter_masks_with_yolo(image_rgb, masks)
            if not filtered_masks:
                print(f"ã‚¹ã‚­ãƒƒãƒ—: YOLOæ¤œå‡ºã‚¹ã‚³ã‚¢ãŒé–¾å€¤ã‚’ä¸‹å›ã‚Šã¾ã—ãŸ")
                return "skip"
            
            # 5. å“è³ªè©•ä¾¡ã«ã‚ˆã‚‹æœ€é©ãƒã‚¹ã‚¯é¸æŠ
            best_mask, best_score = self._select_best_character_mask(image_rgb, filtered_masks)
            if best_mask is None:
                print(f"ã‚¹ã‚­ãƒƒãƒ—: é©åˆ‡ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒã‚¹ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return "skip"
            
            # 6. ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡ºã¨ä¿å­˜
            success = self._extract_and_save_character(
                image, best_mask, image_path, output_dir, best_score
            )
            
            return "success" if success else "error"
            
        except Exception as e:
            print(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return "error"
    
    def _select_best_character_mask(self, image: np.ndarray, filtered_masks: List[Tuple[dict, float]]) -> Tuple[Optional[dict], float]:
        """
        å“è³ªè©•ä¾¡ã‚’ä½¿ç”¨ã—ã¦æœ€é©ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒã‚¹ã‚¯ã‚’é¸æŠï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        
        Args:
            image: å…¥åŠ›ç”»åƒ
            filtered_masks: YOLOã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒã‚¹ã‚¯ãƒªã‚¹ãƒˆ
            
        Returns:
            æœ€é©ãƒã‚¹ã‚¯ã¨å“è³ªã‚¹ã‚³ã‚¢
        """
        if not filtered_masks:
            return None, 0.0
        
        # è¤‡æ•°ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ¤œå‡ºæ™‚ã¯æœ€å¤§é¢ç©ã®ãƒã‚¹ã‚¯ã‚’é¸æŠ
        if len(filtered_masks) > 1:
            # é¢ç©ã§ã‚½ãƒ¼ãƒˆï¼ˆå¤§ãã„é †ï¼‰
            filtered_masks.sort(key=lambda x: x[0]['area'], reverse=True)
            print(f"ğŸ¯ è¤‡æ•°ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ¤œå‡º: {len(filtered_masks)}å€‹ â†’ æœ€å¤§é¢ç©ã‚’é¸æŠ")
        
        # è¿‘æ¥ãƒã‚¹ã‚¯ã®çµ±åˆã‚’è©¦è¡Œ
        merged_mask = self._try_merge_nearby_masks(filtered_masks, image)
        if merged_mask is not None:
            print("ğŸ”— è¿‘æ¥ãƒã‚¹ã‚¯ã‚’çµ±åˆã—ã¾ã—ãŸ")
            return merged_mask, 0.85  # çµ±åˆæˆåŠŸæ™‚ã¯é«˜ã‚¹ã‚³ã‚¢
        
        # é€šå¸¸ã®æœ€é©ãƒã‚¹ã‚¯é¸æŠ
        best_mask = None
        best_total_score = 0.0
        
        for mask_data, yolo_score in filtered_masks:
            mask = mask_data['segmentation']
            bbox = mask_data['bbox']  # [x, y, w, h]
            
            # å“è³ªè©•ä¾¡
            quality_score = self.quality_evaluator.evaluate_character_quality(
                image, mask.astype(np.uint8), tuple(map(int, bbox))
            )
            
            # ç·åˆã‚¹ã‚³ã‚¢ = YOLOã‚¹ã‚³ã‚¢ * 0.6 + å“è³ªã‚¹ã‚³ã‚¢ * 0.4
            total_score = yolo_score * 0.6 + quality_score * 0.4
            
            if total_score > best_total_score:
                best_total_score = total_score
                best_mask = mask_data
        
        # æœ€ä½å“è³ªé–¾å€¤ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆç·©å’Œï¼‰
        if best_total_score < 0.25:  # 0.3â†’0.25 ã«ç·©å’Œ
            return None, 0.0
        
        return best_mask, best_total_score
    
    def _try_merge_nearby_masks(self, filtered_masks: List[Tuple[dict, float]], 
                               image: np.ndarray) -> Optional[dict]:
        """
        è¿‘æ¥ã™ã‚‹è¤‡æ•°ã®ãƒã‚¹ã‚¯ã‚’çµ±åˆã—ã¦ã‚ˆã‚Šå®Œå…¨ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’ç”Ÿæˆ
        
        Args:
            filtered_masks: ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ãƒã‚¹ã‚¯ãƒªã‚¹ãƒˆ
            image: å…ƒç”»åƒ
            
        Returns:
            çµ±åˆã•ã‚ŒãŸãƒã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿ã€ã¾ãŸã¯ None
        """
        if len(filtered_masks) < 2:
            return None
        
        # æœ€ã‚‚ä¿¡é ¼åº¦ã®é«˜ã„ãƒã‚¹ã‚¯ã‚’åŸºæº–ã¨ã™ã‚‹
        primary_mask, primary_score = filtered_masks[0]
        primary_bbox = primary_mask['bbox']
        primary_center = (primary_bbox[0] + primary_bbox[2]/2, primary_bbox[1] + primary_bbox[3]/2)
        
        # çµ±åˆå€™è£œãƒã‚¹ã‚¯ã‚’åé›†
        merge_candidates = [primary_mask]
        
        for mask_data, yolo_score in filtered_masks[1:3]:  # æœ€å¤š3å€‹ã«åˆ¶é™
            bbox = mask_data['bbox']
            center = (bbox[0] + bbox[2]/2, bbox[1] + bbox[3]/2)
            
            # è·é›¢è¨ˆç®—
            distance = np.sqrt((primary_center[0] - center[0])**2 + 
                             (primary_center[1] - center[1])**2)
            
            # ã‚ˆã‚Šå³æ ¼ãªçµ±åˆåˆ¤å®šåŸºæº–ï¼ˆè¤‡æ•°ã‚³ãƒçµ±åˆã‚’é˜²ãï¼‰
            max_distance = min(primary_bbox[2], primary_bbox[3]) * 0.8  # åŸºæº–ãƒã‚¹ã‚¯ã®0.8å€ä»¥å†…ã«å³æ ¼åŒ–
            
            # é¢ç©æ¯”ç‡ã§ã‚‚ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå¤§ãã™ãã‚‹ãƒã‚¹ã‚¯ã¯çµ±åˆã—ãªã„ï¼‰
            area_ratio = mask_data['area'] / primary_mask['area']
            
            # çµ±åˆæ¡ä»¶ï¼šè·é›¢ãŒè¿‘ãã€ã‹ã¤é¢ç©æ¯”ãŒé©åˆ‡
            if distance < max_distance and 0.1 < area_ratio < 3.0:
                merge_candidates.append(mask_data)
                print(f"ğŸ”— çµ±åˆå€™è£œ: è·é›¢ {distance:.1f} < é–¾å€¤ {max_distance:.1f}, é¢ç©æ¯” {area_ratio:.2f}")
            else:
                print(f"âŒ çµ±åˆæ‹’å¦: è·é›¢ {distance:.1f} ã¾ãŸã¯é¢ç©æ¯” {area_ratio:.2f} ãŒä¸é©åˆ‡")
        
        # çµ±åˆã®ä¾¡å€¤ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ˆã‚Šä¿å®ˆçš„ã«ï¼‰
        if len(merge_candidates) < 2:
            return None
        
        # çµ±åˆãƒã‚¹ã‚¯ã®ã‚µã‚¤ã‚ºäº‹å‰ãƒã‚§ãƒƒã‚¯ï¼ˆå¤§ãã™ãã‚‹å ´åˆã¯æ‹’å¦ï¼‰
        total_area = sum(mask['area'] for mask in merge_candidates)
        image_area = image.shape[0] * image.shape[1]
        area_ratio = total_area / image_area
        
        if area_ratio > 0.4:  # ç”»åƒã®40%ä»¥ä¸Šã¯æ‹’å¦
            print(f"âŒ çµ±åˆæ‹’å¦: çµ±åˆãƒã‚¹ã‚¯ãŒå¤§ãã™ãã¾ã™ ({area_ratio:.2f})")
            return None
        
        # ãƒã‚¹ã‚¯ã‚’çµ±åˆ
        merged_segmentation = merge_candidates[0]['segmentation'].copy()
        total_area = merge_candidates[0]['area']
        
        for mask_data in merge_candidates[1:]:
            merged_segmentation = np.logical_or(merged_segmentation, mask_data['segmentation'])
            total_area += mask_data['area']
        
        # çµ±åˆãƒã‚¹ã‚¯ã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã‚’è¨ˆç®—
        y_indices, x_indices = np.where(merged_segmentation)
        if len(y_indices) == 0 or len(x_indices) == 0:
            return None
        
        x_min, x_max = x_indices.min(), x_indices.max()
        y_min, y_max = y_indices.min(), y_indices.max()
        
        merged_bbox = [x_min, y_min, x_max - x_min + 1, y_max - y_min + 1]
        
        # çµ±åˆãƒã‚¹ã‚¯ã®æœ€çµ‚ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆå¤§ãã™ãã‚‹å ´åˆã¯æ‹’å¦ï¼‰
        merged_width, merged_height = merged_bbox[2], merged_bbox[3]
        merged_area_ratio = (merged_width * merged_height) / image_area
        
        if merged_area_ratio > 0.6:  # ç”»åƒã®60%ä»¥ä¸Šã¯æ‹’å¦
            print(f"âŒ çµ±åˆæ‹’å¦: ãƒã‚¹ã‚¯ãŒå¤§ãã™ãã¾ã™ ({merged_area_ratio:.2f})")
            return None
        
        print(f"âœ… çµ±åˆæˆåŠŸ: {len(merge_candidates)}å€‹ã®ãƒã‚¹ã‚¯ã‚’çµ±åˆ")
        
        # çµ±åˆãƒã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        merged_mask_data = {
            'segmentation': merged_segmentation,
            'bbox': merged_bbox,
            'area': total_area,
            'predicted_iou': 0.8,  # çµ±åˆãƒã‚¹ã‚¯ã®äºˆæ¸¬IoU
            'point_coords': [[x_min + (x_max-x_min)/2, y_min + (y_max-y_min)/2]],
            'stability_score': 0.8,
            'crop_box': [0, 0, image.shape[1], image.shape[0]]
        }
        
        return merged_mask_data
    
    def _extract_and_save_character(self, image: np.ndarray, mask_data: dict, 
                                  image_path: str, output_dir: str, quality_score: float) -> bool:
        """
        ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’æŠ½å‡ºã—ã¦ä¿å­˜
        
        Args:
            image: å…ƒç”»åƒ (BGR)
            mask_data: ãƒã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿
            image_path: å…ƒç”»åƒãƒ‘ã‚¹
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            quality_score: å“è³ªã‚¹ã‚³ã‚¢
            
        Returns:
            ä¿å­˜æˆåŠŸå¯å¦
        """
        try:
            mask = mask_data['segmentation'].astype(np.uint8)
            bbox = mask_data['bbox']  # [x, y, w, h]
            
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã§ã‚¯ãƒ­ãƒƒãƒ—
            x, y, w, h = map(int, bbox)
            
            # å¢ƒç•Œãƒã‚§ãƒƒã‚¯
            x = max(0, x)
            y = max(0, y)
            w = min(w, image.shape[1] - x)
            h = min(h, image.shape[0] - y)
            
            if w <= 0 or h <= 0:
                print(f"âš ï¸ ç„¡åŠ¹ãªãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹: {bbox}")
                return False
            
            # ç”»åƒã¨ãƒã‚¹ã‚¯ã‚’ã‚¯ãƒ­ãƒƒãƒ—
            cropped_image = image[y:y+h, x:x+w].copy()
            cropped_mask = mask[y:y+h, x:x+w]
            
            # èƒŒæ™¯é™¤å»ï¼ˆé»’èƒŒæ™¯ã«çµ±ä¸€ï¼‰
            final_image = self.bg_remover.remove_background(cropped_image, cropped_mask)
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
            base_name = os.path.splitext(os.path.basename(image_path))[0]
            output_filename = f"{base_name}.jpg"
            output_path = os.path.join(output_dir, output_filename)
            
            # ä¿å­˜
            cv2.imwrite(output_path, final_image)
            
            print(f"âœ… ä¿å­˜å®Œäº†: {output_filename} (å“è³ª: {quality_score:.3f})")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _calculate_smart_merge_distance(self, primary_mask: dict, secondary_mask: dict, image: np.ndarray) -> float:
        """
        ã‚¹ãƒãƒ¼ãƒˆãªçµ±åˆè·é›¢ã‚’è¨ˆç®—ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å†…éƒ¨ vs åŸç¨¿å…¨ä½“ï¼‰v4æ”¹è‰¯ç‰ˆ
        """
        try:
            primary_bbox = primary_mask['bbox']
            secondary_bbox = secondary_mask['bbox']
            
            # ãƒã‚¹ã‚¯ã‚µã‚¤ã‚ºã®è©•ä¾¡
            primary_size = max(primary_bbox[2], primary_bbox[3])
            secondary_size = max(secondary_bbox[2], secondary_bbox[3])
            primary_area = np.sum(primary_mask['segmentation'])
            secondary_area = np.sum(secondary_mask['segmentation'])
            
            # ç”»åƒã‚µã‚¤ã‚ºã«å¯¾ã™ã‚‹ç›¸å¯¾çš„ãªé¢ç©
            image_area = image.shape[0] * image.shape[1]
            primary_area_ratio = primary_area / image_area
            secondary_area_ratio = secondary_area / image_area
            
            # é‡å¿ƒé–“ã®è·é›¢ã‚’è¨ˆç®—
            primary_center = self._calculate_mask_center(primary_mask['segmentation'])
            secondary_center = self._calculate_mask_center(secondary_mask['segmentation'])
            center_distance = np.sqrt((primary_center[0] - secondary_center[0])**2 + 
                                     (primary_center[1] - secondary_center[1])**2)
            
            # å°ã•ã„ãƒã‚¹ã‚¯åŒå£«ã®çµ±åˆã¯è·é›¢ã‚’æ‹¡å¤§ï¼ˆ11.jpgå¯¾ç­–ï¼‰
            if primary_size < 200 and secondary_size < 200:
                # é¢ç©æ¯”ã«ã‚ˆã‚‹èª¿æ•´
                area_ratio = min(primary_area, secondary_area) / max(primary_area, secondary_area)
                if area_ratio > 0.3:  # ä¼¼ãŸã‚µã‚¤ã‚ºã®å ´åˆã¯ã‚ˆã‚Šç©æ¥µçš„ã«
                    return min(primary_size, secondary_size) * 2.0
                else:
                    return min(primary_size, secondary_size) * 1.5
            
            # ä¸­ç¨‹åº¦ã®ãƒã‚¹ã‚¯ã¯é‡å¿ƒè·é›¢ã‚‚è€ƒæ…®
            elif primary_size < 500 and secondary_size < 500:
                relative_distance = center_distance / min(primary_size, secondary_size)
                if relative_distance < 1.0:  # é‡å¿ƒãŒè¿‘ã„å ´åˆ
                    return min(primary_size, secondary_size) * 1.2
                else:
                    return min(primary_size, secondary_size) * 0.8
            
            # å¤§ããªãƒã‚¹ã‚¯ã¯ä¿å®ˆçš„ã«ï¼ˆ110.jpgå¯¾ç­–ï¼‰
            else:
                return min(primary_size, secondary_size) * 0.5
            
        except Exception as e:
            print(f"âš ï¸ çµ±åˆè·é›¢è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 100  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    def _calculate_mask_center(self, mask: np.ndarray) -> Tuple[float, float]:
        """
        ãƒã‚¹ã‚¯ã®é‡å¿ƒã‚’è¨ˆç®—
        
        Args:
            mask: ãƒã‚¤ãƒŠãƒªãƒã‚¹ã‚¯
            
        Returns:
            é‡å¿ƒåº§æ¨™ (x, y)
        """
        y_coords, x_coords = np.where(mask)
        if len(x_coords) == 0:
            return (0, 0)
        
        center_x = np.mean(x_coords)
        center_y = np.mean(y_coords)
        return (center_x, center_y)
    
    def _contains_multiple_people(self, mask1: dict, mask2: dict, image: np.ndarray) -> bool:
        """
        çµ±åˆå¾Œã®ãƒã‚¹ã‚¯ã«è¤‡æ•°äººç‰©ãŒå«ã¾ã‚Œã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆ103.jpgå¯¾ç­–ï¼‰v4æ”¹è‰¯ç‰ˆ
        """
        try:
            # ä»®çµ±åˆãƒã‚¹ã‚¯ã‚’ä½œæˆ
            temp_mask = np.logical_or(mask1['segmentation'], mask2['segmentation'])
            
            # çµ±åˆãƒã‚¹ã‚¯ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’è¨ˆç®—
            y_indices, x_indices = np.where(temp_mask)
            if len(y_indices) == 0:
                return False
            
            x_min, x_max = x_indices.min(), x_indices.max()
            y_min, y_max = y_indices.min(), y_indices.max()
            
            # ã‚¯ãƒ­ãƒƒãƒ—ã—ã¦YOLOã§äººæ•°ã‚«ã‚¦ãƒ³ãƒˆ
            crop_region = image[y_min:y_max+1, x_min:x_max+1]
            
            if crop_region.shape[0] == 0 or crop_region.shape[1] == 0:
                return False
            
            # YOLOã§äººç‰©æ¤œå‡ºï¼ˆv4æ”¹è‰¯ç‰ˆï¼‰
            try:
                results = self.yolo(crop_region, verbose=False)
                person_count = 0
                large_person_count = 0  # å¤§ããªäººç‰©ã®æ•°
                
                for result in results:
                    if hasattr(result, 'boxes') and result.boxes is not None:
                        for box in result.boxes:
                            if box.cls.item() == 0:  # personã‚¯ãƒ©ã‚¹
                                if box.conf.item() > 0.25:  # ä½é–¾å€¤ã§ã‚«ã‚¦ãƒ³ãƒˆ
                                    person_count += 1
                                    
                                    # å¤§ããªäººç‰©ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯
                                    box_area = (box.xyxy[0][2] - box.xyxy[0][0]) * (box.xyxy[0][3] - box.xyxy[0][1])
                                    crop_area = crop_region.shape[0] * crop_region.shape[1]
                                    
                                    if box_area > crop_area * 0.1:  # ã‚¯ãƒ­ãƒƒãƒ—é ˜åŸŸã®10%ä»¥ä¸Š
                                        large_person_count += 1
                
                # è¤‡æ•°ã®å¤§ããªäººç‰©ãŒã„ã‚‹å ´åˆã¯çµ±åˆã‚’é¿ã‘ã‚‹
                if large_person_count > 1:
                    return True
                
                # å°ã•ãªäººç‰©ã‚’å«ã‚ã¦è¤‡æ•°ã„ã‚‹å ´åˆã‚‚æ³¨æ„
                return person_count > 1
                
            except Exception as e:
                print(f"âš ï¸ äººæ•°ã‚«ã‚¦ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                return False
                
        except Exception as e:
            print(f"âš ï¸ è¤‡æ•°äººç‰©ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return False


def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹å­˜ï¼‰
    """
    # æ–°ã—ã„mainå‡¦ç†ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
    import sys
    sys.argv[0] = __file__  # ã‚¹ã‚¯ãƒªãƒ—ãƒˆåã‚’è¨­å®š
    
    # å¤ã„å¼•æ•°å½¢å¼ã‚’æ–°ã—ã„å½¢å¼ã«å¤‰æ›
    if "--model-type" in sys.argv:
        idx = sys.argv.index("--model-type")
        sys.argv[idx] = "--model_type"
    if "--sam-checkpoint" in sys.argv:
        idx = sys.argv.index("--sam-checkpoint")
        sys.argv[idx] = "--sam_checkpoint"
    if "--yolo-model" in sys.argv:
        idx = sys.argv.index("--yolo-model")
        sys.argv[idx] = "--yolo_model"
    if "--score-threshold" in sys.argv:
        idx = sys.argv.index("--score-threshold")
        sys.argv[idx] = "--score_threshold"
    if "--anime-mode" in sys.argv:
        idx = sys.argv.index("--anime-mode")
        sys.argv[idx] = "--anime_yolo"
    
    # å¤ã„å¼•æ•°å½¢å¼ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã€å¾Œæ–¹äº’æ›æ€§ã‚’æä¾›
    print("âš ï¸ å¤ã„main()é–¢æ•°ãŒå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸã€‚æ–°ã—ã„å½¢å¼ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
    print("ä½¿ç”¨ä¾‹: python sam_yolo_character_segment.py --mode reproduce-auto")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="SAM + YOLOv8 æ¼«ç”»ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ‡ã‚Šå‡ºã—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
    parser.add_argument("--mode", choices=["interactive", "batch", "choice", "reproduce-auto"], 
                       default="interactive", help="å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰")
    parser.add_argument("--input", help="å…¥åŠ›ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆinteractiveãƒ¢ãƒ¼ãƒ‰ç”¨ï¼‰")
    parser.add_argument("--input_dir", help="å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆbatch/choice/reproduce-autoãƒ¢ãƒ¼ãƒ‰ç”¨ï¼‰")
    parser.add_argument("--output_dir", help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--sam_checkpoint", default="sam_vit_h_4b8939.pth", help="SAMãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--model_type", default="vit_h", choices=["vit_h", "vit_l", "vit_b"], help="SAMãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—")
    parser.add_argument("--yolo_model", default="yolov8n.pt", help="YOLOv8ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--score_threshold", type=float, default=0.15, help="YOLOäººç‰©æ¤œå‡ºã‚¹ã‚³ã‚¢é–¾å€¤")
    parser.add_argument("--device", choices=["cuda", "cpu"], help="è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹")
    parser.add_argument("--anime_yolo", action="store_true", help="ã‚¢ãƒ‹ãƒ¡ç”¨YOLOãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨")
    
    args = parser.parse_args()
    
    # reproduce-autoãƒ¢ãƒ¼ãƒ‰ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
    if args.mode == "reproduce-auto":
        if not args.input_dir:
            args.input_dir = "/mnt/c/AItools/lora/train/diff_aichi/org_aichikan1"
        if not args.output_dir:
            args.output_dir = "/mnt/c/AItools/lora/train/diff_aichi/auto_extracted"
        args.anime_yolo = True  # æ¼«ç”»ç”¨ã«ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹
    
    try:
        # ã‚»ã‚°ãƒ¡ãƒ³ã‚¿ãƒ¼åˆæœŸåŒ–
        segmentor = SAMYOLOCharacterSegmentor(
            sam_checkpoint=args.sam_checkpoint,
            model_type=args.model_type,
            yolo_model=args.yolo_model,
            score_threshold=args.score_threshold,
            device=args.device,
            use_anime_yolo=args.anime_yolo
        )
        
        if args.mode == "reproduce-auto":
            # å†ç¾è‡ªå‹•æŠ½å‡ºãƒ¢ãƒ¼ãƒ‰
            if not os.path.exists(args.input_dir):
                print(f"ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.input_dir}")
                sys.exit(1)
            
            segmentor.process_reproduce_auto_mode(args.input_dir, args.output_dir)
            print("ğŸ‰ å†ç¾è‡ªå‹•æŠ½å‡ºãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            sys.exit(0)  # æ­£å¸¸çµ‚äº†
    
    except KeyboardInterrupt:
        print("\nå‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()

