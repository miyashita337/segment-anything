#!/usr/bin/env python3
"""
kaname09 v0.3.3æœ€é«˜å“è³ªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡ºãƒãƒƒãƒå®Ÿè¡Œ
Phase 1å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ å¼·åŒ–ç‰ˆ - 5ã¤ã®æ–°ã‚·ã‚¹ãƒ†ãƒ çµ±åˆå®Ÿè¡Œ
"""

import sys
import os
import time
import json
from pathlib import Path
import traceback
from datetime import datetime
from typing import Dict, List, Any

# Add project root to Python path
sys.path.insert(0, str(Path(__file__).parent))

def run_kaname09_v033_batch():
    """kaname09 v0.3.3æœ€é«˜å“è³ªãƒãƒƒãƒæŠ½å‡ºå®Ÿè¡Œï¼ˆPhase 1å…¨æ©Ÿèƒ½çµ±åˆï¼‰"""
    
    # ãƒ‘ã‚¹è¨­å®šï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šï¼‰
    input_path = "/mnt/c/AItools/lora/train/yadokugaeru/org/kaname09"
    output_path = "/mnt/c/AItools/lora/train/yadokugaeru/clipped_boundingbox/kaname09_0_3_3"
    
    print("ğŸš€ kaname09 v0.3.3æœ€é«˜å“è³ªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡ºãƒãƒƒãƒå®Ÿè¡Œé–‹å§‹")
    print(f"å…¥åŠ›ãƒ‘ã‚¹: {input_path}")
    print(f"å‡ºåŠ›ãƒ‘ã‚¹: {output_path}")
    print(f"ãƒãƒ¼ã‚¸ãƒ§ãƒ³: v0.3.3 (Phase 1å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ å¼·åŒ–ç‰ˆ)")
    
    # å…¥åŠ›ãƒ‘ã‚¹æ¤œè¨¼
    if not Path(input_path).exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ‘ã‚¹ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {input_path}")
        sys.exit(1)
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
    image_files = list(Path(input_path).glob("*.jpg")) + list(Path(input_path).glob("*.png"))
    
    if not image_files:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ‘ã‚¹ã«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“: {input_path}")
        sys.exit(1)
    
    print(f"ğŸ“Š å‡¦ç†å¯¾è±¡: {len(image_files)}å€‹ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«")
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    Path(output_path).mkdir(parents=True, exist_ok=True)
    
    # v0.3.3å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    quality_analyzers = initialize_v033_quality_systems()
    
    # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
    try:
        from features.extraction.commands.extract_character import extract_character_from_path
        
        success_count = 0
        error_count = 0
        start_time = time.time()
        
        # v0.3.3å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹
        quality_scores = []
        processing_times = []
        v033_quality_results = []
        
        # å“è³ªåˆ†æçµæœæ ¼ç´
        batch_quality_analysis = {
            'batch_info': {
                'version': 'v0.3.3',
                'input_path': input_path,
                'output_path': output_path,
                'total_images': len(image_files),
                'start_time': datetime.now().isoformat()
            },
            'individual_results': [],
            'summary_stats': {}
        }
        
        for i, image_file in enumerate(image_files, 1):
            print(f"\nğŸ”„ [{i}/{len(image_files)}] å‡¦ç†ä¸­: {image_file.name}")
            
            try:
                image_start = time.time()
                
                # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®šï¼ˆç•ªå·ä»˜ãã§æ•´ç†ï¼‰
                output_filename = f"{i:05d}_{image_file.stem}.jpg"
                output_file_path = Path(output_path) / output_filename
                
                # v0.3.3æœ€é«˜å“è³ªè¨­å®šã§ã®æŠ½å‡ºå®Ÿè¡Œ
                result = extract_character_from_path(
                    str(image_file),
                    output_path=str(output_file_path),
                    multi_character_criteria='fullbody_priority_enhanced',  # P1-003æ”¹è‰¯ç‰ˆå…¨èº«æ¤œå‡º
                    enhance_contrast=True,   # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–
                    filter_text=True,        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    save_mask=True,          # ãƒã‚¹ã‚¯ä¿å­˜
                    save_transparent=True,   # é€æ˜èƒŒæ™¯ä¿å­˜
                    verbose=False,           # ãƒãƒƒãƒå‡¦ç†ãªã®ã§è©³ç´°ãƒ­ã‚°ã¯æŠ‘åˆ¶
                    high_quality=True,       # é«˜å“è³ªå‡¦ç†
                    difficult_pose=True,     # å›°é›£å§¿å‹¢å¯¾å¿œ
                    adaptive_learning=True,  # é©å¿œå­¦ç¿’
                    manga_mode=True,         # æ¼«ç”»ãƒ¢ãƒ¼ãƒ‰
                    effect_removal=True,     # ã‚¨ãƒ•ã‚§ã‚¯ãƒˆé™¤å»
                    min_yolo_score=0.05,     # YOLOé–¾å€¤ã‚’ç·©ã‚ã«è¨­å®š
                    # Phase 1è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                    use_enhanced_screentone=True,   # P1-004å¼·åŒ–ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒˆãƒ¼ãƒ³æ¤œå‡º
                    use_mosaic_boundary=True,       # P1-005ãƒ¢ã‚¶ã‚¤ã‚¯å¢ƒç•Œå‡¦ç†
                    use_solid_fill_enhancement=True, # P1-006ãƒ™ã‚¿å¡—ã‚Šé ˜åŸŸæ”¹å–„
                    partial_extraction_check=True,  # P1-002éƒ¨åˆ†æŠ½å‡ºæ¤œå‡º
                )
                
                image_time = time.time() - image_start
                processing_times.append(image_time)
                
                # v0.3.3å“è³ªåˆ†æã®å®Ÿè¡Œ
                v033_analysis = perform_v033_quality_analysis(
                    image_file, output_file_path, result, quality_analyzers
                )
                
                if result.get('success', False):
                    success_count += 1
                    print(f"âœ… æˆåŠŸ: {output_filename}")
                    
                    # v0.3.3å“è³ªæƒ…å ±è¡¨ç¤º
                    if 'quality_score' in result:
                        quality_score = result['quality_score']
                        quality_scores.append(quality_score)
                        print(f"   å“è³ªã‚¹ã‚³ã‚¢: {quality_score:.3f}")
                    
                    # v0.3.3æ–°æ©Ÿèƒ½å“è³ªæƒ…å ±
                    if v033_analysis:
                        print(f"   å¢ƒç•Œå“è³ª: {v033_analysis.get('boundary_grade', 'N/A')}")
                        print(f"   æ§‹é€ èªè­˜: {v033_analysis.get('structure_grade', 'N/A')}")
                        print(f"   åˆ†é›¢å“è³ª: {v033_analysis.get('separation_grade', 'N/A')}")
                    
                    # Phase 1æ”¹å–„æƒ…å ±è¡¨ç¤º
                    if 'enhancement_applied' in result:
                        enhancements = result['enhancement_applied']
                        if enhancements:
                            print(f"   é©ç”¨æ”¹å–„: {', '.join(enhancements)}")
                    
                    print(f"   å‡¦ç†æ™‚é–“: {image_time:.2f}ç§’")
                    
                else:
                    error_count += 1
                    error_msg = result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')
                    print(f"âŒ å¤±æ•—: {output_filename} - {error_msg}")
                
                # å€‹åˆ¥çµæœã‚’è¨˜éŒ²
                individual_result = {
                    'image_file': image_file.name,
                    'output_file': output_filename,
                    'success': result.get('success', False),
                    'processing_time': image_time,
                    'quality_score': result.get('quality_score'),
                    'v033_analysis': v033_analysis,
                    'enhancement_applied': result.get('enhancement_applied', []),
                    'error': result.get('error') if not result.get('success', False) else None
                }
                batch_quality_analysis['individual_results'].append(individual_result)
                v033_quality_results.append(v033_analysis)
                
            except Exception as e:
                error_count += 1
                print(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {image_file.name} - {str(e)}")
                print(f"   ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}")
                
                # ã‚¨ãƒ©ãƒ¼çµæœã‚’è¨˜éŒ²
                individual_result = {
                    'image_file': image_file.name,
                    'output_file': output_filename,
                    'success': False,
                    'processing_time': 0.0,
                    'error': str(e),
                    'v033_analysis': None
                }
                batch_quality_analysis['individual_results'].append(individual_result)
        
        # ãƒãƒƒãƒå‡¦ç†å®Œäº†çµ±è¨ˆ
        total_time = time.time() - start_time
        success_rate = success_count / len(image_files) * 100
        avg_processing_time = sum(processing_times) / len(processing_times) if processing_times else 0
        avg_quality_score = sum(quality_scores) / len(quality_scores) if quality_scores else 0
        
        # v0.3.3å“è³ªçµ±è¨ˆè¨ˆç®—
        v033_stats = calculate_v033_quality_statistics(v033_quality_results)
        
        # ã‚µãƒãƒªãƒ¼çµ±è¨ˆã‚’ãƒãƒƒãƒçµæœã«è¿½åŠ 
        batch_quality_analysis['summary_stats'] = {
            'total_images': len(image_files),
            'success_count': success_count,
            'error_count': error_count,
            'success_rate': success_rate,
            'total_time': total_time,
            'avg_processing_time': avg_processing_time,
            'avg_quality_score': avg_quality_score,
            'v033_quality_stats': v033_stats,
            'end_time': datetime.now().isoformat()
        }
        
        # çµæœãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
        print("\n" + "="*80)
        print("ğŸ“Š kaname09 v0.3.3ãƒãƒƒãƒå‡¦ç†å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*80)
        
        print(f"\nğŸ“ˆ å‡¦ç†çµæœ:")
        print(f"  ç·å‡¦ç†æ•°: {len(image_files)}æš")
        print(f"  æˆåŠŸ: {success_count}æš")
        print(f"  å¤±æ•—: {error_count}æš")
        print(f"  æˆåŠŸç‡: {success_rate:.1f}%")
        print(f"  ç·å‡¦ç†æ™‚é–“: {total_time:.1f}ç§’")
        print(f"  å¹³å‡å‡¦ç†æ™‚é–“: {avg_processing_time:.2f}ç§’/æš")
        
        if quality_scores:
            print(f"\nğŸ¯ å“è³ªçµ±è¨ˆ:")
            print(f"  å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {avg_quality_score:.3f}")
            print(f"  æœ€é«˜å“è³ªã‚¹ã‚³ã‚¢: {max(quality_scores):.3f}")
            print(f"  æœ€ä½å“è³ªã‚¹ã‚³ã‚¢: {min(quality_scores):.3f}")
        
        # v0.3.3æ–°æ©Ÿèƒ½çµ±è¨ˆè¡¨ç¤º
        if v033_stats:
            print(f"\nğŸ†• v0.3.3å“è³ªè©•ä¾¡çµ±è¨ˆ:")
            for metric, stats in v033_stats.items():
                if stats and 'avg_score' in stats:
                    print(f"  {metric}: å¹³å‡{stats['avg_score']:.3f} (ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ†å¸ƒ: {stats.get('grade_distribution', {})})")
        
        # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_path = Path(output_path) / f"kaname09_v033_quality_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(batch_quality_analysis, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
        print(f"\nâœ… kaname09 v0.3.3ãƒãƒƒãƒå‡¦ç†å®Œäº†!")
        
        return success_rate >= 70.0  # 70%ä»¥ä¸Šã®æˆåŠŸç‡ã§æˆåŠŸåˆ¤å®š
        
    except Exception as e:
        print(f"âŒ ãƒãƒƒãƒå‡¦ç†ã§é‡å¤§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        print(f"ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}")
        return False


def initialize_v033_quality_systems():
    """v0.3.3å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
    try:
        from features.evaluation.utils.boundary_analysis import BoundaryAnalyzer
        from features.evaluation.utils.human_structure_recognition import HumanStructureRecognizer
        from features.evaluation.utils.foreground_background_analyzer import ForegroundBackgroundAnalyzer
        from features.evaluation.utils.evaluation_difference_analyzer import EvaluationDifferenceAnalyzer
        from features.evaluation.utils.learning_data_collection import LearningDataCollectionPlanner
        
        return {
            'boundary_analyzer': BoundaryAnalyzer(),
            'structure_recognizer': HumanStructureRecognizer(),
            'separation_analyzer': ForegroundBackgroundAnalyzer(),
            'difference_analyzer': EvaluationDifferenceAnalyzer(),
            'collection_planner': LearningDataCollectionPlanner()
        }
    except ImportError as e:
        print(f"âš ï¸ v0.3.3å“è³ªã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return {}


def perform_v033_quality_analysis(image_file, output_file, result, analyzers):
    """v0.3.3å“è³ªåˆ†æã®å®Ÿè¡Œ"""
    if not analyzers or not result.get('success', False):
        return None
    
    try:
        import cv2
        import numpy as np
        
        # æŠ½å‡ºã•ã‚ŒãŸç”»åƒã¨ãƒã‚¹ã‚¯ã‚’èª­ã¿è¾¼ã¿
        if not output_file.exists():
            return None
        
        extracted_image = cv2.imread(str(output_file))
        if extracted_image is None:
            return None
        
        # ãƒã‚¹ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°èª­ã¿è¾¼ã¿
        mask_file = output_file.parent / f"{output_file.stem}_mask.png"
        if mask_file.exists():
            mask = cv2.imread(str(mask_file), cv2.IMREAD_GRAYSCALE)
        else:
            # RGBç”»åƒã‹ã‚‰ç°¡æ˜“ãƒã‚¹ã‚¯ä½œæˆ
            gray = cv2.cvtColor(extracted_image, cv2.COLOR_BGR2GRAY)
            _, mask = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)
        
        analysis_result = {}
        
        # P1-017: å¢ƒç•Œç·šè§£æ
        if 'boundary_analyzer' in analyzers:
            try:
                boundary_analysis = analyzers['boundary_analyzer'].calculate_boundary_quality_score(mask)
                analysis_result['boundary_analysis'] = boundary_analysis
                analysis_result['boundary_grade'] = boundary_analysis.get('quality_grade', 'F')
                analysis_result['boundary_score'] = boundary_analysis.get('overall_score', 0.0)
            except Exception as e:
                analysis_result['boundary_error'] = str(e)
        
        # P1-019: äººä½“æ§‹é€ èªè­˜
        if 'structure_recognizer' in analyzers:
            try:
                structure_analysis = analyzers['structure_recognizer'].analyze_mask_structure(mask)
                analysis_result['structure_analysis'] = structure_analysis
                overall_assessment = structure_analysis.get('overall_assessment', {})
                analysis_result['structure_grade'] = overall_assessment.get('overall_grade', 'unknown')
                analysis_result['structure_score'] = overall_assessment.get('overall_score', 0.0)
            except Exception as e:
                analysis_result['structure_error'] = str(e)
        
        # P1-021: èƒŒæ™¯ãƒ»å‰æ™¯åˆ†é›¢
        if 'separation_analyzer' in analyzers:
            try:
                original_image = cv2.imread(str(image_file))
                if original_image is not None:
                    if original_image.shape[:2] != mask.shape[:2]:
                        original_image = cv2.resize(original_image, (mask.shape[1], mask.shape[0]))
                    
                    separation_analysis = analyzers['separation_analyzer'].analyze_separation_quality(original_image, mask)
                    analysis_result['separation_analysis'] = separation_analysis
                    separation_score = separation_analysis.get('separation_score', {})
                    analysis_result['separation_grade'] = separation_score.get('quality_grade', 'F')
                    analysis_result['separation_score'] = separation_score.get('overall_score', 0.0)
            except Exception as e:
                analysis_result['separation_error'] = str(e)
        
        return analysis_result
        
    except Exception as e:
        return {'error': str(e)}


def calculate_v033_quality_statistics(v033_results):
    """v0.3.3å“è³ªçµ±è¨ˆè¨ˆç®—"""
    if not v033_results:
        return {}
    
    valid_results = [r for r in v033_results if r and 'error' not in r]
    if not valid_results:
        return {}
    
    stats = {}
    
    # å¢ƒç•Œç·šå“è³ªçµ±è¨ˆ
    boundary_scores = [r.get('boundary_score', 0) for r in valid_results if 'boundary_score' in r]
    boundary_grades = [r.get('boundary_grade', 'F') for r in valid_results if 'boundary_grade' in r]
    
    if boundary_scores:
        stats['boundary_quality'] = {
            'avg_score': sum(boundary_scores) / len(boundary_scores),
            'max_score': max(boundary_scores),
            'min_score': min(boundary_scores),
            'grade_distribution': {grade: boundary_grades.count(grade) for grade in set(boundary_grades)}
        }
    
    # æ§‹é€ èªè­˜çµ±è¨ˆ
    structure_scores = [r.get('structure_score', 0) for r in valid_results if 'structure_score' in r]
    structure_grades = [r.get('structure_grade', 'unknown') for r in valid_results if 'structure_grade' in r]
    
    if structure_scores:
        stats['structure_recognition'] = {
            'avg_score': sum(structure_scores) / len(structure_scores),
            'max_score': max(structure_scores),
            'min_score': min(structure_scores),
            'grade_distribution': {grade: structure_grades.count(grade) for grade in set(structure_grades)}
        }
    
    # åˆ†é›¢å“è³ªçµ±è¨ˆ
    separation_scores = [r.get('separation_score', 0) for r in valid_results if 'separation_score' in r]
    separation_grades = [r.get('separation_grade', 'F') for r in valid_results if 'separation_grade' in r]
    
    if separation_scores:
        stats['separation_quality'] = {
            'avg_score': sum(separation_scores) / len(separation_scores),
            'max_score': max(separation_scores),
            'min_score': min(separation_scores),
            'grade_distribution': {grade: separation_grades.count(grade) for grade in set(separation_grades)}
        }
    
    return stats


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ kaname09 v0.3.3æœ€é«˜å“è³ªãƒãƒƒãƒå‡¦ç†é–‹å§‹")
    
    success = run_kaname09_v033_batch()
    
    if success:
        print("\nâœ… ãƒãƒƒãƒå‡¦ç†æˆåŠŸ!")
        sys.exit(0)
    else:
        print("\nâŒ ãƒãƒƒãƒå‡¦ç†å¤±æ•—")
        sys.exit(1)


if __name__ == "__main__":
    main()