#!/usr/bin/env python3
"""
å®Œå…¨è‡ªå‹•ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
ã‚¢ãƒ‹ãƒ¡å…¨èº«æ¤œå‡ºãƒ¢ãƒ‡ãƒ«æ¢ç´¢ã¨ãƒãƒƒãƒå®Ÿè¡Œã®è‡ªå‹•åŒ–
"""

import logging
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from .background_executor import get_task_manager
from .error_recovery import get_auto_recovery_executor
from .progress_monitor import get_progress_monitor

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class AutoPipeline:
    """å®Œå…¨è‡ªå‹•å®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.task_manager = get_task_manager()
        self.progress_monitor = get_progress_monitor()
        self.recovery_executor = get_auto_recovery_executor()
        self.pipeline_status = {
            'start_time': None,
            'end_time': None,
            'tasks': [],
            'results': {},
            'errors': []
        }
        
    def start_pipeline(self):
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹"""
        self.pipeline_status['start_time'] = datetime.now()
        self.progress_monitor.start_monitoring()
        logger.info("Auto pipeline started")
        
    def stop_pipeline(self):
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åœæ­¢"""
        self.pipeline_status['end_time'] = datetime.now()
        self.progress_monitor.stop_monitoring()
        logger.info("Auto pipeline stopped")
        
    def run_anime_model_search(self) -> Dict[str, Any]:
        """ã‚¢ãƒ‹ãƒ¡å…¨èº«æ¤œå‡ºãƒ¢ãƒ‡ãƒ«æ¢ç´¢"""
        logger.info("Starting anime fullbody model search...")
        
        search_results = {
            'models_found': [],
            'best_model': None,
            'test_results': {}
        }
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«å€™è£œ
        model_candidates = [
            {
                'name': 'yolov8x6_animeface.pt',
                'type': 'anime_specialized',
                'url': 'local',
                'description': 'ã‚¢ãƒ‹ãƒ¡é¡”ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«'
            },
            {
                'name': 'yolov8x.pt',
                'type': 'general',
                'url': 'https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt',
                'description': 'æ±ç”¨é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«'
            },
            {
                'name': 'yolov8l.pt',
                'type': 'general',
                'url': 'https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l.pt',
                'description': 'æ±ç”¨å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«'
            }
        ]
        
        # ãƒ¢ãƒ‡ãƒ«æ¤œç´¢ãƒ»ãƒ†ã‚¹ãƒˆ
        for model_info in model_candidates:
            try:
                # ãƒ¢ãƒ‡ãƒ«å­˜åœ¨ç¢ºèª
                model_path = model_info['name']
                if os.path.exists(model_path):
                    logger.info(f"Found model: {model_path}")
                    search_results['models_found'].append(model_info)
                    
                    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
                    test_result = self._test_anime_model(model_path)
                    search_results['test_results'][model_path] = test_result
                    
            except Exception as e:
                logger.error(f"Error testing model {model_info['name']}: {e}")
                
        # æœ€é©ãƒ¢ãƒ‡ãƒ«é¸æŠ
        if search_results['test_results']:
            best_model = max(
                search_results['test_results'].items(),
                key=lambda x: x[1].get('fullbody_score', 0)
            )
            search_results['best_model'] = best_model[0]
            
        return search_results
        
    def _test_anime_model(self, model_path: str) -> Dict[str, Any]:
        """ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ"""
        try:
            from ultralytics import YOLO
            
            model = YOLO(model_path)
            test_results = {
                'model_path': model_path,
                'tests': []
            }
            
            # ãƒ†ã‚¹ãƒˆç”»åƒ
            test_images = [
                "test_small/img001.jpg",
                "test_small/img002.jpg",
                "test_small/img003.jpg"
            ]
            
            fullbody_count = 0
            total_detections = 0
            
            for img_path in test_images:
                if os.path.exists(img_path):
                    results = model(img_path, conf=0.05, verbose=False)
                    
                    if results[0].boxes is not None:
                        boxes = results[0].boxes
                        detections = len(boxes)
                        total_detections += detections
                        
                        # å…¨èº«æ¤œå‡ºåˆ¤å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
                        for box in boxes.xyxy:
                            x1, y1, x2, y2 = box
                            height = y2 - y1
                            width = x2 - x1
                            aspect_ratio = height / width if width > 0 else 0
                            
                            # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã§å…¨èº«åˆ¤å®š
                            if 1.5 < aspect_ratio < 4.0:
                                fullbody_count += 1
                                
            # ã‚¹ã‚³ã‚¢è¨ˆç®—
            fullbody_score = fullbody_count / max(total_detections, 1)
            
            test_results['fullbody_count'] = fullbody_count
            test_results['total_detections'] = total_detections
            test_results['fullbody_score'] = fullbody_score
            
            return test_results
            
        except Exception as e:
            logger.error(f"Model test error: {e}")
            return {'error': str(e), 'fullbody_score': 0}
            
    def run_batch_processing(self, model_path: Optional[str] = None) -> Dict[str, Any]:
        """ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ"""
        logger.info("Starting batch processing...")
        
        if model_path is None:
            model_path = 'yolov8x.pt'
            
        # ãƒãƒƒãƒå‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        batch_params = {
            'input_dir': 'test_small',
            'output_dir': 'results_batch/auto_pipeline_results',
            'model_path': model_path,
            'score_threshold': 0.005,
            'quality_method': 'balanced'
        }
        
        # ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ
        task_id = self.task_manager.run_batch_extraction(
            batch_params['input_dir'],
            batch_params['output_dir'],
            model_path=batch_params['model_path'],
            score_threshold=batch_params['score_threshold'],
            quality_method=batch_params['quality_method']
        )
        
        self.pipeline_status['tasks'].append(task_id)
        
        # çµæœå¾…æ©Ÿï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ10åˆ†ï¼‰
        try:
            result = self.task_manager.wait_for_completion(task_id, timeout=600)
            return result
        except TimeoutError:
            return {'error': 'Batch processing timeout', 'task_id': task_id}
            
    def collect_output_paths(self) -> List[str]:
        """å‡ºåŠ›ç”»åƒãƒ‘ã‚¹åé›†"""
        logger.info("Collecting output paths...")
        
        output_paths = []
        
        # æ—¢çŸ¥ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dirs = [
            'results_batch',
            'results_batch/auto_pipeline_results',
            'results_batch/yolo_005_test',
            '/tmp'
        ]
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åé›†
        for output_dir in output_dirs:
            if os.path.exists(output_dir):
                for root, dirs, files in os.walk(output_dir):
                    for file in files:
                        if file.endswith(('.jpg', '.jpeg', '.png')):
                            full_path = os.path.join(root, file)
                            output_paths.append(full_path)
                            
        # Phase 2ãƒ†ã‚¹ãƒˆçµæœ
        phase2_patterns = [
            '/tmp/phase2_test_*.jpg',
            '/tmp/test_*.jpg',
            '/tmp/pipeline_test/*.jpg'
        ]
        
        import glob
        for pattern in phase2_patterns:
            matches = glob.glob(pattern)
            output_paths.extend(matches)
            
        # é‡è¤‡é™¤å»
        output_paths = list(set(output_paths))
        output_paths.sort()
        
        return output_paths
        
    def generate_final_report(self) -> Dict[str, Any]:
        """æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        logger.info("Generating final report...")
        
        output_paths = self.collect_output_paths()
        
        report = {
            'pipeline_status': self.pipeline_status,
            'execution_time': str(
                self.pipeline_status['end_time'] - self.pipeline_status['start_time']
            ) if self.pipeline_status['end_time'] else 'Running',
            'output_images': {
                'count': len(output_paths),
                'paths': output_paths
            },
            'model_search_results': self.pipeline_status['results'].get('model_search', {}),
            'batch_results': self.pipeline_status['results'].get('batch_processing', {}),
            'errors': self.pipeline_status['errors']
        }
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_path = Path('temp/logs/final_pipeline_report.json')
        report_path.parent.mkdir(parents=True, exist_ok=True)
        
        import json
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
            
        return report
        
    def run_full_pipeline(self):
        """å®Œå…¨è‡ªå‹•ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
        self.start_pipeline()
        
        try:
            # 1. ã‚¢ãƒ‹ãƒ¡ãƒ¢ãƒ‡ãƒ«æ¢ç´¢
            logger.info("=== Phase 1: Anime Model Search ===")
            model_search_results = self.recovery_executor.execute_with_recovery(
                self.run_anime_model_search
            )
            self.pipeline_status['results']['model_search'] = model_search_results
            
            # 2. æœ€é©ãƒ¢ãƒ‡ãƒ«ã§ãƒãƒƒãƒå‡¦ç†
            logger.info("=== Phase 2: Batch Processing ===")
            best_model = model_search_results.get('best_model')
            batch_results = self.recovery_executor.execute_with_recovery(
                self.run_batch_processing,
                best_model
            )
            self.pipeline_status['results']['batch_processing'] = batch_results
            
            # 3. çµæœé›†ç´„
            logger.info("=== Phase 3: Results Collection ===")
            final_report = self.generate_final_report()
            
            # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
            self._print_final_report(final_report)
            
        except Exception as e:
            logger.error(f"Pipeline error: {e}")
            self.pipeline_status['errors'].append(str(e))
            
        finally:
            self.stop_pipeline()
            
    def _print_final_report(self, report: Dict[str, Any]):
        """æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º"""
        print("\n" + "="*80)
        print("ğŸ‰ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œå®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*80)
        
        print(f"\nâ±ï¸ å®Ÿè¡Œæ™‚é–“: {report['execution_time']}")
        
        print(f"\nğŸ“Š ãƒ¢ãƒ‡ãƒ«æ¢ç´¢çµæœ:")
        model_results = report.get('model_search_results', {})
        print(f"   ç™ºè¦‹ãƒ¢ãƒ‡ãƒ«æ•°: {len(model_results.get('models_found', []))}")
        print(f"   æœ€é©ãƒ¢ãƒ‡ãƒ«: {model_results.get('best_model', 'N/A')}")
        
        print(f"\nğŸ“ å‡ºåŠ›ç”»åƒ:")
        print(f"   ç·æ•°: {report['output_images']['count']}")
        print(f"   ä¿å­˜å…ˆ:")
        for path in report['output_images']['paths'][:10]:  # æœ€åˆã®10ä»¶
            print(f"      - {path}")
        if len(report['output_images']['paths']) > 10:
            print(f"      ... ä»– {len(report['output_images']['paths']) - 10} ãƒ•ã‚¡ã‚¤ãƒ«")
            
        if report['errors']:
            print(f"\nâš ï¸ ã‚¨ãƒ©ãƒ¼:")
            for error in report['errors']:
                print(f"   - {error}")
                
        print(f"\nğŸ’¾ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: temp/logs/final_pipeline_report.json")
        print("="*80 + "\n")


# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_auto_pipeline = None


def get_auto_pipeline() -> AutoPipeline:
    """è‡ªå‹•ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—"""
    global _auto_pipeline
    if _auto_pipeline is None:
        _auto_pipeline = AutoPipeline()
    return _auto_pipeline