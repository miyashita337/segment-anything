#!/usr/bin/env python3
"""
ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ãƒãƒƒãƒå‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–ã§å°åˆ†ã‘ã—ã¦å‡¦ç†ã—ã€æœ€å¾Œã«ã¾ã¨ã‚ã¦é€šçŸ¥
"""

import sys
import os
import json
import time
from pathlib import Path
sys.path.append('.')

from utils.notification import send_batch_notification

# é€²æ—ãƒ•ã‚¡ã‚¤ãƒ«
PROGRESS_FILE = "batch_progress.json"

def load_progress():
    """é€²æ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    if Path(PROGRESS_FILE).exists():
        with open(PROGRESS_FILE, 'r') as f:
            return json.load(f)
    return {"processed": [], "successful": 0, "failed": 0, "start_time": time.time()}

def save_progress(progress):
    """é€²æ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜"""
    with open(PROGRESS_FILE, 'w') as f:
        json.dump(progress, f, indent=2)

def process_chunk(start_idx, chunk_size=10):
    """æŒ‡å®šç¯„å›²ã®ç”»åƒã‚’å‡¦ç†"""
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    print("ğŸ”„ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
    from hooks.start import start
    start()
    print("âœ… ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
    
    # ãƒãƒƒãƒå‡¦ç†
    from commands.extract_character import batch_extract_characters
    
    input_dir = "/mnt/c/AItools/lora/train/diff_aichi/org_aichikan1"
    output_dir = "/mnt/c/AItools/lora/train/diff_aichi/auto_extracted_v5"
    
    # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå–å¾—
    input_path = Path(input_dir)
    image_files = sorted([f for f in input_path.iterdir() 
                         if f.suffix.lower() in ['.jpg', '.jpeg', '.png']])
    
    total_files = len(image_files)
    end_idx = min(start_idx + chunk_size, total_files)
    chunk_files = image_files[start_idx:end_idx]
    
    print(f"ğŸš€ ãƒãƒ£ãƒ³ã‚¯å‡¦ç†é–‹å§‹: {start_idx+1}-{end_idx}/{total_files}")
    
    # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ç”¨ã®ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    chunk_input_dir = Path("temp_chunk_input")
    chunk_input_dir.mkdir(exist_ok=True)
    
    # ãƒãƒ£ãƒ³ã‚¯å†…ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒªãƒ³ã‚¯
    for i, file in enumerate(chunk_files):
        link_path = chunk_input_dir / file.name
        if link_path.exists():
            link_path.unlink()  # æ—¢å­˜ãƒªãƒ³ã‚¯ã‚’å‰Šé™¤
        link_path.symlink_to(file.absolute())
    
    try:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        extract_args = {
            'enhance_contrast': False,
            'filter_text': True,
            'save_mask': False,
            'save_transparent': False,
            'min_yolo_score': 0.1,
            'verbose': False
        }
        
        result = batch_extract_characters(str(chunk_input_dir), output_dir, **extract_args)
        
        return {
            'successful': result['successful'],
            'failed': result['failed'],
            'total': len(chunk_files),
            'total_time': result.get('total_time', 0),
            'processed_files': [f.name for f in chunk_files]
        }
    
    finally:
        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        for link_file in chunk_input_dir.iterdir():
            link_file.unlink()
        chunk_input_dir.rmdir()

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    progress = load_progress()
    
    # å…¨ãƒ•ã‚¡ã‚¤ãƒ«æ•°å–å¾—
    input_dir = "/mnt/c/AItools/lora/train/diff_aichi/org_aichikan1"
    input_path = Path(input_dir)
    all_files = sorted([f for f in input_path.iterdir() 
                       if f.suffix.lower() in ['.jpg', '.jpeg', '.png']])
    total_files = len(all_files)
    
    # æœªå‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é–‹å§‹ä½ç½®æ±ºå®š
    processed_files = set(progress.get("processed", []))
    start_idx = 0
    for i, file in enumerate(all_files):
        if file.name not in processed_files:
            start_idx = i
            break
    else:
        # å…¨ã¦å‡¦ç†æ¸ˆã¿
        print("âœ… å…¨ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ¸ˆã¿")
        # æœ€çµ‚é€šçŸ¥é€ä¿¡
        elapsed_time = time.time() - progress["start_time"]
        send_batch_notification(
            successful=progress["successful"],
            total=total_files,
            failed=progress["failed"],
            total_time=elapsed_time
        )
        Path(PROGRESS_FILE).unlink(missing_ok=True)
        return
    
    print(f"ğŸ“Š é€²æ—çŠ¶æ³: {len(processed_files)}/{total_files} å®Œäº†")
    print(f"â¯ï¸ ä½ç½® {start_idx+1} ã‹ã‚‰å†é–‹")
    
    # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ï¼ˆ5ãƒ•ã‚¡ã‚¤ãƒ«ãšã¤ï¼‰
    chunk_size = 5
    chunk_result = process_chunk(start_idx, chunk_size)
    
    # é€²æ—æ›´æ–°
    progress["successful"] += chunk_result["successful"]
    progress["failed"] += chunk_result["failed"]
    progress["processed"].extend(chunk_result["processed_files"])
    
    save_progress(progress)
    
    # é€²æ—è¡¨ç¤º
    completed = len(progress["processed"])
    success_rate = (progress["successful"] / completed * 100) if completed > 0 else 0
    
    print(f"\nğŸ“Š ãƒãƒ£ãƒ³ã‚¯å®Œäº†:")
    print(f"   ä»Šå›: æˆåŠŸ{chunk_result['successful']}/å¤±æ•—{chunk_result['failed']}")
    print(f"   ç´¯è¨ˆ: {progress['successful']}/{completed} ({success_rate:.1f}%)")
    print(f"   æ®‹ã‚Š: {total_files - completed}ãƒ•ã‚¡ã‚¤ãƒ«")
    
    # å…¨å‡¦ç†å®Œäº†ãƒã‚§ãƒƒã‚¯
    if completed >= total_files:
        print("\nğŸ‰ å…¨ãƒãƒƒãƒå‡¦ç†å®Œäº†!")
        elapsed_time = time.time() - progress["start_time"]
        
        # æœ€çµ‚é€šçŸ¥é€ä¿¡
        print("ğŸ“± æœ€çµ‚é€šçŸ¥é€ä¿¡ä¸­...")
        notification_sent = send_batch_notification(
            successful=progress["successful"],
            total=total_files,
            failed=progress["failed"],
            total_time=elapsed_time
        )
        
        if notification_sent:
            print("âœ… Pushoveré€šçŸ¥é€ä¿¡å®Œäº†")
        else:
            print("âš ï¸ Pushoveré€šçŸ¥é€ä¿¡å¤±æ•—")
        
        # é€²æ—ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        Path(PROGRESS_FILE).unlink(missing_ok=True)
    else:
        print(f"\nâ­ï¸ æ¬¡å›ã¯ä½ç½® {start_idx + chunk_size + 1} ã‹ã‚‰ç¶™ç¶š")

if __name__ == "__main__":
    main()